{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a7436a844814321bec9efa9e75dddee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6597aae9b50540d591d327d811140fe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed160c828f7a45a6a21f017a0d3ff2dd",
              "IPY_MODEL_c3a9805861074e85935bdc96f27308b2"
            ]
          }
        },
        "6597aae9b50540d591d327d811140fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed160c828f7a45a6a21f017a0d3ff2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00200ac39344a45bb4b13627e2415f5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_092cd69131e94e01a33869984d252490"
          }
        },
        "c3a9805861074e85935bdc96f27308b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc338c906c874f06ae79f192002690d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:12&lt;00:00, 98.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c5c44d482814afeb6646e29f67ec4bf"
          }
        },
        "d00200ac39344a45bb4b13627e2415f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "092cd69131e94e01a33869984d252490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc338c906c874f06ae79f192002690d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c5c44d482814afeb6646e29f67ec4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c13a796deb324ee5ab0517cfd9a67504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_662cf31735914c66a58e446f42f33a44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_015a6f5cdd2b40779560d911ae011a5b",
              "IPY_MODEL_cc598a4ab9954c10979dd8704c0c64fe"
            ]
          }
        },
        "662cf31735914c66a58e446f42f33a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "015a6f5cdd2b40779560d911ae011a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acc88fb05ab04cf58bd75d98ac4399e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d3f0f543ac40929ad82574955fb23f"
          }
        },
        "cc598a4ab9954c10979dd8704c0c64fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5149f97423974c5faa37fb19ab5ad650",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:11&lt;00:00, 76.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0bfd2a76bcb45fabddba532ec553ae9"
          }
        },
        "acc88fb05ab04cf58bd75d98ac4399e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d3f0f543ac40929ad82574955fb23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5149f97423974c5faa37fb19ab5ad650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0bfd2a76bcb45fabddba532ec553ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7460571df65d4f6d976e6ad48b63e04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c448466034c433ea0866e952be3ccb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06dc4f869fad46aa938042f1de1b536a",
              "IPY_MODEL_389fc01fc08c46e6b30b27a60b44ef79"
            ]
          }
        },
        "9c448466034c433ea0866e952be3ccb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06dc4f869fad46aa938042f1de1b536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_986812b32d65416ba26c688e3ecbbe72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bbcdb4bcaeb4f8f9fd8fd8718a596b4"
          }
        },
        "389fc01fc08c46e6b30b27a60b44ef79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bea411c3581b4eabb275826ddb052f2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:03&lt;00:00, 257kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2283e7654ee24404a56299462250b25e"
          }
        },
        "986812b32d65416ba26c688e3ecbbe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bbcdb4bcaeb4f8f9fd8fd8718a596b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea411c3581b4eabb275826ddb052f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2283e7654ee24404a56299462250b25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9e88b138e140578d81958edd8987c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78d775a25b404be5a76bffa9a101cac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bb99946316e45bea265e0ff1641f329",
              "IPY_MODEL_e6103afe0cc5478aa35e4ad92271f8fa"
            ]
          }
        },
        "78d775a25b404be5a76bffa9a101cac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bb99946316e45bea265e0ff1641f329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79110aefc6994d6c9fa8f31991b600e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f82d5814f7c0414cb114a278e45956a0"
          }
        },
        "e6103afe0cc5478aa35e4ad92271f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65a942425ee24c30a4c8f2c2ce1615a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:02&lt;00:00, 470kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba06178a696249aea502f550eda4aad8"
          }
        },
        "79110aefc6994d6c9fa8f31991b600e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f82d5814f7c0414cb114a278e45956a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65a942425ee24c30a4c8f2c2ce1615a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba06178a696249aea502f550eda4aad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUNiu36r0au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396c89db-473d-4c80-ae39-0a8d15eb0c32"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq4hrow7mo4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1af92456-975f-456a-aec1-dbf2da384a9b"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tree = ET.parse(\"/content/drive/MyDrive/datasets/NLP/corpus_taln_v1.tei.xml\") #L'XML du corpus taln est à insérer ici.\n",
        "root = tree.getroot()\n",
        "ns = re.findall(\"{.*}\", root.tag)[0] #Le nom de domaine XML du corpus.\n",
        "ns \n",
        "# {http://www.tei-c.org/ns/1.0}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{http://www.tei-c.org/ns/1.0}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACeRMuSyAjpj"
      },
      "source": [
        "Dans la fonction get_abstracts j'utilise la librairie xml elementtree comme conseillé dans le sujet du projet 1 pour :\n",
        "\n",
        "1.   itérer sur les balises des articles \"TEI\" qui contiennent dans leur attribut de valise le mot clé \"fr\" qui signifie que l'article est en français,\n",
        "\n",
        "2.   naviguer à la balise div de l'entête de l'article qui contient les résumés dont je récupère la version en français si elle existe et est différente de \"None\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcG_YlEUI0ci"
      },
      "source": [
        "def Get_Abstracts(tree, size=None):\n",
        "  abstract = []\n",
        "  text = ''\n",
        "  tei = root.iter(ns+\"TEI\") #Itérateur sur les balises 'TEI' qui correspondent aux articles.\n",
        "  if size == None:\n",
        "    size = root.iter(ns+\"TEI\")\n",
        "  else:\n",
        "    size = range(size)\n",
        "  for i in size:\n",
        "    try:\n",
        "      x = tei.__next__()\n",
        "      if any(\"fr\" in s for s in x.attrib.values()):\n",
        "        for y in x.iter(ns+\"div\"):\n",
        "          if any(\"fr\" in s for s in y.attrib.values()):\n",
        "            for p in y.iter(ns+\"p\"):\n",
        "              if p.text != \"None\":\n",
        "                text = p.text.strip().replace('\\n\\t','') #Nettoyage de ce qui déborde dans les abstracts avec la fonction strip() et effacement des caractères de saut à la ligne présent dans la chaine de caractère brute.\n",
        "        if len(text) != 0:\n",
        "          abstract.append(text)\n",
        "    except:\n",
        "      break\n",
        "  return abstract"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_TiOui8L-p",
        "outputId": "9dd75606-acc6-4469-abfe-143ac61b3aa7"
      },
      "source": [
        "abstracts = Get_Abstracts(root)\n",
        "abstracts[0:5]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nous considérons dans notre travail la tâche du traitement automatique visant à construire, à partir de textes issus d\\'un corpus de constats d\\'accidents de la route, des interprétations compatibles avec ces derniers, et à en proposer des illustrations sous forme de séquences d\\'images fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modèle de la Grammaire Applicative et Cognitive [DES 90], qui vise en particulier à \"expliquer\", à un certain niveau cognitif, les transferts entre représentations imagées et verbales. Pour une revue de la question relative à la \"transcription automatique Verbal-Image\", nous renvoyons à [ARN 90] ; et plus particulièrement aux travaux de C. Vandeloise [VAN 87] et du groupe \"Langue, Raisonnement, Calcul\" de l\\'Université Paul Sabatier [AUR 90, SAB 95] ainsi qu\\'aux approches proposées dans [ARN 93] et dans le système SPRINT [YAM 92]. Plus proches encore de nos préoccupations, B. Victorri et P. Enjalbert [ENJ 94, POI 95] posent le problème de l\\'animation visuelle issue de l\\'interprétation de textes. Nous présentons dans cet article, à travers le traitement d\\'un exemple, la méthode générale d\\'analyse que nous avons adoptée, qui s\\'appuie en priorité sur des connaissances linguistiques. Le texte pris comme exemple est le suivant : Je roulais sur la partie droite de la chaussée quand un véhicule arrivant dans le virage a été complètement déporté. Serrant à droite au maximum, je n\\'ai [pu] éviter la voiture [qui arrivait à grande vitesse]. Nous ne traitons pas ici la modalité introduite par pu , de même que la relative qui arrivait à grande vitesse. Dans la première partie de l\\'article, nous présentons l\\'architecture globale du système informatique. Dans la deuxième partie, nous proposons des éléments d\\'analyse pour une solution opératoire aux problèmes d\\'articulation des significations lexicales et grammaticales, sous forme d\\'une segmentation du texte en différentes phases spatio-temporelles. Dans la troisième partie, nous présentons une modélisation des lieux de circulation et du mouvement des véhicules garantissant le passage à l\\'image.',\n",
              " \"Nous donnons ici un aperçu du logiciel DECID développé au GETA afin d'informatiser le processus de rédaction du dictionnaire explicatif et combinatoire du français contemporain.\",\n",
              " 'Diverses méthodes ont été proposées pour construire un \"graphe conceptuel\" représentant le \"sens\" d\\'une phrase à partir de son analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un véritable formalisme linguistique. Nous nous intéressons ici à la construction d\\'une telle représentation sémantique à partir de la représentation syntaxique produite par une analyse LFG, et montrons comment une transposition du \"joint dirigé\" des graphes conceptuels permet d\\'effectuer cette construction à partir de la \"structure sémantique \"des LFG.',\n",
              " \"Le terme de lambda-DRT désigne un ensemble de méthodes permettant de construire des représentations sémantiques (DRS) à partir d'arbres syntaxiques. La mise en oeuvre de telles méthodes nécessite l'élaboration de systèmes de types dont le détail est rarement présenté. C'est à la description d'un tel système que cet article est consacré.\",\n",
              " \"Dans cet article, nous comparons deux modèles linguistiques utilisés en TAL, les grammaires d'arbres adjoints [= TAG] et le Théorie Sens-Texte [= TST]. Nous montrons que ces deux modèles présentent des similitudes notables, et que les représentations les plus abstraites qu'ils donnent d'une phrase — la représentation sémantique en TST et l'arbre de dérivation en TAG — sont équivalentes. De ce rapprochement découle d'une part que l'on peut s'inspirer de la procédure de dérivation TAG pour opérer la correspondance Sens-Texte, et d'autre part que l'on peut concevoir une grammaire TAG comme le résultat de la précompilation d'une grammaire Sens-Texte.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzDZxsVA_jeU"
      },
      "source": [
        "J'utilise la librairie disponible à ce [lien](https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer) qui permet la lémmatisation des mots français en se basant sur des ressources académiques du [Lexique des Formes Fléchies du Français](http://pauillac.inria.fr/~sagot/index.html#lefff).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Km3jBUiDOu",
        "outputId": "cfa80c37-d3de-4762-c8f2-c5310443f1f3"
      },
      "source": [
        "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
            "  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-6amagics\n",
            "  Running command git clone -q https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-6amagics\n",
            "Building wheels for collected packages: FrenchLefffLemmatizer\n",
            "  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-cp36-none-any.whl size=3533520 sha256=8ebef7656ab2fd981ad3f26236a959ddcaff9e17b98157607361fa92f5923bcf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wkxmwa3o/wheels/95/b7/c0/e249ca2690c04f6106b9581c5e4111287f71dbd85bac903445\n",
            "Successfully built FrenchLefffLemmatizer\n",
            "Installing collected packages: FrenchLefffLemmatizer\n",
            "Successfully installed FrenchLefffLemmatizer-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gY--5Dk4bj"
      },
      "source": [
        "Les abstracts doivent être nettoyer et épurer des mots d'arrêt basique comme prétraitement avant de faire le tf-idf, je procède à ces étapes :\n",
        "\n",
        "\n",
        "1.   Séparation des résumés en token avec la fonction regex de tokénisation de nltk,\n",
        "\n",
        "2.   Utilisisation de la liste de mots d'arrêt de meilleure qualité que celle de nltk trouvé [ici](https://github.com/cmchurch/nltk_french/blob/master/french-nltk.py) dans la fonction \"get_stopswords\",\n",
        "\n",
        "3.   Comme en travaux pratiques dirigés, le texte est mis en miniscule avec .lower(), a noté que la double boucle est dû à des précédentes méthodes que j'ai utilisé et qui ont donné la forme peut pratique d'une liste de liste, ainsi il est nécessaire pour accéder aux chaines de caractères de faire deux fois des for x ~ in y\n",
        "\n",
        "4.   J'utilise ensuite la fonctionnalité de python sur la génération de liste avec opération sur chaque élement pour retirer les mots d'arrêt simples puis tous les nombres et mots courts de trois lettres ou moins,\n",
        "\n",
        "5. Pour finir j'utilise la librairie référencer plus haut pour lemmatiser la liste de mots d'arrêt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP40M-7zagOv"
      },
      "source": [
        "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora, models\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  lemmatizer = FrenchLefffLemmatizer()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  fr_stop = [\"Ap.\", \"Apr.\", \"GHz\", \"MHz\", \"USD\", \"a\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ait\", \"alors\", \"après\", \"as\", \"attendu\", \"au\", \"au-delà\", \"au-devant\", \"aucun\", \"aucune\", \"audit\", \"auprès\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\", \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autour\", \"autre\", \"autres\", \"autrui\", \"aux\", \"auxdites\", \"auxdits\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\", \"aviez\", \"avions\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"banco\", \"ben\", \"bien\", \"bé\", \"c\", \"c'\", \"c'est\", \"c'était\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-là\", \"celles\", \"celles-ci\", \"celles-là\", \"celui\", \"celui-ci\", \"celui-là\", \"celà\", \"cent\", \"cents\", \"cependant\", \"certain\", \"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-là\", \"cf.\", \"cg\", \"cgr\", \"chacun\", \"chacune\", \"chaque\", \"chez\", \"ci\", \"cinq\", \"cinquante\", \"cinquante-cinq\", \"cinquante-deux\", \"cinquante-et-un\", \"cinquante-huit\", \"cinquante-neuf\", \"cinquante-quatre\", \"cinquante-sept\", \"cinquante-six\", \"cinquante-trois\", \"cl\", \"cm\", \"cm²\", \"comme\", \"contre\", \"d\", \"d'\", \"d'après\", \"d'un\", \"d'une\", \"dans\", \"de\", \"depuis\", \"derrière\", \"des\", \"desdites\", \"desdits\", \"desquelles\", \"desquels\", \"deux\", \"devant\", \"devers\", \"dg\", \"différentes\", \"différents\", \"divers\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dl\", \"dm\", \"donc\", \"dont\", \"douze\", \"du\", \"dudit\", \"duquel\", \"durant\", \"dès\", \"déjà\", \"e\", \"eh\", \"elle\", \"elles\", \"en\", \"en-dehors\", \"encore\", \"enfin\", \"entre\", \"envers\", \"es\", \"est\", \"et\", \"eu\", \"eue\", \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eûmes\", \"eût\", \"eûtes\", \"f\", \"fait\", \"fi\", \"flac\", \"fors\", \"furent\", \"fus\", \"fusse\", \"fussent\", \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"fûmes\", \"fût\", \"fûtes\", \"g\", \"gr\", \"h\", \"ha\", \"han\", \"hein\", \"hem\", \"heu\", \"hg\", \"hl\", \"hm\", \"hm³\", \"holà\", \"hop\", \"hormis\", \"hors\", \"huit\", \"hum\", \"hé\", \"i\", \"ici\", \"il\", \"ils\", \"j\", \"j'\", \"j'ai\", \"j'avais\", \"j'étais\", \"jamais\", \"je\", \"jusqu'\", \"jusqu'au\", \"jusqu'aux\", \"jusqu'à\", \"jusque\", \"k\", \"kg\", \"km\", \"km²\", \"l\", \"l'\", \"l'autre\", \"l'on\", \"l'un\", \"l'une\", \"la\", \"laquelle\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lez\", \"lors\", \"lorsqu'\", \"lorsque\", \"lui\", \"lès\", \"m\", \"m'\", \"ma\", \"maint\", \"mainte\", \"maintes\", \"maints\", \"mais\", \"malgré\", \"me\", \"mes\", \"mg\", \"mgr\", \"mil\", \"mille\", \"milliards\", \"millions\", \"ml\", \"mm\", \"mm²\", \"moi\", \"moins\", \"mon\", \"moyennant\", \"mt\", \"m²\", \"m³\", \"même\", \"mêmes\", \"n\", \"n'avait\", \"n'y\", \"ne\", \"neuf\", \"ni\", \"non\", \"nonante\", \"nonobstant\", \"nos\", \"notre\", \"nous\", \"nul\", \"nulle\", \"nº\", \"néanmoins\", \"o\", \"octante\", \"oh\", \"on\", \"ont\", \"onze\", \"or\", \"ou\", \"outre\", \"où\", \"p\", \"par\", \"par-delà\", \"parbleu\", \"parce\", \"parmi\", \"pas\", \"passé\", \"pendant\", \"personne\", \"peu\", \"plus\", \"plus_d'un\", \"plus_d'une\", \"plusieurs\", \"pour\", \"pourquoi\", \"pourtant\", \"pourvu\", \"près\", \"puisqu'\", \"puisque\", \"q\", \"qu\", \"qu'\", \"qu'elle\", \"qu'elles\", \"qu'il\", \"qu'ils\", \"qu'on\", \"quand\", \"quant\", \"quarante\", \"quarante-cinq\", \"quarante-deux\", \"quarante-et-un\", \"quarante-huit\", \"quarante-neuf\", \"quarante-quatre\", \"quarante-sept\", \"quarante-six\", \"quarante-trois\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatre-vingt-cinq\", \"quatre-vingt-deux\", \"quatre-vingt-dix\", \"quatre-vingt-dix-huit\", \"quatre-vingt-dix-neuf\", \"quatre-vingt-dix-sept\", \"quatre-vingt-douze\", \"quatre-vingt-huit\", \"quatre-vingt-neuf\", \"quatre-vingt-onze\", \"quatre-vingt-quatorze\", \"quatre-vingt-quatre\", \"quatre-vingt-quinze\", \"quatre-vingt-seize\", \"quatre-vingt-sept\", \"quatre-vingt-six\", \"quatre-vingt-treize\", \"quatre-vingt-trois\", \"quatre-vingt-un\", \"quatre-vingt-une\", \"quatre-vingts\", \"que\", \"quel\", \"quelle\", \"quelles\", \"quelqu'\", \"quelqu'un\", \"quelqu'une\", \"quelque\", \"quelques\", \"quelques-unes\", \"quelques-uns\", \"quels\", \"qui\", \"quiconque\", \"quinze\", \"quoi\", \"quoiqu'\", \"quoique\", \"r\", \"revoici\", \"revoilà\", \"rien\", \"s\", \"s'\", \"sa\", \"sans\", \"sauf\", \"se\", \"seize\", \"selon\", \"sept\", \"septante\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\", \"serions\", \"serons\", \"seront\", \"ses\", \"si\", \"sinon\", \"six\", \"soi\", \"soient\", \"sois\", \"soit\", \"soixante\", \"soixante-cinq\", \"soixante-deux\", \"soixante-dix\", \"soixante-dix-huit\", \"soixante-dix-neuf\", \"soixante-dix-sept\", \"soixante-douze\", \"soixante-et-onze\", \"soixante-et-un\", \"soixante-et-une\", \"soixante-huit\", \"soixante-neuf\", \"soixante-quatorze\", \"soixante-quatre\", \"soixante-quinze\", \"soixante-seize\", \"soixante-sept\", \"soixante-six\", \"soixante-treize\", \"soixante-trois\", \"sommes\", \"son\", \"sont\", \"sous\", \"soyez\", \"soyons\", \"suis\", \"suite\", \"sur\", \"sus\", \"t\", \"t'\", \"ta\", \"tacatac\", \"tandis\", \"te\", \"tel\", \"telle\", \"telles\", \"tels\", \"tes\", \"toi\", \"ton\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"trente-cinq\", \"trente-deux\", \"trente-et-un\", \"trente-huit\", \"trente-neuf\", \"trente-quatre\", \"trente-sept\", \"trente-six\", \"trente-trois\", \"trois\", \"très\", \"tu\", \"u\", \"un\", \"une\", \"unes\", \"uns\", \"v\", \"vers\", \"via\", \"vingt\", \"vingt-cinq\", \"vingt-deux\", \"vingt-huit\", \"vingt-neuf\", \"vingt-quatre\", \"vingt-sept\", \"vingt-six\", \"vingt-trois\", \"vis-à-vis\", \"voici\", \"voilà\", \"vos\", \"votre\", \"vous\", \"w\", \"x\", \"y\", \"z\", \"zéro\", \"à\", \"ç'\", \"ça\", \"ès\", \"étaient\", \"étais\", \"était\", \"étant\", \"étiez\", \"étions\", \"été\", \"étée\", \"étées\", \"étés\", \"êtes\", \"être\", \"ô\"]\n",
        "  cleaned_text = []\n",
        "  for abstract in text:\n",
        "      lowercase_text = abstract.lower()\n",
        "      words = tokenizer.tokenize(lowercase_text)\n",
        "      non_stopped_words = [lemmatizer.lemmatize(i) for i in words if not i in fr_stop and not bool(re.search(\"\\d+\",i)) and len(i)>3]\n",
        "      cleaned_text.append(non_stopped_words)\n",
        "  return cleaned_text\n",
        "  \n",
        "def doLDA(cleaned_text):\n",
        "  dictionary = corpora.Dictionary(cleaned_text)\n",
        "  corpus = [dictionary.doc2bow(abstract) for abstract in cleaned_text]\n",
        "  ldamodel = models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary)\n",
        "  print(ldamodel.print_topics(num_topics=2, num_words=4))\n",
        "  return ldamodel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_be4mFnn36"
      },
      "source": [
        "Comme dans les exemples trouvables sur internet, j'ai utilisé l'implémentation de tfidf de sklearn ce qui me permet de récupérer le résulat final soit forme d'un Dataframe pandas avec en abscisse les mots d'arrêt et en ordonné l'index des résumés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV5HzTpfoJ5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "20b57d74-606e-4141-e6c4-12faa3be8f0c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "text = clean_text(text = abstracts)\n",
        "corpus = [' '.join(doc) for doc in text]\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns=feature_names)\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonné</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrégé</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>académiques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptées</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordé</th>\n",
              "      <th>accès</th>\n",
              "      <th>accéder</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquière</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activité</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>étiquetagemorpho</th>\n",
              "      <th>étiqueteur</th>\n",
              "      <th>étiquettage</th>\n",
              "      <th>étiquette</th>\n",
              "      <th>étiqueté</th>\n",
              "      <th>étiquetés</th>\n",
              "      <th>étranger</th>\n",
              "      <th>étude</th>\n",
              "      <th>étudiant</th>\n",
              "      <th>étudier</th>\n",
              "      <th>étudions</th>\n",
              "      <th>étudié</th>\n",
              "      <th>étudiées</th>\n",
              "      <th>étudiés</th>\n",
              "      <th>étymologie</th>\n",
              "      <th>évaluatif</th>\n",
              "      <th>évaluation</th>\n",
              "      <th>évaluative</th>\n",
              "      <th>évaluatives</th>\n",
              "      <th>évaluer</th>\n",
              "      <th>évaluerons</th>\n",
              "      <th>évaluée</th>\n",
              "      <th>éventail</th>\n",
              "      <th>éventualité</th>\n",
              "      <th>évidence</th>\n",
              "      <th>évident</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolutif</th>\n",
              "      <th>évolutifs</th>\n",
              "      <th>évolution</th>\n",
              "      <th>évolutive</th>\n",
              "      <th>évolutives</th>\n",
              "      <th>évolutivité</th>\n",
              "      <th>évoque</th>\n",
              "      <th>évoquées</th>\n",
              "      <th>évènementielle</th>\n",
              "      <th>évènements</th>\n",
              "      <th>événement</th>\n",
              "      <th>événementielle</th>\n",
              "      <th>événementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1501 rows × 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      abandonnant  abandonné  able  ...  événement  événementielle  événementiels\n",
              "0             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "2             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "3             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "4             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "...           ...        ...   ...  ...        ...             ...            ...\n",
              "1496          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1497          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1498          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1499          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1500          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "\n",
              "[1501 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwRd1wxUoaHp"
      },
      "source": [
        "Les mots ayant un tfidf de 0 ne sont pas présent dans les résumés des lignes correspondantes, ils ne sont donc pas pertinent, je crée donc un deuxième jeu de donnée fait des valeurs strictement positives.\n",
        "\n",
        "La fonction describe donne des statistiques sur le jeu de donnée, celle ci est utile pour connaitre la répartition des valeurs td idf pertinentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "cvHML79AXhg0",
        "outputId": "a5467dd8-bef8-4905-f00e-0e829f90faff"
      },
      "source": [
        "desc = df[df > 0].describe()\n",
        "desc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonné</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrégé</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>académiques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptées</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordé</th>\n",
              "      <th>accès</th>\n",
              "      <th>accéder</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquière</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activité</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>étiquetagemorpho</th>\n",
              "      <th>étiqueteur</th>\n",
              "      <th>étiquettage</th>\n",
              "      <th>étiquette</th>\n",
              "      <th>étiqueté</th>\n",
              "      <th>étiquetés</th>\n",
              "      <th>étranger</th>\n",
              "      <th>étude</th>\n",
              "      <th>étudiant</th>\n",
              "      <th>étudier</th>\n",
              "      <th>étudions</th>\n",
              "      <th>étudié</th>\n",
              "      <th>étudiées</th>\n",
              "      <th>étudiés</th>\n",
              "      <th>étymologie</th>\n",
              "      <th>évaluatif</th>\n",
              "      <th>évaluation</th>\n",
              "      <th>évaluative</th>\n",
              "      <th>évaluatives</th>\n",
              "      <th>évaluer</th>\n",
              "      <th>évaluerons</th>\n",
              "      <th>évaluée</th>\n",
              "      <th>éventail</th>\n",
              "      <th>éventualité</th>\n",
              "      <th>évidence</th>\n",
              "      <th>évident</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolutif</th>\n",
              "      <th>évolutifs</th>\n",
              "      <th>évolution</th>\n",
              "      <th>évolutive</th>\n",
              "      <th>évolutives</th>\n",
              "      <th>évolutivité</th>\n",
              "      <th>évoque</th>\n",
              "      <th>évoquées</th>\n",
              "      <th>évènementielle</th>\n",
              "      <th>évènements</th>\n",
              "      <th>événement</th>\n",
              "      <th>événementielle</th>\n",
              "      <th>événementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.108237</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.342702</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.279619</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.376711</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.385082</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.381658</td>\n",
              "      <td>0.341043</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.296847</td>\n",
              "      <td>0.417863</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.360660</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.410997</td>\n",
              "      <td>0.318679</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.243023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.308624</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105788</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.089011</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.254174</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440063</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023640</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.156819</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.184360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.163013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.179554</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.104128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.055251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.133793</td>\n",
              "      <td>0.067838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.189427</td>\n",
              "      <td>0.032545</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.207922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.079683</td>\n",
              "      <td>0.232430</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.096411</td>\n",
              "      <td>0.136131</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.120218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.058638</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.102108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.174677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.052591</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.070434</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.118352</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.351925</td>\n",
              "      <td>0.108891</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.372931</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.062085</td>\n",
              "      <td>0.360501</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.138369</td>\n",
              "      <td>0.123565</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.096134</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.319018</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.079687</td>\n",
              "      <td>0.326456</td>\n",
              "      <td>0.058839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.055999</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.170236</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.174820</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.376107</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.102025</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.275764</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.131590</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.310124</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.359586</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.360251</td>\n",
              "      <td>0.250554</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.392465</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.230344</td>\n",
              "      <td>0.380424</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.205342</td>\n",
              "      <td>0.135071</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.243898</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.386965</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.154782</td>\n",
              "      <td>0.360542</td>\n",
              "      <td>0.091839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.245567</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.072856</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.060956</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.093946</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.197336</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.236578</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.396827</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.113916</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.350694</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383865</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.445103</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.461537</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.368577</td>\n",
              "      <td>0.329032</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.350722</td>\n",
              "      <td>0.400347</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.317559</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.454911</td>\n",
              "      <td>0.378852</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.291897</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.301311</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105908</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.091875</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.224435</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440921</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.126838</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.417633</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.387685</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.462888</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.487033</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.396525</td>\n",
              "      <td>0.426920</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.431534</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.379694</td>\n",
              "      <td>0.446544</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.339287</td>\n",
              "      <td>0.158084</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.535561</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.456986</td>\n",
              "      <td>0.525753</td>\n",
              "      <td>0.304972</td>\n",
              "      <td>0.428715</td>\n",
              "      <td>0.362058</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.354599</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.138840</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.119930</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.125694</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.296143</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.360094</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.469429</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.127969</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.523828</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.458937</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.537448</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.498902</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.424473</td>\n",
              "      <td>0.478975</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.451068</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.474284</td>\n",
              "      <td>0.492741</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.406260</td>\n",
              "      <td>0.169591</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.667564</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.459062</td>\n",
              "      <td>0.538022</td>\n",
              "      <td>0.380066</td>\n",
              "      <td>0.462802</td>\n",
              "      <td>0.404369</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.694558</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.174313</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.135269</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.141568</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.367850</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.421852</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.541786</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       abandonnant  abandonné  ...  événementielle  événementiels\n",
              "count     1.000000   1.000000  ...        1.000000       1.000000\n",
              "mean      0.082296   0.096364  ...        0.594895       0.524093\n",
              "std            NaN        NaN  ...             NaN            NaN\n",
              "min       0.082296   0.096364  ...        0.594895       0.524093\n",
              "25%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "50%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "75%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "max       0.082296   0.096364  ...        0.594895       0.524093\n",
              "\n",
              "[8 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqOsQ-KppbNy"
      },
      "source": [
        "J'extraie la ligne des moyennes que je place dans une variable sous forme d'un tableau trié de manière descendante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SsMCyMEZa--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662a1c08-3ce4-4690-fc2a-f1ba2fbbe17b"
      },
      "source": [
        "tf_idf_mean = desc.iloc[1,:]\n",
        "mean_of_means = tf_idf_mean.sort_values(ascending=False).values\n",
        "mean_of_means"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88552986, 0.87503543, 0.85792386, ..., 0.04208241, 0.04208241,\n",
              "       0.04208241])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wGgunJlpzUq"
      },
      "source": [
        "La coupe se fait sur l'index de la partie entière du quart de la longueur du tableau, la valeur ext extraite dans une variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3Cd3s00Tnb",
        "outputId": "1dba7062-253b-4013-dc7e-78a1842dfa52"
      },
      "source": [
        "mean_of_means = mean_of_means[int(len(mean_of_means)*1/4)]\n",
        "mean_of_means"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4300170482020056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VVGbSoYqJIK"
      },
      "source": [
        "Les mots finaux sont ceux qui ont un score tfidf supérieur ou égale à la valeur discriminatoire déterminer plus tôt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L2UeAZL56A8E",
        "outputId": "722491c6-00f2-4a39-9816-13acc423fbd3"
      },
      "source": [
        "words = tf_idf_mean[tf_idf_mean >= mean_of_means].index\n",
        "words = pd.DataFrame(words)\n",
        "words = words.rename(columns={0:\"words\"})\n",
        "words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>able</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>actant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>activation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adapatabilité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>évolutivité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>évènements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>événement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>événementielle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>événementiels</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>751 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              words\n",
              "0              able\n",
              "1            actant\n",
              "2        activation\n",
              "3            active\n",
              "4     adapatabilité\n",
              "..              ...\n",
              "746     évolutivité\n",
              "747      évènements\n",
              "748       événement\n",
              "749  événementielle\n",
              "750   événementiels\n",
              "\n",
              "[751 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxYxZrCi20N1"
      },
      "source": [
        "J'épure le texte des mots d'arrêts déterminés par tfidf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKnNtPtIpQok",
        "outputId": "3c660ff8-62eb-456a-e29b-cab6517ba94c"
      },
      "source": [
        "final_text = [i for i in text if i in words.values]\n",
        "final_text[0:4]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['déplacer',\n",
              "  'pied',\n",
              "  'moyen',\n",
              "  'activité',\n",
              "  'humaine',\n",
              "  'courante',\n",
              "  'trouver',\n",
              "  'chemin',\n",
              "  'suppose',\n",
              "  'souvent',\n",
              "  'aide',\n",
              "  'type',\n",
              "  'verbal',\n",
              "  'description',\n",
              "  'itinéraire',\n",
              "  'iconique',\n",
              "  'croquis',\n",
              "  'carte',\n",
              "  'présentons',\n",
              "  'article',\n",
              "  'système',\n",
              "  'capable',\n",
              "  'produire',\n",
              "  'description',\n",
              "  'itinéraire',\n",
              "  'métro',\n",
              "  'générateur',\n",
              "  'fondé',\n",
              "  'cognitif',\n",
              "  'production',\n",
              "  'description',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'montrons',\n",
              "  'comment',\n",
              "  'facteur',\n",
              "  'importance',\n",
              "  'relative',\n",
              "  'information',\n",
              "  'choix',\n",
              "  'stylistique',\n",
              "  'peuvent',\n",
              "  'faire',\n",
              "  'varier',\n",
              "  'foi',\n",
              "  'contenu',\n",
              "  'forme',\n",
              "  'description',\n",
              "  'itinéraire'],\n",
              " ['expression',\n",
              "  'spatio',\n",
              "  'temporalité',\n",
              "  'traditionnellement',\n",
              "  'scindée',\n",
              "  'paradigme',\n",
              "  'localisation',\n",
              "  'déplacement',\n",
              "  'localisation',\n",
              "  'exprime',\n",
              "  'nombre',\n",
              "  'relation',\n",
              "  'entité',\n",
              "  'localiser',\n",
              "  'site',\n",
              "  'déplacement',\n",
              "  'exprime',\n",
              "  'changement',\n",
              "  'relation',\n",
              "  'temps',\n",
              "  'omettre',\n",
              "  'autonomie',\n",
              "  'richesse',\n",
              "  'déplacement',\n",
              "  'exprimer',\n",
              "  'rapport',\n",
              "  'localisation',\n",
              "  'opposer',\n",
              "  'paradigme',\n",
              "  'partagent',\n",
              "  'nombre',\n",
              "  'type',\n",
              "  'contrainte',\n",
              "  'topologie',\n",
              "  'distance',\n",
              "  'proposons',\n",
              "  'observer',\n",
              "  'domaine',\n",
              "  'spatio',\n",
              "  'temporel',\n",
              "  'articulation',\n",
              "  'façon',\n",
              "  'oppose',\n",
              "  'montre',\n",
              "  'contraire',\n",
              "  'partagent',\n",
              "  'travail',\n",
              "  'formalisation',\n",
              "  'analyse',\n",
              "  'destiné',\n",
              "  'élaboration',\n",
              "  'mécanisme',\n",
              "  'compréhension',\n",
              "  'automatique'],\n",
              " ['objectif',\n",
              "  'étude',\n",
              "  'concerne',\n",
              "  'traitement',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'système',\n",
              "  'reconnaissance',\n",
              "  'parole',\n",
              "  'exploitant',\n",
              "  'contrainte',\n",
              "  'accord',\n",
              "  'phrase',\n",
              "  'reconnaître',\n",
              "  'nombre',\n",
              "  'contrainte',\n",
              "  'peut',\n",
              "  'traité',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'portée',\n",
              "  'locale',\n",
              "  'type',\n",
              "  'gram',\n",
              "  'utilisés',\n",
              "  'habituellement',\n",
              "  'modèle',\n",
              "  'proposés',\n",
              "  'modèle',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'modèle',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'permettent',\n",
              "  'résoudre',\n",
              "  'homophonie',\n",
              "  'méthode',\n",
              "  'modèle',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'permet',\n",
              "  'introduire',\n",
              "  'contrainte',\n",
              "  'syntaxiques',\n",
              "  'modèle',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'objet',\n",
              "  'discriminer',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'manière',\n",
              "  'robuste',\n",
              "  'sensible',\n",
              "  'mauvais',\n",
              "  'reconnaissance',\n",
              "  'sein',\n",
              "  'phrase'],\n",
              " ['article',\n",
              "  'présente',\n",
              "  'identification',\n",
              "  'corpus',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'considérés',\n",
              "  'linguiste',\n",
              "  'hautement',\n",
              "  'dénominatifs',\n",
              "  'approche',\n",
              "  'utilise',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologique',\n",
              "  'applique',\n",
              "  'corpus',\n",
              "  'préalablement',\n",
              "  'étiqueté',\n",
              "  'lemmatisé',\n",
              "  'avoir',\n",
              "  'rappelé',\n",
              "  'propriété',\n",
              "  'linguistique',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'présenterons',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'modification',\n",
              "  'apportées',\n",
              "  'effectuer',\n",
              "  'identification',\n",
              "  'évaluerons',\n",
              "  'caractère',\n",
              "  'dénominatif',\n",
              "  'adjectif',\n",
              "  'terme',\n",
              "  'nominaux',\n",
              "  'apparaissent',\n",
              "  'comparant',\n",
              "  'thesaurus',\n",
              "  'conclurons',\n",
              "  'intérêt',\n",
              "  'adjectif',\n",
              "  'foi',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'problématique',\n",
              "  'extraction',\n",
              "  'connaissance',\n",
              "  'partir',\n",
              "  'corpus',\n",
              "  'mise',\n",
              "  'jour',\n",
              "  'thesaurus']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7M-PP9C-RWf",
        "outputId": "15ef15c0-e149-44fa-b968-1ad681431bde"
      },
      "source": [
        "doLDA(words.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.002*\"dicovalence\" + 0.002*\"répétés\" + 0.002*\"empiriques\" + 0.002*\"jeu\"'), (1, '0.002*\"négation\" + 0.002*\"world\" + 0.002*\"extension\" + 0.002*\"tourisme\"')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.ldamodel.LdaModel at 0x7efe0411d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALiHMVd2-Dq"
      },
      "source": [
        "Transformers est une librairie qui utilise huggingface dans un environnement pytorch et tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R02wjiLcH3y",
        "outputId": "180d8e42-22df-4b52-ca10-401e9ee9d3a8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fa8bb40f6fe39ec1b054ab2f2c4f2fbcf96ef36f59afdce5564b7e061e7e9f89\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_7wEr-e3IOL"
      },
      "source": [
        "T5-base est un modèle encodeur décodeur entrainé sur des articles de presse,  il est capable de faire des résumés en prédisant à partir d'une séquence de représentation vectorielle d'une chaine de caractère une autre chaine plus petite. Sa capacité d'entrée est limité à 512 vecteurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "8a7436a844814321bec9efa9e75dddee",
            "6597aae9b50540d591d327d811140fe6",
            "ed160c828f7a45a6a21f017a0d3ff2dd",
            "c3a9805861074e85935bdc96f27308b2",
            "d00200ac39344a45bb4b13627e2415f5",
            "092cd69131e94e01a33869984d252490",
            "bc338c906c874f06ae79f192002690d2",
            "5c5c44d482814afeb6646e29f67ec4bf",
            "c13a796deb324ee5ab0517cfd9a67504",
            "662cf31735914c66a58e446f42f33a44",
            "015a6f5cdd2b40779560d911ae011a5b",
            "cc598a4ab9954c10979dd8704c0c64fe",
            "acc88fb05ab04cf58bd75d98ac4399e5",
            "f9d3f0f543ac40929ad82574955fb23f",
            "5149f97423974c5faa37fb19ab5ad650",
            "f0bfd2a76bcb45fabddba532ec553ae9",
            "7460571df65d4f6d976e6ad48b63e04a",
            "9c448466034c433ea0866e952be3ccb5",
            "06dc4f869fad46aa938042f1de1b536a",
            "389fc01fc08c46e6b30b27a60b44ef79",
            "986812b32d65416ba26c688e3ecbbe72",
            "5bbcdb4bcaeb4f8f9fd8fd8718a596b4",
            "bea411c3581b4eabb275826ddb052f2a",
            "2283e7654ee24404a56299462250b25e",
            "2a9e88b138e140578d81958edd8987c8",
            "78d775a25b404be5a76bffa9a101cac6",
            "7bb99946316e45bea265e0ff1641f329",
            "e6103afe0cc5478aa35e4ad92271f8fa",
            "79110aefc6994d6c9fa8f31991b600e5",
            "f82d5814f7c0414cb114a278e45956a0",
            "65a942425ee24c30a4c8f2c2ce1615a9",
            "ba06178a696249aea502f550eda4aad8"
          ]
        },
        "id": "gxlI-JaEc7AH",
        "outputId": "80fdcee8-7a46-49b2-8db7-046bb94c38fa"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a7436a844814321bec9efa9e75dddee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c13a796deb324ee5ab0517cfd9a67504",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7460571df65d4f6d976e6ad48b63e04a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9e88b138e140578d81958edd8987c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMV4xwl3kqt"
      },
      "source": [
        "Avec cette fonction je transforme ma liste de résumé d'article du corpus en liste des résumés concaténés s'ils font moins de 512 mots ensemble.\n",
        "Ceux qui font plus de 512 mots sont ajoutés à la liste immédiatement, ils seront tronqué par le modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1JqHtF8Un5J"
      },
      "source": [
        "def Make_Data_For_T5(text_list,token_func):\n",
        "  text_for_model = []\n",
        "  holder = ''\n",
        "  for i in range(len(text_list)):\n",
        "    if len(token_func.encode(text_list[i]))>512:\n",
        "      text_for_model.append(text_list[i])\n",
        "    else:\n",
        "      if len(token_func.encode(holder))+len(token_func.encode(text_list[i]))>512:\n",
        "        text_for_model.append(holder)\n",
        "        holder = ''\n",
        "      else:\n",
        "        holder += text_list[i]\n",
        "  return text_for_model\n",
        "text_for_model = Make_Data_For_T5(abstracts,tokenizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Tl_EuhacQP",
        "outputId": "f46d48a6-db2d-4e89-b3b6-4068e09e0ac4"
      },
      "source": [
        "len(text_for_model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KaYX7oJXx6K"
      },
      "source": [
        "summaries = []\n",
        "for i in text_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOh-KjwraJ3k",
        "outputId": "de1ad2de-8b9a-43f6-e9dc-610e1e9c6fce"
      },
      "source": [
        "summaries_for_model = Make_Data_For_T5(summaries,tokenizer)\n",
        "summaries_for_model = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model[0:4]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' à en proposer des illustrations sous forme de séquences fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modèle de la Grammaire Applicative et Cognitive [DES 90] qui vise à \"expliquer\", à un certain niveau cognitif, les transferts entre représentations imagées et verbales.</s> d\\'analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un véritable formalisme linguistique. Nous présentons ici un aperçu du logiciel DECID développé au GETA afin d\\'informatiser le processus de rédaction du dictionnaire explicatif et combinatoire français contemporain.</s> dans le contexte des approches à base de grammaires faiblement sensibles au contexte, cette contribution passe en revue le problème de l\\'extraction de l\\'arbre d\\'analyse le plus probable au sens de Data-Oriented Parsing (DOP). Une démonstration formelle de l\\'utilisabilité des méthodes de Monte-Carlo est donnée, puis une technique d\\'échantillonnage contrôlée est développée per</s> l\\'ordre d\\'intervention de ces deux couches dans le processus d\\'analyse est déterminé par l\\'occurrence de marques de surface qui indiquent la présence d\\'une distorsion ou d\\'une construction particulière (interrogative, relative, etc.). La première version de l\\'analyseur nous a fourni des résultats encourageants qui nous invitent à reconsidérer le rôle et l\\'utilité des ressources linguistiques développées pour le traitement</s> reclasser les mots représentés sur la base de leurs contraintes syntaxiques-sémantiques ; il faut ensuite reclasser les mots représentés sur la base de leurs contraintes syntaxiques-sémantiques ; il faut ensuite reclasser ces mots sur la base de leurs contraintes syntaxiques-sémantiques.</s>',\n",
              " \" On parle souvent de chemins et de trajectoires, mais on ne les exprime pas dans le temps. La localisation exprime alors un certain nombre de relations entre une entité à localiser et des sites, tandis que le déplacement exprime un changement de ces relations dans le temps.</s> des données de grande taille. Nous présentons en détail la métrique Précision-Décision qui a été développée dans le cadre de GRACE pour mesurer quantitativement les performances des systèmes d'étiquetage.</s> linguistique informatique. une des recherches de pointe menées actuellement en informatique est l'extraction des connaissances dans un texte électronique (textual data mining). Nous présentons dans cet article un modèle hybride, à la fois robuste et fin, qui s'inspire des modèles neuronaux et de l'analyse linguistique informatique.</s> automatique de textes écrits.. un langage de représentation sémantico-cognitive des verbes. Cette communication décrit un outil informatique de construction et de consultation du lexique verbal. Cette communication ne présente pas de dictionnaire mais développe une méthodologie de construction et de consultation du lexique verbal.</s> les familles de mots morphologiquement reliés que nous avons obtenues sont correctes à 95 %. Nous proposons une méthode simple et puissante pour améliorer le processus d'acquisition automatique du langage médical.</s>. Or les cognats sont généralement captés au moyen d'une approximation abrupte, de nature opératoire. Nous avons ensuite essayé de développer un filtrage plus efficace, basé sur une méthode générale développée par nous.</s> d'une méthodologie précise. <unk> partir de l'arborescence sont constitués les groupes intonatifs, tout en tenant compte du rythme. Dans certains cas, des modifications de la structure syntaxique sont effectuées.</s>\",\n",
              " \" Nous présentons ici une implémentation de cette méthode de correction.Nous présentons dans ce document le problème de la détection et de la correction des graphies fautives dans les textes arabes. Nous présentons brièvement les principaux résultats obtenus à ce jour dans le cadre du projet MAREDI.</s> des connaissances langagières pré-codées. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux.Notre étude propose un modèle cohérent pour formaliser la modalité en tant que module interlingua d'un système de traduction automatique (TA).</s> une grammaire d'arbres adjoints compactée et sur la mise en concurrence des différentes hypothèses du système de reconnaissance de la parole. Nous présentons une stratégie d'analyse robuste dans le but de relayer la décision d'un système de reconnaissance de la parole.</s> n'est pas un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une pratique dans laquelle il faut tenir compte de plus en plus de chercheurs, qu'ils soient linguistes ou informaticiens.</s> sémantique. sémantique, il s'agit d'une requête orale. Si le dialogue est finalisé, cette requête nécessite une analyse linguistique plus fine que celle utilisée dans les applications classiques de CHM1.</s> grammaire, grammaire de propriétés, relation de dépendance, grammaire formelle, grammaire de dépendance, lexieparadigme d'évaluation, campagne d'évaluation, lexieparadigme d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation</s>\",\n",
              " \" syntaxique partielle, grammaires de dépendances, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de</s> langage stochastique. Les modèles de langage stochastiques favorisent l'interprétation d'un signal par les phrases les plus courtes possibles, celles-ci étant par construction souvent affectées par les coûts les plus bas.</s> il n'a jamais fait recette auprès des littéraires, des psycho-socios, des sémio-machins, des politiques et des pouvoirs académiques dont tout le monde a oublié sur quelles complicités exactes ils se fondaient. Il n'a jamais fait recette auprès des littéraires, des psycho-socios, des sémio-machins, des politiques et des pouvoirs </s> sémantique lexicaleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, S</s> linguistique. linguistique, sémantique, etc. Nous présentons dans cet article un cadre d'explication des relations entre les différentes composantes de l'analyse linguistique (prosodie, syntaxe, sémantique, etc.). Cette approche permet d'expliquer certains phénomènes de variabilité dans des applications comme les systèmes de synthèse de parole.</s>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ira5OwgF6KY2"
      },
      "source": [
        "Résumé des résumés concentré, ce qui donne un petit paragraphe résumant le document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACE1Jb4R4Mk8"
      },
      "source": [
        "summaries_for_model_summarized = []\n",
        "for i in summaries_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries_for_model_summarized.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn-iJxSS8Rii",
        "outputId": "b81ffff7-e2f3-4f20-e856-28f6f0829e66"
      },
      "source": [
        "summaries_for_model_summarized = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" dans le contexte d'approches linguistiques faiblement sensibles, cette contribution passe en revue le problème de l'extraction de l'arbre d'analyse linguistique.</s>\",\n",
              " \" d'une méthodologie de construction et de consultation du lexique verbal. Cette communication décrit en détail un outil informatique de construction et de consultation du lexique verbal. Cette méthodologie a été développée dans le cadre de GRACE.</s>\",\n",
              " \" n'est pas un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une méthode de correction linguistique plus fine que celle utilisée dans les applications classiques de CHM1.</s>\",\n",
              " \" linguistique, sémantique, etc.) n'a jamais fait recette auprès des littéraires, des psycho-socios, des politiques et des pouvoirs dont tout le monde a oublié sur quelles complices exactes ils se fondaient.</s>\",\n",
              " ' Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique.</s>',\n",
              " \" et d'intervalles (RCG)Traduction de dialogue, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage </s>\",\n",
              " ' orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique,</s>',\n",
              " ' ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par</s>',\n",
              " ' syntaxique, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, </s>',\n",
              " \", classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification syntaxique, évaluation automatique, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, </s>\",\n",
              " ', apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé</s>',\n",
              " ' linguistiques, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentalesÉtiqueteur, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales</s>',\n",
              " ', approche numérique, approche hybride, approche symbolique, approche numérique, approche hybride, approche numérique, approche hybride, approche symbolique, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche</s>',\n",
              " ' terminologie, traduction terminologique, traduction bilingue, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduc</s>',\n",
              " ', e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, </s>',\n",
              " \", Relation sémantique.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire</s>\",\n",
              " ' langue anglaise.Analyse de sentiment, dialecte tunisien, prétraitement de texte, entités nommées.Analyse de sentiment au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8FJBA2g_QOH"
      },
      "source": [
        "Ecriture des fichiers de résultats dans le stockage en ligne, pour conserver les résultats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCONf9D1HEW"
      },
      "source": [
        "MyFile=open('T5-base_summaries.txt','w')\n",
        "\n",
        "for element in summaries:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_model.txt','w')\n",
        "\n",
        "for element in summaries_for_model:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_summaries.txt','w')\n",
        "\n",
        "for element in summaries_for_model_summarized:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "!cp T5-base_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_model.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgogffNg_blg"
      },
      "source": [
        "J'ai essayé beaucoup de méthode, et regardé et lu beaucoup de document, notamment sur huggingface et transformers.\n",
        "J'ai préféré ces méthodes à celle de modèle keras avec des couches lstm car je n'étais vraiment pas convaincue par les performances de cette technique lors de la séance sur la génération de texte.\n",
        "La LDA ne fournissait pas également de résultat des plus explicites et pertinents à mon gout, j'ai donc délaisser ces méthodes pour la structure encodeur décodeur fourni par transformers.\n",
        "J'ai essayé d'utilisé un modèle prométeur par facebook, mais celui ne marchais pas, du fait du nom différent d'un attribut, la fonction generate ne pouvait récupérer l'encodeur du modèle ce qui provoquais une erreur arrétant l'éxecution du programme.\n",
        "\n",
        "\n",
        "\n",
        "La méthode que j'ai ici dévellopé consiste à résumer les résumés d'article concaténé pour ensuite concaténé et résumer à nouveau ces résumés.\n",
        "En ayant lû le contenu final, il touche bien aux différent principe du NLP et aborde les grands axes et les grandes méthodes de ce domaine, donnant un vue globale du contenu du corpus."
      ]
    }
  ]
}
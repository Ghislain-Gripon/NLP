{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a7436a844814321bec9efa9e75dddee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6597aae9b50540d591d327d811140fe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed160c828f7a45a6a21f017a0d3ff2dd",
              "IPY_MODEL_c3a9805861074e85935bdc96f27308b2"
            ]
          }
        },
        "6597aae9b50540d591d327d811140fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed160c828f7a45a6a21f017a0d3ff2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00200ac39344a45bb4b13627e2415f5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_092cd69131e94e01a33869984d252490"
          }
        },
        "c3a9805861074e85935bdc96f27308b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc338c906c874f06ae79f192002690d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:12&lt;00:00, 98.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c5c44d482814afeb6646e29f67ec4bf"
          }
        },
        "d00200ac39344a45bb4b13627e2415f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "092cd69131e94e01a33869984d252490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc338c906c874f06ae79f192002690d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c5c44d482814afeb6646e29f67ec4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c13a796deb324ee5ab0517cfd9a67504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_662cf31735914c66a58e446f42f33a44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_015a6f5cdd2b40779560d911ae011a5b",
              "IPY_MODEL_cc598a4ab9954c10979dd8704c0c64fe"
            ]
          }
        },
        "662cf31735914c66a58e446f42f33a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "015a6f5cdd2b40779560d911ae011a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acc88fb05ab04cf58bd75d98ac4399e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d3f0f543ac40929ad82574955fb23f"
          }
        },
        "cc598a4ab9954c10979dd8704c0c64fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5149f97423974c5faa37fb19ab5ad650",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:11&lt;00:00, 76.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0bfd2a76bcb45fabddba532ec553ae9"
          }
        },
        "acc88fb05ab04cf58bd75d98ac4399e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d3f0f543ac40929ad82574955fb23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5149f97423974c5faa37fb19ab5ad650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0bfd2a76bcb45fabddba532ec553ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7460571df65d4f6d976e6ad48b63e04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c448466034c433ea0866e952be3ccb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06dc4f869fad46aa938042f1de1b536a",
              "IPY_MODEL_389fc01fc08c46e6b30b27a60b44ef79"
            ]
          }
        },
        "9c448466034c433ea0866e952be3ccb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06dc4f869fad46aa938042f1de1b536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_986812b32d65416ba26c688e3ecbbe72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bbcdb4bcaeb4f8f9fd8fd8718a596b4"
          }
        },
        "389fc01fc08c46e6b30b27a60b44ef79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bea411c3581b4eabb275826ddb052f2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:03&lt;00:00, 257kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2283e7654ee24404a56299462250b25e"
          }
        },
        "986812b32d65416ba26c688e3ecbbe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bbcdb4bcaeb4f8f9fd8fd8718a596b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea411c3581b4eabb275826ddb052f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2283e7654ee24404a56299462250b25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9e88b138e140578d81958edd8987c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78d775a25b404be5a76bffa9a101cac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bb99946316e45bea265e0ff1641f329",
              "IPY_MODEL_e6103afe0cc5478aa35e4ad92271f8fa"
            ]
          }
        },
        "78d775a25b404be5a76bffa9a101cac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bb99946316e45bea265e0ff1641f329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79110aefc6994d6c9fa8f31991b600e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f82d5814f7c0414cb114a278e45956a0"
          }
        },
        "e6103afe0cc5478aa35e4ad92271f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65a942425ee24c30a4c8f2c2ce1615a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:02&lt;00:00, 470kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba06178a696249aea502f550eda4aad8"
          }
        },
        "79110aefc6994d6c9fa8f31991b600e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f82d5814f7c0414cb114a278e45956a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65a942425ee24c30a4c8f2c2ce1615a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba06178a696249aea502f550eda4aad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUNiu36r0au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396c89db-473d-4c80-ae39-0a8d15eb0c32"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq4hrow7mo4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1af92456-975f-456a-aec1-dbf2da384a9b"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tree = ET.parse(\"/content/drive/MyDrive/datasets/NLP/corpus_taln_v1.tei.xml\") #L'XML du corpus taln est à insérer ici.\n",
        "root = tree.getroot()\n",
        "ns = re.findall(\"{.*}\", root.tag)[0] #Le nom de domaine XML du corpus.\n",
        "ns \n",
        "# {http://www.tei-c.org/ns/1.0}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{http://www.tei-c.org/ns/1.0}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACeRMuSyAjpj"
      },
      "source": [
        "Dans la fonction get_abstracts j'utilise la librairie xml elementtree comme conseillé dans le sujet du projet 1 pour :\n",
        "\n",
        "1.   itérer sur les balises des articles \"TEI\" qui contiennent dans leur attribut de valise le mot clé \"fr\" qui signifie que l'article est en français,\n",
        "\n",
        "2.   naviguer à la balise div de l'entête de l'article qui contient les résumés dont je récupère la version en français si elle existe et est différente de \"None\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcG_YlEUI0ci"
      },
      "source": [
        "def Get_Abstracts(tree, size=None):\n",
        "  abstract = []\n",
        "  text = ''\n",
        "  tei = root.iter(ns+\"TEI\") #Itérateur sur les balises 'TEI' qui correspondent aux articles.\n",
        "  if size == None:\n",
        "    size = root.iter(ns+\"TEI\")\n",
        "  else:\n",
        "    size = range(size)\n",
        "  for i in size:\n",
        "    try:\n",
        "      x = tei.__next__()\n",
        "      if any(\"fr\" in s for s in x.attrib.values()):\n",
        "        for y in x.iter(ns+\"div\"):\n",
        "          if any(\"fr\" in s for s in y.attrib.values()):\n",
        "            for p in y.iter(ns+\"p\"):\n",
        "              if p.text != \"None\":\n",
        "                text = p.text.strip().replace('\\n\\t','') #Nettoyage de ce qui déborde dans les abstracts avec la fonction strip() et effacement des caractères de saut à la ligne présent dans la chaine de caractère brute.\n",
        "        if len(text) != 0:\n",
        "          abstract.append(text)\n",
        "    except:\n",
        "      break\n",
        "  return abstract"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_TiOui8L-p",
        "outputId": "5a878adb-d64c-4757-f22c-eabcc1fbca1d"
      },
      "source": [
        "abstracts = Get_Abstracts(root)\n",
        "abstracts"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nous considérons dans notre travail la tâche du traitement automatique visant à construire, à partir de textes issus d\\'un corpus de constats d\\'accidents de la route, des interprétations compatibles avec ces derniers, et à en proposer des illustrations sous forme de séquences d\\'images fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modèle de la Grammaire Applicative et Cognitive [DES 90], qui vise en particulier à \"expliquer\", à un certain niveau cognitif, les transferts entre représentations imagées et verbales. Pour une revue de la question relative à la \"transcription automatique Verbal-Image\", nous renvoyons à [ARN 90] ; et plus particulièrement aux travaux de C. Vandeloise [VAN 87] et du groupe \"Langue, Raisonnement, Calcul\" de l\\'Université Paul Sabatier [AUR 90, SAB 95] ainsi qu\\'aux approches proposées dans [ARN 93] et dans le système SPRINT [YAM 92]. Plus proches encore de nos préoccupations, B. Victorri et P. Enjalbert [ENJ 94, POI 95] posent le problème de l\\'animation visuelle issue de l\\'interprétation de textes. Nous présentons dans cet article, à travers le traitement d\\'un exemple, la méthode générale d\\'analyse que nous avons adoptée, qui s\\'appuie en priorité sur des connaissances linguistiques. Le texte pris comme exemple est le suivant : Je roulais sur la partie droite de la chaussée quand un véhicule arrivant dans le virage a été complètement déporté. Serrant à droite au maximum, je n\\'ai [pu] éviter la voiture [qui arrivait à grande vitesse]. Nous ne traitons pas ici la modalité introduite par pu , de même que la relative qui arrivait à grande vitesse. Dans la première partie de l\\'article, nous présentons l\\'architecture globale du système informatique. Dans la deuxième partie, nous proposons des éléments d\\'analyse pour une solution opératoire aux problèmes d\\'articulation des significations lexicales et grammaticales, sous forme d\\'une segmentation du texte en différentes phases spatio-temporelles. Dans la troisième partie, nous présentons une modélisation des lieux de circulation et du mouvement des véhicules garantissant le passage à l\\'image.',\n",
              " \"Nous donnons ici un aperçu du logiciel DECID développé au GETA afin d'informatiser le processus de rédaction du dictionnaire explicatif et combinatoire du français contemporain.\",\n",
              " 'Diverses méthodes ont été proposées pour construire un \"graphe conceptuel\" représentant le \"sens\" d\\'une phrase à partir de son analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un véritable formalisme linguistique. Nous nous intéressons ici à la construction d\\'une telle représentation sémantique à partir de la représentation syntaxique produite par une analyse LFG, et montrons comment une transposition du \"joint dirigé\" des graphes conceptuels permet d\\'effectuer cette construction à partir de la \"structure sémantique \"des LFG.',\n",
              " \"Le terme de lambda-DRT désigne un ensemble de méthodes permettant de construire des représentations sémantiques (DRS) à partir d'arbres syntaxiques. La mise en oeuvre de telles méthodes nécessite l'élaboration de systèmes de types dont le détail est rarement présenté. C'est à la description d'un tel système que cet article est consacré.\",\n",
              " \"Dans cet article, nous comparons deux modèles linguistiques utilisés en TAL, les grammaires d'arbres adjoints [= TAG] et le Théorie Sens-Texte [= TST]. Nous montrons que ces deux modèles présentent des similitudes notables, et que les représentations les plus abstraites qu'ils donnent d'une phrase — la représentation sémantique en TST et l'arbre de dérivation en TAG — sont équivalentes. De ce rapprochement découle d'une part que l'on peut s'inspirer de la procédure de dérivation TAG pour opérer la correspondance Sens-Texte, et d'autre part que l'on peut concevoir une grammaire TAG comme le résultat de la précompilation d'une grammaire Sens-Texte.\",\n",
              " \"Dans le cadre des approches à base de grammaires faiblement sensibles au contexte, cette contribution passe en revue le problème de l'extraction de l'arbre d'analyse le plus probable dans le modèle du Data-Oriented Parsing (DOP). Une démonstration formelle de l'utilisabilité des méthodes de Monte-Carlo est donnée, puis une technique d'échantillonnage contrôlée est développée permettant de garantir (avec un certain seuil de confiance fixé a priori) que l'arbre d'analyse sélectionné est bien l'arbre d'analyse le plus probable au sens de DOP. plus probable au sens de DOP.\",\n",
              " \"Dans cet article, nous proposons de prendre du recul par rapport à l'aspect opératoire du tagging, et nous tentons de montrer que le tagging ouvre la voie au renouveau de l'analyse syntaxique en la fondant sur l'explicitation des processus: processus de déduction locale dans les syntagmes non récursifs, et processus de mise en relation des syntagmes non récursifs, étendant ainsi à l'analyse syntaxique les propriétés calculatoires du tagging.\",\n",
              " 'Nous décrivons dans cet article un système d\\'extraction automatique de réponses. L\\'extraction automatique de réponses (EAR) a pour but de trouver les passages d\\'un document qui répondent directement à une question posée par un utilisateur. L\\'EAR est plus ambitieuse que la recherche d\\'informations et l\\'extraction d\\'informations dans le sens que les résultats de la recherche sont des phrases et non pas des documents en entier, et dans le sens que les questions peuvent être formulées de façon libre. Elle est par contre moins ambitieuse que les systèmes questions-réponses car les réponses ne sont pas générées à partir d\\'une base de connaissance, mais repérées dans les textes des documents. La version actuelle d\\'ExtrAns permet d\\'analyser la documentation en ligne (en Anglais) du système Unix (les \"man pages\"), et de construire une représentation sémantique (sous forme d\\'expressions logiques) des phrases. Un programme de démonstration de théorèmes trouve ensuite les passages pertinents qui sont mis en évidence dans leur contexte.',\n",
              " 'L\\'analyseur syntaxique robuste que nous décrivons dans cet article s\\'insère dans le cadre des travaux relatifs au traitement du langage oral. Nous montrons à partir d\\'une étude menée sur des dialogues transcrits qu\\'il est avantageux de traiter le langage oral avec un analyseur syntaxique robuste faisant appel à un analyseur syntaxique conçu pour l\\'écrit. Pour ce faire, nous avons réalisé un système qui se base sur une architecture à deux couches : le noyau et la périphérie, l\\'une interagissant avec l\\'autre via un superviseur. La première couche, le noyau, est dédiée à l\\'analyse des constituants d\\'énoncés respectant la grammaire standard : c\\'est un analyseur syntaxique de l\\'écrit. La deuxième couche, la périphérie, se charge de \"corriger\" les constituants de l\\'énoncé oral ayant subis des distorsions. Cette couche intervient lorsque le noyau ne parvient plus à progresser dans son analyse. L\\'ordre d\\'intervention de ces deux couches dans le processus d\\'analyse est déterminé par l\\'occurrence de marques de surface qui signalent la présence d\\'une distorsion ou d\\'une construction particulière (interrogative, relative, etc.). Le système ainsi conçu nous a permis de traiter les bruits et différents types de répétitions caractéristiques de l\\'oral. La première version de l\\'analyseur nous a fourni des résultats encourageants qui nous permettent de confirmer l\\'interdépendance entre le traitement du langage oral et le traitement du langage écrit. Ces résultats nous invitent aussi à reconsidérer le rôle et l\\'utilité, pour le traitement de l\\'oral, des ressources d\\'informatique linguistique développées pour l\\'écrit.',\n",
              " \"Les sorties parlées d'un système de dialogue homme-machine sont souvent d'une qualité médiocre pour deux raisons : le texte généré par le générateur ne tient souvent pas compte de l'usager et la synthèse de la parole à partir de ce texte, donne souvent une prosodie de lecture. L'article décrit les principes d'introduction d'une composante pragmatique en amont du système de génération afin de tenir compte des degrés de force et des buts illocutoires. En effet, les études en génération portent généralement sur les réalisations linguistiques du contenu propositionnel de la réponse (c'est-à-dire le sujet du message) mais très rarement sur la constitution de l'acte énonciatif qui est généralement abandonnée au moteur de dialogue de l'application. Nous développons cet aspect au coeur même de la génération afin de fournir un outil performant et surtout pour prendre en compte les aspects pragmatiques de manière précoce dans le dialogue. La conclusion est que notre système, grâce à son module de traitement pragmatique, a la capacité de générer des énoncés plus naturels. La génération est basée non plus sur le contenu informatif seul, mais aussi sur une situation pragmatique, exprimée dans un cadre bien défini. Notre approche montre l'intérêt de prendre en compte les paramètres illocutoires dans le cadre du dialogue.\",\n",
              " \"Nous présentons ici le dispositif GASPAR qui construit des représentations des mots sous la forme d'objets informatiques appelés des prototypes ; GASPAR associe à ces objets les comportements syntaxiques et sémantiques des mots en prenant appui sur des informations extraites à partir d'un corpus. GASPAR a pour première tâche de construire progressivement une représentation informatique des mots, sans présumer de leurs descriptions linguistiques ; il doit ensuite reclasser les mots représentés et mettre au jour, de manière inductive, les classes de mots du sous-langage étudié. Nous montrons comment la programmation à prototypes permet de représenter des mots dynamiquement par apprentissage et par affinements successifs. Elle permet ensuite d'amorcer un début de classement de ces mots sur la base de leurs contraintes syntaxico-sémantiques en construisant des hiérarchies locales de comportements partagés.\",\n",
              " \"Se déplacer à pied ou par un autre moyen est une activité humaine courante. Cependant, trouver son chemin suppose souvent des aides de type verbal (descriptions d'itinéraires) ou iconique\\n(croquis, cartes). Nous présentons dans cet article un système capable de produire des descriptions d'itinéraires en métro. Notre générateur est fondé sur un mod èle cognitif de la production de telles descriptions et sur une analyse de corpus. Nous montrons comment des facteurs\\ncomme l'importance relative d'informations et les choix stylistiques peuvent faire varier à la\\nfois le contenu et la forme de la description d'un itinéraire.\",\n",
              " \"Les outils d'aide à la construction de terminologie à partir de corpus ont connu un essor important ces dernières années. D'un autre côté, les outils d'aide à l'acquisition de relations sémantiques entre termes sont peu nombreux. Face à ce problème, nous avons développé le système Prométhée qui acquière incrémentalement un ensemble de patrons lexico-syntaxiques caractéristiques d'une relation sémantique. Ainsi, pour la relation d'hyponymie, Prométhée a extrait un ensemble de patrons qui servent à améliorer la couverture d'un thesaurus ou d'une base de connaissances.\",\n",
              " \"Cet article présente une chaîne de traitement automatique réalisée dans le cadre du projet ILIAD (Informatique Linguistique et Infométrie pour l'Analyse de grands fonds Docu-mentaires) du GIS Sciences de la Cognition. Cette chaˆine est dédiée à l'analyse de l'infor-mation à partir de corpus de textes de très grand volume, en français. Elle est expérimentée sur un corpus de 2,5 Mb et a conduit à la création de 50 classes de termes. Ces classes sont construites sur la base de la co-occurrence des termes et représentent des connaissances du do-maine. Les différentes étapes de la chaˆine associent des méthodes linguistiques informatiques et des méthodes statistiques : pré-traitement des textes, étiquetage, morphologie, terminologie et analyse des documents. Pour chacune d'entre elles, nous présentons les méthodes, les outils ainsi que leur evaluation.\",\n",
              " \"Dans le domaine de l'ingénierie linguistique et de la connaissance, le problème des ressources lexicales et linguistiques s'est toujours posé. Néanmoins, l'avancée des techniques du Traitement Automatique des Langues Naturelles (TALN) l'a rendu plus sensible. Il nous faut maintenant pouvoir répondre à des besoins importants en terme de quantité, de qualité et de complexité. La complexité et la diversité des informations requises augmente avec les exigences des outils de TALN ainsi qu'avec le développement de nouvelles applications (humaines ou machinales). Si la récupération (semi)automatique d'information lexicale est une piste, elle ne pourra remplacer la création manuelle de dictionnaires. Nous nous sommes donc intéressés à la construction d'outils pour lexicographes et lexicologues. pour répondre aux besoins de nos systèmes de traduction et à la demande du projet Universal Networking Language (UNL), nous avons décidé d'informatiser la construction d'une base lexicale multi-lingue. Dans ce but, nous avons fusionné des dictionnaires existants. A partir de ces données, nous générons automatiquement des fichiers qui sont envoyés aux lexicographes. Ceux-ci complètent et corrigent les données sur leur plate-forme avec des outils très simples. Les fichiers sont ensuite réintégrés dans la base lexicale. La dernière étape est la génération de dictionnaires nécessaires à nos systèmes de traduction.\",\n",
              " \"Le traitement de la sémantique de la spatialité nécessite de manipuler des entités qu'il n'est pas aisé de définir. On parle souvent de lieux, mais on les assimile trop à un sens hors contexte des mots désignant des objets ; on évoque les notions de routine et de trajectoire, mais elles ne sont pas réellement intégrées au calcul du sens. Nous discutons dans cet article de la façon d'intégrer ces référents spatiaux à un traitement automatique, et nous focalisons en particulier sur la richesse que recèlent les chemins et les trajectoires dans l'expression du déplacement lorsqu'un formalisme leur donne existence.\",\n",
              " \"L'expression de la spatio-temporalité est traditionnellement scindée en deux paradigmes, la localisation et le déplacement. La localisation exprime alors un certain nombre de relations entre une entité à localiser et des sites, tandis que le déplacement exprime un changement de ces relations dans le temps. Pourtant, c'est omettre l'autonomie et la richesse du déplacement que de l'exprimer par rapport à la localisation, et c'est aussi opposer deux paradigmes qui partagent un certain nombre de types de contraintes (topologie, distance, etc.). Nous proposons donc d'observer le domaine spatio-temporel et ses articulations d'une façon qui ne les oppose pas mais qui montre au contraire ce qu'ils partagent. Ce travail de formalisation et d'analyse est destiné à l'élaboration de mécanismes de compréhension automatique.\",\n",
              " \"Cet article présente la démarche suivie pour mettre en place un logiciel d'aide à la veille technologique. Pour l'analyse de documents très techniques, les veilleurs utilisent des outils d'infométrie, qui sont pertinents sur les données structurées, mais qui ne sont pas adaptés pour l'exploitation des informations textuelles. Nous avons donc réalisé un logiciel d'extraction d'informations, nommé VIGITEXT. Notre approche, basée sur la définition de notions indépendantes du domaine comme l'/amélioration/, l'/augmentation/ ou l'/utilisation/, permet d'extraire des informations textuelles à partir d'abrégés descriptifs de brevets rédigés en anglais sans utiliser de lexique technique ou de calculs statistiques. De plus, cette méthode est opérationnelle pour tous les sujets de veille, et les résultats, qui sont les extraits organisés selon les notions, sont simples à utiliser par des veilleurs. Dans cet article, nous décrivons les particularités de la veille technologique, et les limites des logiciels généralement utilisés. Ensuite, nous détaillons l'exploitation de notions générales basée sur la définition de connaissances linguistiques et qui met en oeuvre la méthode d'exploration contextuelle. Nous présentons enfin le prototype VIGITEXT, avec ses spécificités et ses utilisations possibles dans une démarche de veille.\",\n",
              " \"L'action GRACE est le premier exemple d'application du paradigme d'évaluation aux étiqueteurs morpho-syntaxiques pour le français dans le cadre d'une campagne d'évaluation formelle, à participation ouverte et utilisant des données de grande taille. Après une rapide description de l'organisation et du déroulement de l'action ainsi que des problèmes posés par la nécessaire mise en place d'un référentiel commun pour l'évaluation, nous présenterons en détail la métrique Précision-Décision qui a été développée dans le cadre de GRACE pour la mesure quantitative des performances des systèmes d'étiquetage. Nous nous intéresserons ensuite aux résultats obtenus pour les participants à la phase de test de la campagne et indiquerons les aspects du protocole d'évaluation qui restent encore à valider sur les données recueillies. Enfin, nous conclurons en soulignant les incidences positives d'une campagne d'évaluation comme GRACE sur le domaine de l'ingénierie linguistique.\",\n",
              " \"L'objectif de cette étude concerne le traitement d'homophones singulier/pluriel dans un Système de Reconnaissance de la Parole en exploitant les contraintes d'accord dans la phrase à reconnaître. Un certain nombre de ces contraintes ne peut être traité par les modèles de langage à portée locale de type n-gram utilisés habituellement. Les deux modèles proposés, le modèle à base de syntagme et le modèle Homophone-Cache, permettent de résoudre certains cas d'homophonie par deux méthodes différentes : le modèle à base de syntagme permet d'introduire des contraintes syntaxiques ; le modèle Homophone-Cache a pour objet de discriminer les homophones singulier/pluriel, de manière robuste, en étant peu sensible à la mauvaise reconnaissance d'un mot au sein de la phrase.\",\n",
              " \"Nous présentons dans cet article une nouvelle approche, que nous appelons 5P, permettant la description des propriétés d'un langage et son utilisation pour une analyse automatique. Nous montrons comment cette approche permet la prise en compte de la dimension descriptive de la linguistique. Par ailleurs, nous présentons une technique d'analyse, appelée analyse par Filtrage et Fusion, qui tire parti de cette description en propriétés. Nous montrons en quoi ces deux projets (description d'une langue et analyse automatique) convergent et ouvrent de nouvelles perspectives.\",\n",
              " \"Une des recherches de pointe menée actuellement en informatique est l'extraction des connaissances dans un texte électronique (textual data mining). Ce thème de recherche est de première importance pour les technologies de l'information qui sont confrontées à des marées de documents électroniques. Pour résoudre ce problème, plusieurs stratégies sont possibles : les unes relèvent des mathématiques et les autres de l'informatique linguistique. Nous présentons dans cet article un modèle hybride, à la fois robuste et fin, qui s'inspire des modèles neuronaux et de l'analyse linguistique informatique.\",\n",
              " \"interrogation de base de données, langage naturel, opérateurs linguistiques, transducteur (automate à nombre fini d'états)\",\n",
              " \"interrogation de base de données, langage naturel, opérateurs linguistiques, transducteur (automate à nombre fini d'états)\",\n",
              " \"Cet article présente l'identification en corpus des adjectifs relationnels considérés par les linguistes comme hautement dénominatifs. Notre approche utilise un programme d'extraction terminologique qui s'applique sur un corpus préalablement étiqueté et lemmatisé. Après avoir rappelé quelques propriétés linguistiques des adjectifs relationnels, nous présenterons le programme d'extraction de terminologie et les modifications apportées à celui-ci pour effectuer cette identification. Nous évaluerons le caractère dénominatif de ces adjectifs et des termes nominaux où ils apparaissent en les comparant à un thesaurus. Nous conclurons sur l'intérêt de ces adjectifs à la fois pour l'extraction de terminologie mais aussi pour d'autres problématiques comme l'extraction de connaissances à partir de corpus ou la mise à jour d'un thesaurus.\",\n",
              " \"Cette communication décrit un outil informatique de construction et de consultation d'un lexique verbal saisi sur des supports informatiques en vue d'une utilisation par des linguistes et qui peut être appelé à certaines étapes d'un traitement automatique de textes écrits. L'analyse du lexique verbal s'inscrit dans un modèle, celui de la Grammaire Applicative et Cognitive (GAC) développé dans l'équipe LaLIC. Le formalisme utilisé est celui du \\U00100068-calcul typé et de la logique combinatoire typée avec ses combinateurs. Le lexique verbal est organisé à l'aide d'un langage de représentation sémantico-cognitif (LRSC) s'appuyant sur un ensemble de relateurs et de primitives sémantico-cognitives typées. Dans un premier temps nous présentons un outil informatique (DISCC) qui a pour tâche d'aider un sémanticien à construire des représentations sémantico-cognitives associées aux significations des verbes; et dans un second temps, nous montrons comment il est possible de consulter les différentes significations d'un vocable verbal polysémique représenté sous forme d'un réseau. La présentation ne présente pas un dictionnaire mais développe une méthodologie de construction et de manipulation d'une base de connaissances sémantico-cognitives des verbes.\",\n",
              " \"Cette communication décrit un outil informatique de construction et de consultation d'un lexique verbal saisi sur des supports informatiques en vue d'une utilisation par des linguistes et qui peut être appelé à certaines étapes d'un traitement automatique de textes écrits. L'analyse du lexique verbal s'inscrit dans un modèle, celui de la Grammaire Applicative et Cognitive (GAC) développé dans l'équipe LaLIC. Le formalisme utilisé est celui du \\U00100068-calcul typé et de la logique combinatoire typée avec ses combinateurs. Le lexique verbal est organisé à l'aide d'un langage de représentation sémantico-cognitif (LRSC) s'appuyant sur un ensemble de relateurs et de primitives sémantico-cognitives typées. Dans un premier temps nous présentons un outil informatique (DISCC) qui a pour tâche d'aider un sémanticien à construire des représentations sémantico-cognitives associées aux significations des verbes; et dans un second temps, nous montrons comment il est possible de consulter les différentes significations d'un vocable verbal polysémique représenté sous forme d'un réseau. La présentation ne présente pas un dictionnaire mais développe une méthodologie de construction et de manipulation d'une base de connaissances sémantico-cognitives des verbes.\",\n",
              " 'sémantique lexicale, prédicats, lexique génératif',\n",
              " \"En synthèse automatique de la parole, la phonétisation est une étape cruciale pour une bonne intelligibilité et une bonne qualité de voix. Elle consiste à convertir une suite de mots en chaîne phonétique, qui sera par la suite utilisée pour générer le signal sonore. Les homographes hétérophones et les ajustements phonologiques tels que la liaison et l'élision sont les sources d'erreurs les plus courantes. De plus, des mots comme 'plus' , 'tous' et certains nombres ('cinq', 'six', 'dix',…) pour lesquels plusieurs réalisations phonétiques sont possibles, peuvent également être problématiques. Nous proposons ici une résolution de ces cas complexes par l'utilisation d'une analyse syntaxique.\",\n",
              " \"La morphologie médicale est riche et productive. À côté de la simple flexion, dérivation et composition sont d'autres moyens pour créer des mots nouveaux. La connaissance morphologique se révèle par conséquent très importante pour toute application dans le traitement automatique du langage médical. Nous proposons une méthode simple et puissante pour l'acquisition automatique d'une telle connaissance. Cette méthode tire avantage de listes de termes synonymes disponibles afin d'amorcer le processus d'acquisition. Nous l'avons expérimentée dans le domaine médical sur le Microglossaire de Pathologie SNOMED. Les familles de mots morphologiquement reliés que nous avons obtenues sont correctes à 95 %.Utilisées dans un outil d'aide au codage avec expansion de requête, elles permettent d'en améliorer les performances.\",\n",
              " \"Le traitement automatique du langage requiert des corpus textuels de plus en plus volumineux, entre autres pour les étiqueteurs morpho-syntaxiques. Ces processus de traitement ne sont pas exempts d'erreurs. Dans l'optique d'améliorer cet étiquetage de corpus hétérogènes (composés de textes tout-venant), une approche adaptative au type de texte utilisant les ressources produites par une campagne d'évaluation sera proposée. Les résultats d'une première validation seront présentés sur les données MULTITAG. Les faits suivants sont constatés : les textes ne sont pas homogènes en terme de distribution de parties du discours, les classifications a priori ne fournissent pas une homogénéité en terme de performance et un même texte peut produire des variations positives pour un système et négatives pour un autre. De plus, il existe une relation entre la typologie de textes obtenue de façon non supervisée sur le jeu de caractères et les variations de performance.\",\n",
              " 'Depuis [Kimball 73], les préférences d\\'attachement telles que \"l\\'association droite\" et \"l\\'attachement minimal\" ont essentiellement été formulées en termes d\\'arbres de constituants (e.g. forme, nombre de noeuds ...) . Nous présentons 2 principes de préférence d\\'attachement formulés en termes d\\'arbres de dérivation (i.e. d\\'information dépendancielle) dans le cadre du formalisme des Grammaires d\\'Arbres Adjoints Lexicalisées (LTAG) . Nous montrons pourquoi ce type d\\'approche permet de remédier aux défauts des approches structurales exprimées en termes d\\'arbres de constituants et rendent compte d\\'heuristiques largement acceptées (i.e. argument / modifieur, idiomes).',\n",
              " \"Nous nous intéressons ici aux méthodes d'alignement automatique destinées à produire des corpus bi-textuels, utiles au traducteur, au terminologue ou au linguistique. Certaines techniques ont obtenu des résultats probants en s'appuyant sur la détermination empirique des « cognats » (de l'anglais « cognate »), des mots qui se traduisent l'un par l'autre et qui présentent une ressemblance graphique. Or les cognats sont généralement captés au moyen d'une approximation abrupte, de nature opératoire : on considère tous les 4-grammes (mots possédants 4 lettres en commun) comme cognats potentiels. Aucune étude n'a été faite, à notre connaissance, à propos de la validité de cette approximation. Afin d'en démontrer les possibilités et les limites, nous avons cherché à déterminer empiriquement la qualité de cette simplification, en termes de bruit et de silence (ou de manière complémentaire, de précision et de rappel). Nous avons ensuite essayé de développer un filtrage plus efficace, basé sur l'utilisation des sous-chaînes maximales. Enfin, nous avons corrélé les améliorations du filtrage avec les résultats de l'alignement, en nous basant sur une méthode générale développée par nous : nous avons pu constater un net progrès en terme de rappel et de précision de l'alignement.\",\n",
              " \"Nous présentons une technique de résolution de proformes enchâssées à l'aide des méta-structures Prolog. Nous montrons tout d'abord un exemple d'utilisation de ces méta-structures pour contrôler l'appartenance d'un élément à un domaine. Une plus grande utilité est ensuite démontrée dans la résolution de contraintes contextuelles dynamiques, qui sont particulières dans le sens où elles interviennent en fonction des contraintes déjà existantes sur les éléments considérés. Une application utile de ces contraintes est d'éviter les redondances dans la recherche des possibilités de référents pour un discours considéré, notamment dans le cas de proformes enchâssées.\",\n",
              " \"Nous présentons un système dédié à la conception et au test d'un sous-language d'application pour un système de Dialogue Homme-Machine. EGAL se base sur une grammaire LTAG générale de la langue qui est spécialisée à une application donnée à l'aide d'un corpus d'entraînement. Un double effort a porté premièrement sur la définition d'une méthodologie précise passant par une expérimentation de type Magicien d'Oz pour le recueil des corpus et des estimations de la représentativité du corpus de conception, et, deuxièmement, sur la spécification des composants du système en vue de mettre en oeuvre des outils convivaux, génériques et ouverts.\",\n",
              " \"L'article décrit l'implémentation d'un modèle d'intonation dans son application à la synthèse de la parole pour le français. Le modèle se caractérise par l'importance accordée à la syntaxe et par une approche analytique de l'intonation qui, en synthèse, permet une manipulation explicite et compositionnelle du sens intonatif. Le traitement proprement dit est précédé d'une analyse syntaxique identifiant les constituants, certains rapports de dépendance ou certaines constructions qui demandent une intonation particulière. Ces aspects intonatifs sont représentés par des marqueurs symboliques. À partir de l'arborescence sont constitués les groupes intonatifs, tout en tenant compte du rythme. Dans certaines conditions, des réajustements de la structure syntaxique seront effectués. Les tons mélodiques sont attribués aux groupes en fonction des marqueurs et des rapports syntaxiques.\",\n",
              " 'Inférence grammaticale régulière, analyse corrective, évaluation du modèle de language',\n",
              " \"Cet article présente les avantages qu'apporte la modélisation des ressources linguistiques utilisées dans une application. Le lecteur trouvera également dans cet article une présentation rapide de deux méthodes répandues dans le monde de l'informatique (Merise et UML) et leur modèle associé (entité relation et objet). Enfin, nous donnerons un exemple de modélisation des ressources linguistiques d'une application en cours de développement.\",\n",
              " \"Quels types d'informations sont nécessaires à l'interprétation de référents évolutifs et de référents associés ? Nous verrons que les anaphores évolutives et associatives sont construites à partir de processus et de situations, et que leur interprétation nécessite une représentation lexicale complexe. Les approches atomiques peuvent par conséquent difficilement rendre compte de ce type d'anaphores : cependant les propriétés des quantificateurs semblent jouer un rôle dans ces phénomènes.\",\n",
              " \"Dans cet article, nous montrons, à travers l'exposé de résultats d'une expérience menée sur corpus, comment la connaissance des thèmes dans lesquels apparaissent des mots et la mise en évidence de similarités et de différences entre les voisinages de leurs occurrences dans les parties de textes abordant ces thèmes permettent de mettre au jour des différences fines dans les acceptions associées aux mots dans chacun de ces thèmes. La méthode proposée pour ce faire est presque entièrement automatique et est basée sur le calcul d'intersections et de différences ensemblistes entre des séquences de mots constituant des contextes.\",\n",
              " \"A des fins d'automatisation de la vérification de traduction, les méthodes traditionnelles se basent généralement sur un fort niveau de littéralité dans le style de la traduction. En faisant appel à des bases terminologiques multi-lingues et des algorithmes d'alignement de textes parallèles, il est possible de vérifier dans un travail de traduction le respect de normes strictes, sous la forme d'une liste de possibilités de traduction pour un terme donné. Nous proposons ici une méthode alternative basée sur le repérage, dans les deux textes, de structures sémantiques générales, ou isotopies, et la comparaison des schémas qu'elles présentent au niveau du texte et non plus de la phrase ou du paragraphe, permettant ainsi une plus grande tolérance dans le style de traduction à vérifier.\",\n",
              " \"L'analyse des propositions relatives en anglais telle que déecrite par Sag (1997) se base sur une classification à deux dimensions des constructions syntaxiques en HPSG. Nous présentons ici une implémentation de cette analyse, fondée sur l'héritage multiple et les templates à deux dimensions dans le système ProFIT (Erbach, 1995).\",\n",
              " 'Nous traitons dans ce papier du problème de la détection et de la correction des graphies fautives dans les textes arabes. Nous commençons par présenter une expérience visant à mesurer de manière comparative la difficulté du problème pour l\\'arabe, le français et l\\'anglais. L\\'idée est d\\'évaluer le degré de \"ressemblance\" (proximité) des mots au sein de chaque langue. Ensuite les algorithmes de base de notre méthode de correction sont présentés.',\n",
              " \"Nous présentons dans cet article l'architecture logicielle de Context, plate-forme d'ingénierie linguistique dédiée au filtrage sémantique. Nous avons défini un modèle conceptuel et un langage de description et de traitement des connaissances linguistiques. Ces connaissances sont gérées par un système dédié et indépendant des applications qui les utilisent. Les traitements sont spécifiés sous forme déclarative dans un langage formel que nous présentons.\",\n",
              " \"Nous présentons les principaux résultats obtenus à ce jour dans le cadre du projet MAREDI qui vise à développer un système de traitement de la langue naturelle permettant d'analyser des transcriptions de dialogues oraux et de générer un modèle conceptuel de la conversation. Nous discutons principalement des aspects touchant l'analyse sémantique, en l'occurrence le rôle qu'y jouent les actes de discours et l'analyse casuelle, tout en présentant brièvement l'architecture globale du système et les caractéristiques de ses différentes composantes.\",\n",
              " 'Cet article introduit une représentation du sens basée sur des vecteurs de notions. Ces vecteurs sémantiques ont pour but de rendre compte de lÕensemble des idées évoquées dans un segment textuel. Ce type de représentation utilisé en conjonction avec une analyse morpho-syntaxique classique permet dÕeffectuer dans de nombreux cas une désambiguïsation lexicale efficace.',\n",
              " \"Nous présentons dans cet article une approche acquisitionniste de la langue naturelle dans le cadre du dialogue homme-machine finalisé, ainsi qu'une première implémentation. Le système de dialogue COALA, qui tente de mettre en oeuvre cette approche, se constitue ses propres représentations à partir de son expérience, au lieu d'utiliser des connaissances langagières pré-codées. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux. Le système COALA réunit d'une part un modèle de dialogue (non décrit dans cet article) et d'autre part une méthode d'analyse par chart hypothético-déductif qui permet une forme d'apprentissage par extraction de régularités structurelles.\",\n",
              " \"Nous présentons dans cet article une approche acquisitionniste de la langue naturelle dans le cadre du dialogue homme-machine finalisé, ainsi qu'une première implémentation. Le système de dialogue COALA, qui tente de mettre en oeuvre cette approche, se constitue ses propres représentations à partir de son expérience, au lieu d'utiliser des connaissances langagières pré-codées. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux. Le système COALA réunit d'une part un modèle de dialogue (non décrit dans cet article) et d'autre part une méthode d'analyse par chart hypothético-déductif qui permet une forme d'apprentissage par extraction de régularités structurelles.\",\n",
              " \"Notre étude propose un modèle cohérent pour formaliser la modalité pour une implémentation en tant que module interlingua d'un système de traduction automatique (TA). Un grand nombre d'erreurs de traduction en TA peut être attribué à l'absence d'un traitement autonome de modalité. Le modèle tient compte de l'hétérogénéité des éléments modaux et permet la combinaison des éléments déclencheurs.\",\n",
              " \"Nous présentons une méthode de classification d'analyses robustes sur des hypothèses concurrentes d'un système de reconnaissance de la parole. Pour réaliser cette classification, différents critères hétérogènes sont combinés, comme le score de reconnaissance, diverses caractéristiques syntaxiques et sémantiques propres à l'analyse robuste effectuée ou encore des estimations de la cohérence pragmatique. L'analyse est fondée sur une variante des LTAG (Lexicalized Tree Adjoining Grammars). La classification proposée est évaluée à partir d'un corpus d'analyses robustes d'hypothèses de reconnaissance.\",\n",
              " \"Nous présentons une technique d'analyse robuste dans le but de relayer la décision d'un système de reconnaissance de la parole. La stratégie d'analyse proposée est fondée sur une grammaire d'arbres adjoints lexicalisée compactée et sur la mise en concurrence des différentes hypothèses du système de reconnaissance de la parole. Les problèmes de robustesse sont étudiés en considérant les interférences entre erreurs de reconnaissance de la parole et phénomènes de parole spontanée dans les dialogues homme-machine.\",\n",
              " 'Cet article décrit l\\'amorçage d\\'une ontologie et d\\'un lexique partagé dans une population d\\'agents robotiques dotés de capacités visuelles. Cette évolution a lieu alors que les agents jouent un jeu de langage, appelé \"guessing game\". Nous étudions les dynamiques d\\'un tel système et montrons, en particulier, comment la synonymie et l\\'ambiguïté du système sémantique, qui émergent dans un premier temps, sont progressivement réduites au fur et à mesure que l\\'environnement physique se complexifie.',\n",
              " \"L'analyse syntaxique robuste est devenue une technique essentielle à toute application qui touche au contenu des documents. Les analyseurs inscrits dans cette approche permettent d'extraire des informations d'ordre linguistique qui peuvent être exploitées postérieurement par des traitements linguistiques plus profonds ou par des systèmes de recherche d'information. Une des caractéristiques principales de ces outils est leur robustesse. Or, cette robustesse est souvent diminuée par la grande hétérogénéité de phénomènes linguistiques et extralinguistiques présents dans les textes tout-venant. Cet article présente tout d'abord (section 1) la notion de robustesse et caractérise (section 2) les systèmes d'analyse syntaxique robuste. L'article présente par la suite (section 3) un inventaire de phénomènes linguistiques et extralinguistiques non-standard attestés dans divers corpus et, finalement, (section 4) une architecture qui se propose de traiter ces phénomènes.\",\n",
              " \"Un des enjeux de la CHM orale, dès qu'elle aura quitté le champ d'investigation du dialogue fortement finalisé, semble être de pouvoir allier robustesse (face aux spécificités de l'oral), efficacité et couverture de la langue. Cet article tente de montrer qu'une analyse linguistique détaillée peut être menée tout en respectant la contrainte de robustesse imposée. Le système, proposé comme une alternative aux méthodes sélectives, repose tout d'abord sur l'exploitation du pouvoir structurant de la syntaxe au niveau de constituants minimaux non récursifs (chunks). Une recherche des relations de dépendances entre les têtes lexicales associées à ces unités peut être ensuite envisagée à un niveau sémantico-pragmatique.\",\n",
              " \"Cet article présente un système de compréhension d'une requête orale dans le cadre d'un dialogue homme-machine. Si le dialogue est finalisé, son domaine est néanmoins relativement vaste : la construction d'une représentation sémantique de l'énoncé exige une analyse linguistique plus fine que celle utilisée dans les applications classiques de CHM1. Le système présenté ici, entièrement lexicalisé, utilise à différents niveaux les types logiques : au niveau syntaxique, il reconstitue les groupes de mots par composition de lambda-termes ; à un niveau plus sémantique, il compose les différents constituants pour construire une formule logique qui correspond à la représentation sémantique de la requête. Les tests réalisés semblent valider la méthode.\",\n",
              " \"Il est communément admis que la tâche de désambiguïsation sémantique n'est pas une fin en soi. Pour tenter d'apporter un début de solution à ce problème reconnu comme très difficile, de nombreux systèmes ont été développés. Pour la plupart, ces systèmes sont destinés à être les composants de systèmes plus complexes (moteurs de recherche d'information, de dialogue personne-machine, ou d'aide à la traduction). Néanmoins, ils sont testés en tant que tels dans le cadre de campagnes d'évaluation, comme par exemple Senseval ou Romanseval. La seconde édition de ces campagnes est d'ores et déjà planifiée. De fait, on est en droit de se demander - sans pour autant vouloir chercher à enrayer le mouvement -, si la désambiguïsation sémantique a un sens, et si oui lequel. Il ne faut pas voir dans ce questionnement un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une pratique dans laquelle s'engagent de plus en plus de chercheurs, qu'ils soient linguistes ou informaticiens. Si l'on s'en tient au protocole suivi lors de la première campagne d'évaluation de Senseval, on peut dégager de ses caractéristiques un certain nombre d'observations qui peuvent alimenter la réflexion. Une quarantaine de mots appartenant à l'une ou l'autre de trois catégories grammaticales avait été retenue : les noms, les verbes et les adjectifs. Pour chacun de ces mots était fournie une liste d'étiquettes sémantiques et pour couvrir l'ensemble de ces sens, en moyenne, une centaine d'exemples étiquetés ainsi qu'une définition pour chaque étiquette. Pour chaque mot, enfin une centaine d'exemples de tests devaient être étiquetés par les différents systèmes en lice. Pour un mot donné, les étiquettes pouvaient entretenir des relations de type hiérarchique, ce qui permettait d'évaluer les systèmes à trois niveaux  de granularité : fin, grossier, et intermédiaire. Une remarque préalable concerne le corpus d'apprentissage disponible pour chacun des mots. Pour un mot donné, seul le mot en question était étiqueté. Pour les mots du contexte aucune étiquette sémantique n'était proposée. Les annotations sémantiques posées par des juges humains sur chacun des exemples relatifs à un mot particulier, avait fait l'objet d'un arbitrage, et quand cela  s'avérait impossible plusieurs étiquettes sémantiques avaient été maintenues. Enfin, détail qui peut avoir son importance : les étiquettes sémantiques utilisées pour annoter le corpus d'apprentissage étaient plus fines que celles qui étaient employés pour le niveau le plus fin d'évaluation. Notre propos n'est pas ici de décrire ifficultés à mettre en relation des définitions et des emplois de mots en contexte .Une des significations d'un mot employé dans un contexte particulier peut se trouver absente de la ressource pour plusieurs raisons. Les lacunes des dictionnaires ont  suffisamment été pointées du doigt à diverses reprises, pour qu'il soit nécessaire d'en rajouter sur le sujet. Par essence, une ressource finie ne peut couvrir toutes les productions résultant des capacités créatives qui s'exercent sur les langages naturels. Certains usages langagiers correspondent à des nuances fines dont il est difficile de rendre compte dans un lexique où par contre figurent souvent des acceptions qui n'ont plus cours. Par ailleurs, il n'y a pas de découpage unique d'un mot en unités de sens. Il suffit pour s'en convaincre de comparer les choix faits par différents dictionnaires. Mais, le problème est plus complexe que cela. En analysant le fonctionnement des métaphores, on peut expliquer comment certaines figures de style permettent de rajouter un sens (le plus souvent figuré) à un mot tout en maintenant en partie son sens premier. Ces évidences expliquent en grande partie la complexité de la relation entre étiquetage et choix d'étiquettes sémantiques. Les méthodes numériques ont leur mot à dire pour tenter de trouver une voie entre lexique et corpus annoté. Toute approche qui entre dans cette catégorie peut non seulement permettre de choisir une étiquette parmi plusieurs, mais aussi servir à classer toutes les étiquettes candidates soit par calcul de distances ou de vraisemblances. Si la méthode retenue est de ce type, le vecteur final associé à un exemple peut être vu comme un moyen de localiser un emploi particulier dans l'espace déterminé par la base que forment les étiquettes sémantiques. Par le biais d'une analyse en composantes principales ou d'une analyse discriminante, des axes orthogonaux peuvent être dégagés un à un, axes correspondant à un compromis entre le jeu d'étiquettes initial et les exemples présents dans le corpus annoté. Même si le processus n'a pas tendance à converger, il ne serait peut-être pas inutile de de le voir comme une étape parmi d'autres d'une procédure itérative appliquée s'il le faut sur des données mouvantes afin de reproduire les aspects dynamiques de toute langue vivante. Si l'on accepte l'idée que Numérique et Métrique ont un rôle à jouer dans le domaine de la Sémantique, il est possible de voir le problème de la désambiguïsation sémantique comme formant un tout avec celui du choix des étiquettes. La question ne serait plus comment choisir entre tel ou tel sens pour un emploi donné, mais dans quelle région se situe cet emploi, sachant que la somme des usages aura tendance à modifier l'espace lui-même, dès qu'il sera patent qu'il aura été pour une raison ou pour autre, sous ou sur dimensionné.\",\n",
              " 'annotation morpho-syntaxique, type de texte, linguistique de corpus, apprentissage, classification',\n",
              " \"recherche d'information, modèle vectoriel, arbre, arbre de décision, moteur de recherche, indexation\",\n",
              " 'traduction, traduction automatique, transfert lexico-structural, sémantique, éléments lexicaux',\n",
              " 'paradigme monodimensionnel, prédication monodimensionnelle, prédicat, prédicat verbal, sémantique',\n",
              " 'contrainte contextuelle, grammaire, grammaire de propriétés, relation de dépendance, grammaire de dépendance',\n",
              " 'grammaire, grammaire transductive, grammaire générative, grammaire formelle, grammaire de dépendance, lexie',\n",
              " \"paradigme d'évaluation, campagne d'évaluation, système d'annotation, corpus\",\n",
              " 'expression régulière, entrée lexicale, étiquetage, arbre, arbre de décision, corpus, corpus de test',\n",
              " 'extraction, extraction automatique de correspondances lexicales, alignement, alignement lexical, lexicographie, relation de traduction',\n",
              " 'entité nommée, expression régulière, acquisition lexicale, marqueur, marqueur discursif, moteur de recherche',\n",
              " 'Corpus, Concordancier, TAL, Parser, Expression régulière',\n",
              " 'Automates finis, forme normale de Greibach, grammaires context-free, graphes',\n",
              " 'Entités nommées, reconnaissance automatique, procédure incrémentielle',\n",
              " 'sémantique, représentation du discours, temporalité, narration',\n",
              " 'Analyse syntaxico-sémantique, système question–réponse',\n",
              " 'recherche documentaire, système anthropocentré, filtrage documentaire, sémantique différentielle et componentielle, isotopie',\n",
              " 'Corpus, dictionnaire, étiquetage lexical, information distributionnelle',\n",
              " 'Analyse par contraintes, théorie Sens-Texte',\n",
              " \"Reformulation des requêtes, recherche et extraction d'information, personnalisation\",\n",
              " \"Amorce, Extraction d'information, Ontologie, Patron d'indexation\",\n",
              " \"Nous proposons de montrer comment l'analyse syntaxique automatique est aujourd'hui à un tournant de son évolution, en mettant l'accent sur l'évolution des modèles d'analyse syntaxique : de l'analyse de langages de programmation (compilation) à l'analyse de langues, et, dans le cadre de l'analyse de langues, de l'analyse combinatoire à l'analyse calculatoire, en passant par le tagging et le chunking (synthèse en section 4). On marquera d'abord le poids historique des grammaires formelles, comme outil de modélisation des langues et des langages formels (section 1), et comment la compilation a été transposée en traduction automatique par Bernard Vauquois. On analysera ensuite pourquoi il n'a pas été possible d'obtenir en analyse de langue un fonctionnement analogue à la compilation, et pourquoi la complexité linéaire de la compilation n'a pas pu être transposée en analyse syntaxique (section 2). Les codes analysés étant fondamentalement différents, et le tagging ayant montré la voie, nous en avons pris acte en abandonnant la compilation transposée : plus de dictionnaire exhaustif en entrée, plus de grammaire formelle pour modéliser les structures linguistiques (section 3). Nous montrerons comment, dans nos analyseurs, nous avons implémenté une solution calculatoire, de complexité linéaire (section 5). Nous conclurons (section 6) en pointant quelques évolutions des tâches de l'analyse syntaxique.\",\n",
              " 'Corpus arboré, corpus journalistique, français, syntaxe',\n",
              " 'Temps linguistique, Valeurs Aspectuelles, Schèmes Sémantico-Cognitifs, Graphes Conceptuels',\n",
              " \"Nous présentons dans cet article un modèle d'exploration contextuelle et une plate-forme logicielle qui permet d'accéder au contenu sémantique des textes et d'en extraire des séquences particulièrement pertinentes. L'objectif est de développer et d'exploiter des ressources linguistiques pour identifier dans les textes, indépendamment des domaines traités, certaines des relations organisatrices des connaissances ainsi que les organisations discursives mises en places par l'auteur. L'analyse sémantique du texte est guidée par le repérage d'indices linguistiques déclencheurs dont l'emploi est représentatif des notions étudiées.\",\n",
              " 'Désambiguïsation, Sémantique Distributionnelle, Représentation Vectorielle, Recherche Documentaire, Champs de Markov, algorithme EM',\n",
              " 'classification numérique de textes, n-grams, multilinguisme',\n",
              " \"Cet article propose une description des dépendances à distances s'appuyant sur une approche totalement déclarative, les grammaires de propriétés, décrivant l'information linguistique sous la forme de contraintes. L'approche décrite ici consiste à introduire de façon dynamique en cours d'analyse de nouvelles contraintes, appelées propriétés distantes. Cette notion est illustrée par la description du phénomène des disloquées en français.\",\n",
              " \"interrogation de BD en langage naturel, modèle relationnel, classes d'objets\",\n",
              " 'corpus, prosodie, étiquetage',\n",
              " \"Trouver l'arbre d'analyse le plus probable dans le cadre du modèle DOP (Data-Oriented Parsing) — une version probabiliste de grammaire à substitution d'arbres développée par R. Bod (1992) — est connu pour être un problème NP-difficile dans le cas le plus général (Sima'an, 1996a). Cependant, si l'on introduit des restrictions a priori sur le choix des arbres élémentaires, on peut obtenir des instances particulières de DOP pour lesquelles la recherche de l'arbre d'analyse le plus probable peut être effectuée en un temps polynomial (par rapport à la taille de la phrase à analyser). La présente contribution se propose d'étudier une telle instance polynomiale de DOP, fondée sur le principe de sélection miminale-maximale et d'en évaluer les performances sur deux corpus différents.\",\n",
              " \"Système de question-réponse, entité nommée, variante terminologique, recherche d'information\",\n",
              " 'Cadre thématique, cohérence thématique, exploration contextuelle',\n",
              " 'liaison, lecture, spontané, débit de parole, longueur, fréquence lexicale',\n",
              " 'Transducteur, noms propres, extraction de motifs',\n",
              " \"Extraction de motifs, arbres stratifiés ordonnés, distances d'édition, séquences\",\n",
              " 'Communication Homme-Machine, Compréhension Automatique de la Parole, robustesse, analyse syntaxique partielle, grammaires de dépendances',\n",
              " 'Structuration de terminologie, aide à la validation, synonymie',\n",
              " 'morphologie dérivationnelle, analogie, structure du lexique',\n",
              " 'Synonymie relative, synonymie subjective, approches statistiques, distances thématiques',\n",
              " \"mémoire de traduction sous-phrastique, traduction assistée par ordinateur, traduction automatique à base d'exemples\",\n",
              " 'système multi-agents, syntaxe, analyse syntaxique, environnement',\n",
              " 'structures textuelles, énumérations, représentation, classification, modèles de texte',\n",
              " 'adjectif, ambiguïté syntaxique, anglais médical, corpus bilingue, découpage, groupe nominal, traduction, traduction automatique',\n",
              " \"dictionnairique, aide à la compréhension, lecture active, sélection d'acceptions\",\n",
              " \"extraction d'information, génomique, transducteurs linguistiques\",\n",
              " 'Reconnaissance Automatique de la Parole, Modèles de Langage statistique, Serveurs de Dialogue, Arbre de Décision',\n",
              " 'Ressources linguistiques, Bases de données textuelles, Dictionn-aires, Web',\n",
              " \"Cartographie de Textes, Recherche d'Information, Extraction d'Information, Apprentissage Automatique\",\n",
              " 'Dialogue Homme-Machine, traitement de la référence',\n",
              " 'Réponse au courriel, Analyse de texte, Analyse de corpus',\n",
              " \"Extraction d'information, Entités nommées\",\n",
              " 'Identification, interprétation, représentation des connaissances, exploration contextuelle, graphes, base de données',\n",
              " 'dialogue oral homme-machine, gestionnaire de dialogue, modèle de dialogue, modèle de la tâche',\n",
              " \"Les modèles de langage stochastiques utilisés pour la reconnaissance de la parole continue, ainsi que dans certains systèmes de traitement automatique de la langue, favorisent pour la plupart l'interprétation d'un signal par les phrases les plus courtes possibles, celles-ci étant par construction bien souvent affectées des coûts les plus bas. Cet article expose un algorithme permettant de répondre à ce problème en remplaçant le coût habituel affecté par le modèle de langage par sa moyenne sur la longueur de la phrase considérée. Cet algorithme est très général et peut être adapté aisément à de nombreux modèles de langage, y compris sur des tâches d'analyse syntaxique.\",\n",
              " \"Morphologie, recherche d'information, variantes de termes, médecine, terminologie, Doc'CISMeF, MeSH\",\n",
              " \"On appelle grammaire de dépendance toute grammaire formelle qui manipule comme\\nreprésentations syntaxiques des structures de dépendance. Le but de ce cours est de présenter à\\nla fois les grammaires de dépendance (formalismes et algorithmes de synthése et d'analyse) et\\nla théorie Sens-Texte, une théorie linguistique riche et pourtant méconnue, dans laquelle la\\ndépendance joue un rôle crucial et qui sert de base théorique à plusieurs grammaires de\\ndépendance.\",\n",
              " \"Désambiguïsation lexicale, dictionnaire, propriétés distributionnelles, collocations, classes d'objets\",\n",
              " 'Désambiguïsation sémantique, corpus sémantiquement étiqueté, co-occurrences',\n",
              " 'TALN, assistant linguistique, ressources linguistiques, agents autonomes, études sur corpus',\n",
              " 'Bases de données, ressources lexicales',\n",
              " 'Reconnaissance de gestes, Langue des Signes',\n",
              " 'Génération automatique de textes, annotation, coréférence, rôles thématiques',\n",
              " 'Répétitions, français parlé spontané, « disfluences », phénomènes de performance, étude quantitative, reconnaissance de la parole, étiquetage morpho-syntaxique',\n",
              " 'analyse de contenu, génération, création assistée de documents, normalisation de document',\n",
              " 'Agents Conversationnels, Analyse Distribuée, Micro-Systèmes, Sémantique Procédurale',\n",
              " 'Automates à états finis, analyse de corpus, extraction automatique de phrases, classification automatique de phrases, INTEX',\n",
              " 'analyse de corpus, acquisition supervisée de terminologie, sémantique lexicale',\n",
              " \"Filtrage d'information, e-mail, classification de messages, propriétés linguistiques, réseaux de neurones, filtrage d'email\",\n",
              " 'Qu\\'il s\\'adresse à un Prix Nobel ou à un étudiant de première année Maurice Gross ne craignait jamais d\\'être trop élémentaire. C\\'était à chaque fois comme si, entreprenant d\\'écrire un livre de mathématiques il ne pouvait rien démontrer avant d\\'avoir reconstruit les données les plus primitives du calcul et du raisonnement qui l\\'accompagne. Et il arrivait souvent que ceux qui l\\'écoutaient ou le lisaient pour la première fois, manquant par leur impatience le détail qui faisait que ses évidences n\\'avaient rien d\\'évident, s\\'imaginent qu\\'il les prenait pour des imbéciles. Parce qu\\'il avait l\\'expression littéraire et philosophique, la langue du style, la forme de l\\'émotion, dans les tripes – il pouvait citer sans discontinuer des poètes français ou anglais du XVIe siècle à nos jours et discuter longuement des formulations exactes d\\'un René Descartes ou d\\'un Charles Sanders Pierce, deux de ses deux philosophes préférés - il n\\'a jamais fait recette auprès des littéraires, des psycho-socios, des sémio-machins, des politiques et des pouvoirs académiques chez qui le raccourci, la connotation, le clin d\\'oeil, dont tout le monde a oublié sur quelles complicités exactes ils se fondent, tiennent lieu de découverte quand ce n\\'est pas de pensée. La complexité qui l\\'intéressait était d\\'une tout autre nature et autrement plus complexe. Elle avait pour horizon la phrase simple. Même pas l\\'énoncé, juste la phrase. Et simple c\\'est-à-dire constituée d\\'une seule proposition. Contrairement à ceux qui voyaient dans les processus de récursivité propositionnelle – relatives notamment -- une source de complexité et de créativité, il y voyait un mécanisme très banal 1. La vraie complexité, celle qu\\'aucune machine construite à ce jour ne contrôle vraiment, il l\\'a exposée avec une simplicité désarmante en un peu moins de deux pages au début de Méthodes en syntaxe (1975: 17-19) dans le chapitre intitulé La créativité du langage. Elle porte sur les combinaisons possibles ou impossibles au sein d\\'une structure de neuf constituants formant une phrase simple. Mais ces possibilités \"limitées à 1050 cas\" et qui peuvent donc \"être considérées comme intuitivement infinies\" sans qu\\'il soit nécessaire \"de faire appel à des mécanismes infinis pour rendre compte de leur richesse\" ne sont qu\\'un horizon virtuel.',\n",
              " 'Recherche documentaire, modèle vectoriel, réduction de dimension, analyse factorielle, ACP, GHA, réseaux de neurones',\n",
              " 'Traduction statistique, adapatabilité, terminologie',\n",
              " 'Réaccentuation, mots inconnus, étiquetage, langue de spécialité, médecine',\n",
              " 'analyse syntaxique, analyse descendante, analyse calculatoire, corpus multi-lingues',\n",
              " 'analyse syntaxique automatique, analyse distributionnelle, corpus, ontologie, terminologie',\n",
              " 'Analyse Syntaxique, Tabulation, DCG, TAG, RCG, BMG, TFS',\n",
              " 'Syntaxe, linguistique mathématique, apprentissage statistique, SCFG, Gibbs',\n",
              " \"Extraction d'information, modélisation, construction d'ontologie, corpus dégradés\",\n",
              " 'Identification thématique, modèles de langage, uni-grammes',\n",
              " 'représentation thématique, vecteurs conceptuels, antonymie, apprentissage automatique, fonctions lexicales',\n",
              " 'Similarités textuelles, repréesentation vectorielle de textes, sémantique distributionnelle, contexte de co-occurrence',\n",
              " 'Reconnaissance de la parole, modélisation statistique du langage, détection de thème, information mutuelle, similarité',\n",
              " 'Analyse du discours, analyse thématique, segmentation, détection de liens thématiques',\n",
              " 'langue parlée spontanée, compréhension automatique, méthodes formelles',\n",
              " 'Exercices contextuels, lexique, corpus, ALAO',\n",
              " 'Analyse syntaxique de questions, connaissances sémantiques, détection du focus',\n",
              " 'Nous présentons dans cet article un cadre d\\'explication des relations entre les différents composants de l\\'analyse linguistique (prosodie, syntaxe, sémantique, etc.). Nous proposons un principe spécifiant un équilibre pour un objet linguistique donné entre ces différents composants sous la forme d\\'un poids (précisant l\\'aspect marqué de l\\'objet décrit) défini pour chacun d\\'entre eux et d\\'un seuil (correspondant à la somme de ces poids) à atteindre. Une telle approche permet d\\'expliquer certains phénomènes de variabilité : le choix d\\'une \"tournure\" à l\\'intérieur d\\'un des composants peut varier à condition que son poids n\\'empêche pas d\\'atteindre le seuil spécifié. Ce type d\\'information, outre son intérêt purement linguistique, constitue le premier élément de réponse pour l\\'introduction de la variabilité dans des applications comme les systèmes de génération ou de synthèse de la parole.',\n",
              " 'analyse syntaxique automatique, analyse endogène, productivité, argument, circonstant',\n",
              " 'taux de polysémie, taux de synonymie, lexiques sémantiques, Word-Net, SemCor',\n",
              " 'Morphologie dérivationnelle, affixation et conversion, acquisition de traits sémantiques',\n",
              " 'Morphologie dérivationnelle, ressource lexicale, Web comme corpus, analogie',\n",
              " 'Classes sémantiques, Évaluation, Ressources, Réseau sémantique',\n",
              " 'Entités nommées, reconnaissance incrémentielle, apprentissage, surcomposition référentielle',\n",
              " 'Partage de révision, représentation interlingue, coédition de texte et de graphe UNL, communication multi-lingue',\n",
              " \"Traduction automatique, français-anglais, base d'exemples\",\n",
              " \"Grammaire formelle, Grammaire Catégorielle, Description d'arbres\",\n",
              " \"Recherche d'information, système de question-réponse, focus, patron d'extraction\",\n",
              " 'ressources linguistiques francophones, dialogue oral, communication homme-machine',\n",
              " 'Anaphore, SN complexes, référence, préposition de, relatif qui',\n",
              " 'Métaphore, Analyse sémantique latente, interprétation et détection, textes littéraires',\n",
              " 'Termes, collocations, adjectifs, noms, corpus, anglais de spécialité',\n",
              " \"Grammaires d'arbres adjoints, MétaGrammaire, Développement, Constructions adjectivales\",\n",
              " 'Langage multimodal, coordination des modes, expressions sémantiquement équivalentes',\n",
              " 'Dialogue, attentes, pragmatique, analyse, statistique, aspects cognitifs',\n",
              " \"segmentation en thèmes, analyse des conversations, extraction d'information\",\n",
              " 'Analyse du discours, compositionnalité, lambda-calcul, SDRT, actes de langage',\n",
              " 'communication orale homme-machine, compréhension automatique de la parole, répétitions, corrections, analyse syntaxique partielle, grammaires de liens',\n",
              " 'Ressources linguistiques, corpus, dictionnaires, lexiques, Frantext, TLFi, Stella',\n",
              " 'Fonction lexicale, lexicologie explicative et combinatoire, théorie Sens-Texte, lexicographie formelle',\n",
              " \"Nous présenterons tout d'abord la philosophie « Agents » en général, afin d'en montrer les avantages pour le domaine du TALN, qui se caractérise par une hétérogénéité avérée des systèmes existants (multiplicité des langages de programmation), ainsi qu'une forte demande en ressources (mémoire notamment). Nous ferons ensuite une présentation des principales plate-formes orientées agents, puis nous examinerons de plus près la plate-forme développée au Standford Research Institute (SRI) : OAA (licence libre). Nous clôturerons le tutoriel sur des exemples commentés d'applications industrielles utilisant OAA, permettant de donner toutes les clés nécessaires au développement d'applications distribuées (intra/internet), multi-agents et multiplates-formes (plusieurs langages de programmation/systèmes d'exploitation).\",\n",
              " \"Analyse syntaxique, Robustesse d'analyse, HPSG, système multi-agent, AgentBuilder\",\n",
              " 'Analyse de dépendance, analyse syntaxique, intégration, fusion',\n",
              " \"Extraction d'information, profil utilisateur, résumé multi-document\",\n",
              " 'Structure communicative (ou structure informationnelle), progression thématique, structure du discours (relations de discours), structuration de document, génération automatique de textes',\n",
              " 'analyse syntaxique automatique, approche endogène, ressource exogène, approche mixte, ambiguïté catégorielle',\n",
              " 'polysémie, calcul du sens, construction syntaxique, espace sémantique, préposition',\n",
              " 'Résolution de la Référence Intrinsèque, Approche Fonctionnelle, Dialogue Homme Machine',\n",
              " \"sociétés d'agents, vecteurs conceptuels, sémantique lexicale, apprentissage\",\n",
              " 'Langage \"pivot\", que-phrase, description, formalisation',\n",
              " 'Anglais, TAL, étiquetage morphologique, ambiguïtés dues à la morphologie, grammaires locales, contexte',\n",
              " \"Dérivation, suffixe, finnois, tranducteurs à nombre fini d'états\",\n",
              " 'Linguistique descriptive, Linguistique formelle, Grammaires de Propriétés (GP), Traitement Automatique des Langues Naturelles (TALN), Syntaxe',\n",
              " 'annotation sémantique, désambiguisation sémantique lexicale',\n",
              " 'Tokenisation, segmentation du chinois, n-grammes, approche statistique, maximum matching',\n",
              " 'Dialogue homme-machine, gestion du dialogue, gestion de la tâche, compréhension, interprétation',\n",
              " \"Filtrage d'information, e-mail, réseaux de neurones, apprentissage, spam\",\n",
              " 'Analyse syntaxique robuste, compréhension de la parole, dialogue homme-machine',\n",
              " 'Désambiguïsation sémantique automatique, corpus sémantiquement étiqueté, co-occurrences',\n",
              " 'Détection de thème, création de vocabulaire, combinaison',\n",
              " \"Analyse, Classification, Extraction d'information\",\n",
              " 'Acquisition de lexique, extraction de patrons morpho-syntaxiques et sémantiques, lexique génératif, programmation logique inductive, bootstrapping, apprentissage semi-supervisé',\n",
              " 'Grammaire, analyse syntaxique, ressources lexicales, LTAG, représentation compacte du lexique',\n",
              " 'Désambiguïsation sémantique, arbres de classification sémantique',\n",
              " 'Discours, SDRT (Segmented Discourse représentation Theory), DAG (Directed Acyclic Graph), Représentation sémantique sous-spécifiée, LTAG (Lexicalized Tree Adjoining Grammar)',\n",
              " \"Système de question-réponse, recherche d'information, fiabilité des réponses\",\n",
              " 'Questions-Réponses, Apprentissage Automatique, Acquisition de Paraphrase',\n",
              " 'grammaires de dépendance, ordre des mots, prosodie, topologie, générateur de parole, grec',\n",
              " \"analyse syntaxique robuste, normalisation en vue de l'extraction d'information\",\n",
              " 'Séries de cadres organisationnels, marqueurs dintégration linéaire, cadres de discours, segmentation automatique de textes, méthode dexploration contextuelle, filtrage automatique de textes',\n",
              " 'Compréhension de la parole, concepts sémantiques, réseaux bayésiens, étiquetage sémantique, catégorisation automatique',\n",
              " \"Morphème grammatical, interface syntaxe-sémantique, grammaire d'unification, grammaire de dépendance, HPSG, passif, impersonnel, tough-movement\",\n",
              " 'Pertinence, référence aux objets, dialogue multimodal, effets contextuels, effort de traitement',\n",
              " 'Traduction automatique, mémoire de traduction sous-phrastique, alignement sous-phrastique',\n",
              " 'Démonstratifs, analyse de corpus, annotation de corpus, génération de texte',\n",
              " \"Analyseurs syntaxiques, Combinaison d'informations, Evaluation\",\n",
              " \"STSG, Gibbs-Markov, Maximum d'Entropie, Vraisemblance Conditionnelle\",\n",
              " 'représentation thématique, vecteurs conceptuels, fonctions lexicales, acceptions',\n",
              " 'Créole, Martiniquais, Grammaire, TAG, Génération',\n",
              " 'Désambiguïsation lexicale, recherche dinformation, interfaces graphiques',\n",
              " \"Classification automatique, Rocchio, kPPV, SVM, Internet, filtrage de l'information\",\n",
              " 'Morphologie, apprentissage, corpus, langue de spécialité, médecine',\n",
              " \"Grammaires d'arbres adjoints, FTAG, noms prédicatifs, verbes supports, méta-grammaire, ordre des constituants\",\n",
              " 'Acquisition automatique, inférence grammaticale, modèle de Gold, prégroupe',\n",
              " \"Analyse automatique de discours, Cadres de discours, Recherche d'information, Document géographique\",\n",
              " \"Cet article fournit des éléments d'explication pour la description des relations entre les différents domaines de l'analyse linguistique. Il propose une architecture générale en vue d'une théorie formée de plusieurs niveaux : d'un côté les grammaires de chacun des domaines et de l'autre des relations spécifiant les interactions entre ces domaines. Dans cette approche, chacun des domaines est porteur d'une partie de l'information, celle-ci résultant également de l'interaction entre les domaines.\",\n",
              " 'Traitement aspectuo-temporel, temps, temporalité, exploration contextuelle, analyse sémantique de surface, ressources linguistiques',\n",
              " 'Génération automatique de textes, détermination de contenu, logiques de description, structuration de document, SDRT',\n",
              " 'Reconnaissance de termes, évaluation de la reconnaissance de termes, SRT, FASTR, SYRETE',\n",
              " 'Collocations, co-occurrences lexicales, réseaux lexicaux thématiques, analyse thématique',\n",
              " 'Analyse syntaxique robuste, grammaires de dépendances, apprentissage non supervisé, désambiguïsation du rattachement prépositionnel',\n",
              " 'Système de Question/Réponse, Bases de Connaissances',\n",
              " \"Sarfiyya, traitement automatique de l'arabe, automate, filtrage d'information, citation\",\n",
              " 'rédaction contrôlée multi-lingue, XML',\n",
              " 'Reconnaissance de lécriture manuscrite, modèle de langage, n-gramme, n-classe, perplexité',\n",
              " 'Evaluation, Dialogue Homme-Machine, Prototypage Rapide, Wizard-of-Oz',\n",
              " 'Catégorisation, synthèse, questionnabilité dun texte, traitement cognitifs dun texte, traitement automatique de la langue, Justice, dossier dinstruction',\n",
              " 'Langue, Arabe, Erreur orthographique, Correction automatique, Contexte',\n",
              " \"traduction guidée par l'exemple, traduction par analogie, traduction statistique, induction de grammaire de traduction\",\n",
              " 'Extraction de termes, extraction de relations, Terminologie, Ontologies, Ingénierie des connaissances, méthode, modélisation de connaissances, interdisciplinarité',\n",
              " 'Système de Question Réponse, analyse syntaxique, fusion de documents',\n",
              " 'Corpus, relations lexicales, acquisition automatique, désambiguïsation lexicale',\n",
              " 'Indexation Automatique, Terminologie Médicale, Vocabulaire Contrôlé',\n",
              " 'appariement syntaxique de mots, corpus parallèle, traitement automatique des langues naturelles',\n",
              " 'Analyse multimodale, Linguistique formelle, Développement de grammaire, Grammaires de Propriétés',\n",
              " 'Annotation syntaxique, corpus oraux, NFCE, annotation de référence',\n",
              " \"automates finis, grammaire locale, dictionnaire électronique, levée d'ambiguïtés, lexique-grammaire\",\n",
              " 'Lexique, espace sémantique, synonymie, graphes petit monde',\n",
              " 'analyse syntaxique, grammaires catégorielles, théorie des types, assistant de preuves',\n",
              " 'LEC, dictionnaire électronique formalisé, structure définitionnelle, TAL',\n",
              " \"Classes sémantiques, Extraction d'information, Exploration Contextuelle, Ressources, Réseau sémantique\",\n",
              " 'Résumé automatique, fiches de résumé, segmentation thématique, textes juridiques',\n",
              " 'apprentissage/décision automatique, recherche documentaire, expansion de requêtes, évaluation de difficulté',\n",
              " 'Traitements multilingues, découverte de mots vides, alternative à une stop-list, extraction de règles et de motifs fréquents',\n",
              " 'Traduction Automatique, Architecture interlingue, sémantique lexicale, Génération sémanticosyntaxique, structure syntaxique profonde',\n",
              " 'Traitement automatique du slovaque, Analyse morphologique, Morphologie flexionnelle, Morphologie dérivationnelle',\n",
              " 'inflexion vocalique, codage, génération automatique, luxembourgeois',\n",
              " 'Self-Organizing Map, text mining, classification, vectorisation du texte, syntagme, évaluation visuelle',\n",
              " 'Sémantique, λ-DRT, présupposition, compositionnalité',\n",
              " 'Transcription graphème-phonème, langue arabe, règles de transcription',\n",
              " 'base lexicale multilingue, construction automatique de lexies et axies, acception interlingue',\n",
              " 'Analyse syntaxique, granularité variable, grammaire de propriétés, shallow parsing, deep parsing, densité de satisfaction',\n",
              " 'Traduction Automatique, Traducteur Multilingue, Multilinguisme, Document Multilingue',\n",
              " \"Extraction d'information, synonymie, entités nommées, génomique\",\n",
              " \"Macro-sémantique, analyse rhétorique, structure du discours, extraction d'information\",\n",
              " 'Segmentation thématique, métriques de Beeferman et WindowDiff, cohésion lexicale, chaînes lexicales',\n",
              " 'analyse syntaxique automatique, ambiguïté de rattachement prépositionnel, procédures endogènes, ressources exogènes, approche mixte',\n",
              " \"Sémantique, grammaires d'arbre adjoints, grammaires catégorielles, λ-calcul\",\n",
              " \"Lexique sémantique, acquisition sur corpus, recherche d'information, Lexique génératif, extension de requête\",\n",
              " 'Sémantique lexicale, découverte du sens des mots, réseaux lexico-sémantiques',\n",
              " 'Désambiguïsation sémantique, réseaux petits mondes hiérarchiques, dictionnaires',\n",
              " \"Analyse de dépendance, analyse syntaxique, combinaisons d'informations\",\n",
              " 'Grammaires catégorielles, types sémantiques, apprentissage syntaxico-sémantique',\n",
              " 'Langues naturelles, réseaux neuronaux, extraction de connaissances',\n",
              " 'Analyse morpho-syntaxique, analyse syntaxique partielle, automates finis pondérés',\n",
              " 'Document Auto-Explicatifs (DAE), désambiguïsation interactive, documents actifs',\n",
              " 'Interprétariat à distance sur réseau, collecte de corpus oraux bilingues, dialogues spontanés, communication multi-lingue, mutualisation de ressources',\n",
              " 'Terminologie bilingue, corpus comparable, termes complexes',\n",
              " 'Traduction automatique, aide à la traduction, analyse syntaxique, collocations',\n",
              " \"Résumé multi-lingue ciblé, extraction d'information, génération multi-lingue\",\n",
              " \"Repérage d'énoncés définitoires, relations sémantiques, patrons lexico-syntaxiques\",\n",
              " \"Anonymisation, désidentification, reconnaissance d'entités nommées, textes juridiques\",\n",
              " 'MBL, accès lexical, relations sémantiques, associations, SVETLAN, EWN',\n",
              " \"Architecture textuelle, synthèse de la parole, stratégies d'oralisation\",\n",
              " 'Désambiguïsation sémantique, algorithme de Lesk, naive Bayes, WORDNET',\n",
              " 'Syntaxe, analyse, robustesse, contraintes, information linguistique, complexité syntaxique',\n",
              " 'Grammaires de propriétés, traitement du langage naturel, contraintes, configuration',\n",
              " 'Grammaire formelle, unification, polarisation, grammaire de réécriture, grammaire de dépendance, TAG, HPSG, LFG, graphe, arbre, dag',\n",
              " \"Segmentation thématique de texte, extraction d'information, indexation automatique\",\n",
              " \"Étiquetage sémantique, extraction d'information\",\n",
              " 'Détection de thème, Étiquetage thématique, statistique Kappa, erreur de Bayes',\n",
              " 'Référence, anaphore pronominale, dialogue oral homme-machine, analyse des usages sur corpus',\n",
              " 'Annotation, Temps, Discours',\n",
              " 'XML, analyse syntaxique, traitement automatique des langues, traitement de documents, Xpath, XIP',\n",
              " 'ressources libres, annotation multiniveau, corpus arboré, codage référentiel, normalisation',\n",
              " 'annotation en constituants, évaluation, analyseurs syntaxiques',\n",
              " 'Génération de textes, logique de description, détermination de contenu, bases de connaissance, assistant de preuve',\n",
              " 'Apprentissage partiel, inférence grammaticale, grammaire catégorielles',\n",
              " 'formalisme grammatical, interface syntaxe-sémantique, sous-spécification, polarités',\n",
              " \"Grammaires de réécriture, Grammaires Faiblement Contextuelles, complexité du langage naturel, Grammaires à Concaténation d'Intervalles (RCG)\",\n",
              " \"Modèles de langue, recherche d'information, mots composés\",\n",
              " 'Corpus, marquage des catégories grammaticales, regroupement, unification, catégories de mots, type/occurrence, évaluation',\n",
              " 'Structure(s) temporelle(s) dans un texte narratif, S-langages',\n",
              " 'Modulation, discours, modèles de dialogue, interaction verbale, annotation',\n",
              " 'Traduction de dialogue, évaluation subjective et objective de composants de TALN',\n",
              " 'Représentation des structures discursives, langage de représentation des connaissances linguistiques',\n",
              " \"Reformulation de requêtes, Extraction de l'information, Personnalisation\",\n",
              " \"Dialogue, attentes, magicien d'Oz, pragmatique, analyse, statistique\",\n",
              " 'évaluation, résumé automatique, textes français, GÉRAF',\n",
              " 'Terminologie, corpus spécialisés, structuration de terminologies, relations transversales, verbes',\n",
              " 'Traitement automatique des langues naturelles, classification automatique, désambiguïsation sémantique lexicale',\n",
              " 'Dialogue oral homme-machine, modèle de dialogue, but de dialogue',\n",
              " 'Grammaire de Construction, Référence Extensionnelle, Domaines de Référence',\n",
              " 'lexique, apprentissage automatique, système multi-agents',\n",
              " 'Traitement de corpus, segments répétés, recherches de relations, automates, transducteurs',\n",
              " \"anaphore infidèle, ressource sémantique, résolution d'anaphore, corpus annoté multiniveau\",\n",
              " 'Aide à la communication, modélisation stochastique du langage, n-gramme, chunks',\n",
              " 'Apprentissage par Analogie, Automates finis',\n",
              " 'Traduction de parole, modèles de langage, représentation pivot',\n",
              " 'logique, grammaires minimalistes catégorielles, lambda-calcul, portée des quantificateurs, Constraint Language for Lambda Structures',\n",
              " \"Recherche d'information, Analyse de la sémantique latente, Langue arabe, Racinisation\",\n",
              " \"Corpus, jeu d'étiquettes, Étiquetage morpho-syntaxique, texte arabe, modèle de Markov caché\",\n",
              " \"Analyse de textes, structure des évènements, extraction d'information, sémantique du temps\",\n",
              " 'Linguistique Systémique Fonctionnelle, Détection des entités nommées, Fouille de textes',\n",
              " 'Analyse acoustique, arabe standard, gémination, durée, reconnaissance de la parole',\n",
              " 'Corpus, ALAO, TAL, indexation pédagogique, ressources textuelles',\n",
              " 'Phonologie, phonétique, classifieur, réseaux de neurones',\n",
              " \"Linguistique, indexation, recherche d'information, statistique\",\n",
              " 'Synthèse de la parole arabe, Phonèmes, Diphones, Triphones, Unités acoustiques, Dictionnaire de polyphones',\n",
              " 'Etiquetage, Memory-Based Leaning, K-NN, Base de règles, Morphosyntaxique, Langue Arabe',\n",
              " 'Unité du discours, réseaux de cohésion, analyse thématique, littérature potentielle',\n",
              " 'Automate fini, grammaire locale, dictionnaire électronique, étiquetage morpho-syntaxique, désambiguïsation, textes littéraires',\n",
              " 'Modèles statistiques de langage, Modèles n-classes, Décodage sémantique, Approche componentielle et sélective',\n",
              " 'Système de Question Réponse, ressources sémantiques, évaluation des reformulations',\n",
              " 'cartographie de corpus, analyse thématique, logiciel individu-centré, analyse des données textuelles',\n",
              " 'Segmentation morphologique, alignement de segments de mots, corpus',\n",
              " 'Traduction automatique, morphologie constructionnelle, incomplétude lexicale',\n",
              " 'sémantique lexicale, langue spécialisée, spécificités, polysémie, co-occurrences',\n",
              " 'Alignement, corpus parallèles, analyse morphologique japonaise partielle, mémoire de traduction',\n",
              " 'Traduction, corpus, relations lexicales bilingues, acquisition semi-automatique, World Wide Web',\n",
              " 'langue tchatée, ressources linguistiques, collecte de données',\n",
              " 'SMS, phonétisation, synthèse de la parole',\n",
              " 'Étiquetage morpho-syntaxique, Apprentissage de règles, Apprentissage actif, fouille de textes',\n",
              " 'Base de données lexicale, métalangage définitionnel, Lexicologie Explicative et Combinatoire, polysémie',\n",
              " \"Apprentissage de relations prédicat-argument, extraction d'information\",\n",
              " 'syntaxe, analyseur, LFG, désambiguïsation, forêt partagée',\n",
              " 'étiquetage morpho-syntaxique, apprentissage supervisé, modèle de Markov caché, évaluation, homographes',\n",
              " 'Désambiguïsation sémantique, alignement multi-lingue, lexique sémantique',\n",
              " 'Navigation textuelle, apprentissage en lingusitique textuelle',\n",
              " 'Syntaxe, Lexique, Liage, Interface syntaxe sémantique, TAG',\n",
              " 'dialogue incarné, personnages virtuels, personnalité, génération automatique',\n",
              " \"dialogue homme machine, recherche d'information précise, corpus\",\n",
              " 'dictionnaires électroniques, Conditions de Structures Morphématiques, matrices lexicales, Restrictions combinatoires, Restrictions séquentielles',\n",
              " 'Segmenteur de textes arabes, segmentation en phrases, exploration contextuelle, expressions rationnelles',\n",
              " 'Mémoire de traduction, traduction probabiliste, alignements multiples, ré-ordonnancement à postériori',\n",
              " 'troubles du langage, simplification syntaxique, règles de réécriture, validation interactive, traitements de texte',\n",
              " 'Indexation Automatique, Terminologie Médicale, Vocabulaire Contrôlé',\n",
              " \"Systèmes de dialogue, simulation de dialogues, modèle d'utilisateur, optimisation\",\n",
              " 'Correction automatique, temps réel, analyse syntaxique, grammaire de contraintes',\n",
              " \"Analyse syntaxique, interface syntaxe-sémantique, grammaires non-linéaires, Grammaires à Concaténation d'Intervalles (RCG)\",\n",
              " 'segmentation thématique, chaînes lexicales, entités nommées',\n",
              " 'dictionnaire, lexique, lexique noyau',\n",
              " 'Linguistique de corpus, TAL, plate-forme logicielle',\n",
              " 'Méta-grammaires, Analyse Syntaxique, TAG, TIG',\n",
              " \"Grammaires, compilation, ressources linguistiques, Grammaires d'Arbres Adjoints, Grammaires d'Interaction\",\n",
              " \"Théorie Sens-Texte, interface syntaxe-sémantique, synchronisation, grammaire d'unification polarisée, grammaire de dépendance, grammaire topologique, génération de textes\",\n",
              " 'Indexation sémantique, Recherche documentaire, Redondance minimale, Ontologie',\n",
              " \"Systèmes de questions-réponses, repérage d'énoncés définitoires, patrons lexico-syntaxiques, médecine\",\n",
              " \"Système de questions-réponses, recherche d'information, évaluation des systèmes de questions-réponses, extraction de réponse, recherche sur le Web, QRISTAL\",\n",
              " 'morphologie, sémantique, multilinguisme, composition savante, relation lexicale, terminologie médicale',\n",
              " 'antonymie, morphologie, antonymie complémentaire, antonymie scalaire, antonymie duale, répartition statistique',\n",
              " 'Langue de spécialité, langue générale, structuration de terminologies, synonymes, portabilité, filtrage',\n",
              " 'Analyse syntaxique, analyse superficielle, analyse profonde',\n",
              " 'Analyse syntaxique, évaluation',\n",
              " \"français langue étrangère, itinéraires d'acquisition, évaluation, annotation, analyse syntaxique partielle\",\n",
              " \"Pronom impersonnel (explétif), Pronom anaphorique, Lexique-grammaire, Automates, Résolution d'anaphores, Analyse syntaxique modulaire\",\n",
              " 'Analyse syntaxique automatique, étiquetage morpho-syntaxique',\n",
              " 'Erreurs orthographiques cachées, Détection, Correction, Système multiagent, Analyse linguistique, Langue arabe',\n",
              " \"Logique du premier ordre, calcul des prédicats, représentation sémantique, relation prédicat-argument, quantificateur, grammaire d'unification polarisée, grammaire de dépendance, dag, interface syntaxe-sémantique\",\n",
              " 'Entités nommées, référence, sémantique lexicale',\n",
              " \"résumé automatique, fiches de résumé, textes juridiques, évaluation d'un résumé\",\n",
              " 'résumé automatique, compression de phrases, analyse syntaxique',\n",
              " 'Segmentation automatique de textes, Analyse sémantique latente (ASL)',\n",
              " \"Navigation intra-documentaire, analyse thématique, structures du discours, relations discursives, subordination et coordination, parallélisme lexico-syntaxico-sémantique, modèle d'apprentissage, analyses linguistiques\",\n",
              " 'Corpus parallèles, apprentissage automatique, traduction automatique',\n",
              " 'traduction automatique statistique, segments discontinus, modèles log-linéaires',\n",
              " 'alignement de mots, corpus alignés, apprentissage artificiel, programmation logique inductive, analyse syntaxique',\n",
              " 'Traduction automatique de termes, terminologie biomédicale, apprentissage artificiel, inférence de transducteurs',\n",
              " 'facteurs de saillance, saillance linguistique, saillance visuelle, principe de primordialité, principe de singularité, structure communicative, méthodes de quantification',\n",
              " 'Interprétation pragmatique, dialogue homme-machine',\n",
              " 'actes de dialogue, dialogue homme homme, détection automatique, indices multi-niveaux',\n",
              " 'couverture lexicale, terminologie, statistique lexicale',\n",
              " 'classes de sélection distributionnelle, espace distributionnel, désambiguïsation, corpus, contexte',\n",
              " 'Disfluences, Parsing, Linguistique de corpus, Linguistique formelle, Développement de grammaires, Grammaire de Construction (CxG), Grammaires de Propriétés (GP)',\n",
              " 'syntaxe, subordination, dépendance, topologie',\n",
              " 'TAG, analyse syntaxique, sémantique, arbre de dépendance,forêt partagée, forêt de dérivation',\n",
              " 'Modèles de Langage statistiques, n-gramme, multigramme, évaluation',\n",
              " \"Étiquetage grammatical, règle de succession, taille des règles, chaînage de règles, règle attestée, règle simulée, discriminance, couverture, évaluation en usage vs évaluation en définition d'un ensemble de règles\",\n",
              " 'analyse syntaxique, ambiguïté de rattachement prépositionnel, sous-catégorisation syntaxique',\n",
              " 'collocations, acquisition semi-automatique, corpus comparables',\n",
              " 'lexique informatisé, incomplétude lexicale, mots inconnus, typologie',\n",
              " 'langue des Signes Française, descritpion du geste, morphème, kinème, phonème, chérème',\n",
              " \"information biographique, modélisation, extraction d'information, transducteur à états finis, entité nommée, relation, base de connaissances\",\n",
              " \"repérage automatique d'informations évolutives, TAL, corpus de textes encyclopédiques, marqueurs textuels et discursifs\",\n",
              " 'termes complexes, traduction automatique, mondes lexicaux, World Wide Web',\n",
              " 'chaîne coréférentielle, détection automatique, variante de terme, anaphore nominale',\n",
              " 'compréhension de texte, analyse syntaxique, désambiguïsation, interface syntaxe-sémantique, reconnaissance de schémas, logique des prédicats, unification, rôles thématiques, contraintes de sélections, VerbNet, WordNet, Link Grammar Parser',\n",
              " 'langue des signes, représentation, lexique, paramètres, géométrie spatiale',\n",
              " 'lexique syntaxique, HPSG, Lexical Markup Framework, projection lexicale',\n",
              " 'TALN, NooJ, langue arabe, analyse lexicale, analyse morphologique, grammaire morphologique, agglutination, voyellation',\n",
              " 'hypothèses concurrentes, architecture de contrôle, aide multicritère à la décision',\n",
              " 'classifieur bayésien naïf, coréférence, entités nommées',\n",
              " 'désambiguïsation sémantique, modèle vectoriel, traitement de la parole arabe, influence sémantique',\n",
              " \"correcteur orthographique, correcteur grammatical, français, outils de correction linguistique, Microsoft, réforme de l'orthographe, féminisation des noms de métier\",\n",
              " 'polysémie, co-occurrences, correspondances de traduction, prédiction de traduction',\n",
              " 'analyseur morphologique, morphologie à deux niveaux',\n",
              " 'sémantique lexicale, sémantique quantitative, spécificités, polysémie, co-occurrences, analyse de régression',\n",
              " \"analyse syntaxique, motifs lexico-syntaxiques, analyse lexicale, ressources linguistiques, formats d'échange, automates finis, réseaux de transitions récursifs\",\n",
              " \"traduction automatique de la parole, modélisation du langage, grammaire d'unification, reconnaissance linguistique, grammaires multi-lingues\",\n",
              " \"disfluences, analyse syntaxique en dépendances, traitement automatique de l'oral\",\n",
              " 'acquisition, concepts bilingue, alignement superficiel, Web',\n",
              " 'relations sémantiques, ressources lexicales, analyse distributionnelle',\n",
              " \"synthèse d'information, résumés multi-documents, évaluation du résumé\",\n",
              " 'lexique-grammaire, M. Gross, sous-catégorisation',\n",
              " \"grammaire d'arbres adjoints, calcul sémantique\",\n",
              " 'système de questions-réponses, questions booléennes',\n",
              " 'morphologie, corpus journalistique, -Able, -ité, productivité morphologique quantitative',\n",
              " 'syntaxe, coordination, développement de grammaire, grammaires de propriétés (GP), grammaires de construction (CxG)',\n",
              " 'thesaurus, système de question-réponse, similarité',\n",
              " 'dictionnaire électronique, flexion, formes dérivées',\n",
              " 'co-référence, anaphore, contexte, perception visuelle, saillance',\n",
              " 'traduction probabiliste, adaptabilité, aspiration de bi-textes, mémoire de traduction',\n",
              " 'systèmes de question-réponse',\n",
              " \"automates à nombre fini d'états, transducteurs, dictionnaires électroniques\",\n",
              " 'sémantique inférentielle, raisonnement non monot-one, causalité',\n",
              " 'résolution des références, dialogue humain, évaluation quantitative',\n",
              " 'classes sémantiques, nuances de sens, acquisition sur corpus',\n",
              " \"nominalisation, groupe nominal prédicatif, marqueurs prépositionnels, extraction d'information\",\n",
              " \"analyse syntaxique, fouille d'erreurs\",\n",
              " 'lexique, TAL, syntaxe, lexique-grammaire, sous-catégorisation, standardisation',\n",
              " 'dialogue homme-machine, reconnaissance automatique de la parole, apprentissage automatique à base de corpus',\n",
              " 'questions-réponses, prédiction de la difficulté, SVM, arbres de décision',\n",
              " 'évolution terminologique, corpus diachronique, terme complexe, variation terminologique, distance',\n",
              " 'ressources lexico-sémantiques, dictionnaire sémique, sémantique textuelle, classification automatique, CAH, Jaccard',\n",
              " 'analyse du discours, formalisation du discours, approche par contraintes',\n",
              " 'phrase nominale arabe, grammaire HPSG, schéma adapté, analyse syntaxique',\n",
              " 'segmentation automatique, évaluation, accord interjuges',\n",
              " \"analyseur syntaxique, modèle des patrons, indice de corrélation, Grammaires de Propriétés, technique d'analyse hybride\",\n",
              " 'modélisation statistique du langage, modèles distants, combinaison linéaire',\n",
              " 'dictionnaire multi-lingue, banque terminologique juridique, édition de terme',\n",
              " 'incompréhension, malentendu, acte de dialogue, but de dialogue, stratégie de dialogue, dialogue homme-machine',\n",
              " 'gestion de lexiques, base de données linguistique, ressources linguistiques, multilinguisme, architecture linguistique',\n",
              " 'réseau de neurones, perceptron multi couches, classification, poèmes arabes, syllabes, analyse phonétique',\n",
              " \"relations de contrôle, spécifications des besoins, extraction d'information, contrôle, sémantique, annotation automatique\",\n",
              " 'traduction assistée par ordinateur, mémoire de traduction sous-phrastique, récupération sensible au contexte, détection du domaine de traduction',\n",
              " 'analyse morphologique, désambiguïsation morphologique, TALN arabe',\n",
              " 'analyse syntaxico-sémantique, ontologies, représentations ontologiques,Web sémantique',\n",
              " 'thésaurus, vecteurs conceptuels, notions de base, évolutivité',\n",
              " \"recherche d'information translangue, corpus comparables, typologie de documents, catégorisation, document scientifique, document vulgarisé\",\n",
              " 'grammaires, syntaxe, lexicalisation, réseaux de transitions récursifs',\n",
              " 'analyseur syntaxique, clitiques, traitement multi-lingue',\n",
              " 'analyse syntaxique partielle, proposition syntaxique, subordination, Prolog, CFG, DCG',\n",
              " \"grammaire d'arbre d'adjoint lexicalisée, LTAG, LTAG avec traits, FB-LTAG, structure des traits, corpus arboré, extraction automatique d'une grammaire, coréen\",\n",
              " 'métaphores conceptuelles, visualisation de corpus, linguistique de corpus',\n",
              " 'traduction automatique statistique basée sur les segments, corpus parallèle, dictionnaire de terminologie bilingue',\n",
              " 'analyse syntaxique, TAG, coordination, ellipses, forêt partagée, forêt de dérivation',\n",
              " 'classification spectrale continue, segmentation de textes, identification de langue',\n",
              " 'modèles de langage, adaptation, utilisateur, thème, aide au handicap',\n",
              " 'analyse sémantique, modèle probabiliste, extraction automatique, contexte pertinent, information mutuelle moyenne',\n",
              " 'Analogie, proportion, chaîness de symboles, traduction automatique,divergences entre langues',\n",
              " 'commande en langue naturelle, analyse structurelle de surface, modélisation logique, ontologies',\n",
              " \"TAL, ALAO, détection d'erreurs, morphologie flexionnelle, rétroaction(s)\",\n",
              " 'définition terminographique, annotation automatique, repérage de frontière, indices morpho-syntaxiques, sous-langage',\n",
              " \"extraction de paraphrases, fusion d'articles, mesure de similarité, distance sémantique, identification d'hyperonyme, WordNet, Wikipedia, entités nommées, analyse syntaxique, désambiguïsation lexicale, cadres de sous-catégorisation, apprentissage\",\n",
              " 'Fonctions lexicales (non standard), modélisation des relations sémanticolexicales, DiCo',\n",
              " 'communication homme machine multimodale, référence, saillance',\n",
              " \"réseaux sémantiques, accès lexical, profil d'utilisateur\",\n",
              " \"extraction d'information, analyse de réseaux sociaux, biographies, entités nommées, représentation de connaissances\",\n",
              " \"ressource prédicative, extraction d'information, patrons lexico-syntaxiques\",\n",
              " \"corpus de requêtes d'assistance, agent conversationnel, activité conversationnelle, actes de dialogue\",\n",
              " 'alignement multilingue, corpus parrallèles, multitextes, multi-documents, extraction de structures, alignement endogène',\n",
              " \"système de questions-réponses, recherche d'information, évaluation, focus\",\n",
              " \"segments d'information évolutive, segmentation, algorithme TextTiling\",\n",
              " 'corpus oraux, annotation, disfluences, prosodie, XML',\n",
              " 'génération, dialogue, architecture modulaire, portabilité, XML',\n",
              " 'analyse de discours, résolution anaphorique, anaphore pronominales, anaphores zéro, grammaires de propriétés, grammaire fonctionnelle, analyse dynamique, discours oral',\n",
              " \"Antidote RX est la sixième édition d'Antidote, un logiciel d'aide à la rédaction développé et commercialisé par la société Druide informatique. Antidote RX comporte un correcteur grammatical avancé, dix dictionnaires de consultation et dix guides linguistiques. Il fonctionne sous les systèmes d'exploitation Windows, Mac OS X et Linux.\",\n",
              " \"Cordial est un correcteur efficace et discret enrichi d'un grand nombre de fonctions d'aide à la rédaction et d'analyse de documents. Très riche avec ces multiples dictionnaires et souvent pertinent dans ses propositions, Cordial est un compagnon précieux qui vous permet d'assurer la qualité de vos écrits. La version 2007 de Cordial s'intègre dans un vaste éventail de logiciels comme les traitements de texte (Word, Open Office, Word Perfect...), clients de messagerie (Outlook, Notes, Thunderbird, webmails...) ou navigateurs (Explorer, Mozilla).\",\n",
              " 'traduction assistée par ordinateur, vérification automatique de traductions, révision de traduction',\n",
              " \"Créé en 2005 à l'initiative du Centre National de la Recherche Scientifique, le CNRTL propose une plate-forme unifiée pour l'accès aux ressources et documents électroniques destinés à l'étude et l'analyse de la langue française. Les services du CNRTL comprennent le recensement, la documentation (méta-données), la normalisation, l'archivage, l'enrichissement et la diffusion des ressources. La pérennité du service et des données est garantie par le soutien institutionnel du CNRS, l'adossement à un laboratoire de recherche en linguistique et informatique du CNRS et de Nancy Université (ATILF – Analyse et Traitement Informatique de la Langue Française), ainsi que l'intégration dans le réseau européen CLARIN (common language resources and technology infrastructure european).\",\n",
              " 'réseaux de neurones, réseaux de Hopfield, résumé, frontière thématiques',\n",
              " 'extraction de relations sémantiques, patrons lexico-syntaxiques, domaine médical',\n",
              " 'réseaux bayésiens, résolution des anaphores, connaissance linguistique, indice de surface',\n",
              " 'évaluation, analyse morphologique, mots inconnus, morphologie constructionnelle',\n",
              " 'morphologie à deux niveaux, transducteurs finis à états, structure de traits',\n",
              " 'analyse morphosémantique, composition savante, terminologie médicale',\n",
              " 'analogie formelle, enrichissement de lexiques bilingues, traduction automatique',\n",
              " 'traduction artificielle, terminologie biomédicale, apprentissage artificiel, modèles de langue',\n",
              " 'SMS, SMS corpus, correction orthographique, TiLT, evaluation',\n",
              " 'génie linguiciel, langages spécialisés pour la programmation linguistique, LSPL, environnement de développement, EDL, TAO, systèmes distribués hétérogènes',\n",
              " 'évaluation, moteur de recherche, corpus oral',\n",
              " 'développement de grammaire, ressource pour le TAL, grammaire du français, syntaxe, linguistique formelle, linguistique descriptive, grammaires de propriétés (GP)',\n",
              " 'grammaires catégorielles de dépendances, grammaires multimodales, analyseur syntaxique',\n",
              " \"analyseur syntaxique, grammaires d'arbres adjoints, construction sémantique, architecture logicielle\",\n",
              " 'traitement automatique des langues, désambiguïsation, sémantique, polysémie adjectivale, construction dynamique du sens, synonymie, classes distributionnelles, corpus, espace sémantique, espace distributionnel',\n",
              " 'désambiguïsation contextuelle, similarité sémantique, substituabilité, traduction',\n",
              " 'prépositions, lexique, analyse syntaxique',\n",
              " 'lexique syntaxique, Lexique-Grammaire, DICOVALENCE, Lefff',\n",
              " 'étiqueteur sémantique, dictionnaire, LMF, XML, XPATH',\n",
              " 'erreur cachée, erreur sémantique, détection, correction, système multi-agent, langue arabe',\n",
              " 'dialogue homme-machine, résolution de la référence, évaluation, compréhension dans le dialogue',\n",
              " \"multilingue, FrameNet, annotation sémantique automatique, sémantique lexicale, projection d'annotation de rôles, rôles sémantiques\",\n",
              " 'antidote, co-occurrences, collocations, corpus, analyseur, correcteur',\n",
              " 'Word-Net, vecteurs conceptuels, informations lexicales, informations thématiques',\n",
              " \"alignement monolingue, distance d'édition avec déplacements, critique génétique textuelle\",\n",
              " 'analyse syntaxique, lexique, apprentissage, correction',\n",
              " \"interface syntaxe et sémantique, sémantique formelle, grammaires d'arbres adjoints, grammaires catégorielles\",\n",
              " 'lexique syntaxique, évaluation',\n",
              " \"analyse automatique vs interactive, annotation séquentielle, parallèle, voyellation, lemmatisation, étiquetage de l'arabe, métrique pour l'évaluation de l'analyse interactive\",\n",
              " 'analyseur morpho-syntaxique, apprentissage automatique, acquisition des langues',\n",
              " 'familles morphologiques, classification, apprentissage non supervisé',\n",
              " 'temps, aspect, sémantique, apprentissage non supervisé, fouille de données',\n",
              " \"discours, grammaires d'arbres adjoints (synchrones), interface syntaxe/sémantique\",\n",
              " \"alignement de phrases, corpus parallèle, recherche cross-lingue d'information\",\n",
              " \"désambiguïsation lexicale automatique, corpus sémantiquement étiqueté, co-occurrences, sélection d'indices, algorithmes génétiques\",\n",
              " 'linguistique textuelle, énonciation, représentation sémantique',\n",
              " 'chunker, super-chunks, analyse syntaxique, patrons lexico-syntaxiques',\n",
              " 'prédiction de la satisfaction usager, classification des dialogues Personne-Machine',\n",
              " 'traduction automatique de la parole, reconnaissance de la parole, ellipses, évaluation, traitement du dialogue, modèle du language fondé sur les grammaire',\n",
              " \"détection d'opinions, classification automatique, reconnaissance automatique de la parole, champs conditionnels aléatoires\",\n",
              " \"réalisation de surface, grammaire d'arbres adjoints, réversibilité\",\n",
              " 'système de questions/réponses, questions définitoires',\n",
              " \"linguistique des corpus, corpus comparable, algorithmes d'apprentissage, analyse stylistique, degré de comparabilité\",\n",
              " \"plateforme d'annotation linguistique, passage à l'échelle, robustesse\",\n",
              " 'dictionnaires bilingues, traduction automatique, graphe multi-lingue, algorithme, polysémie verbale, dissymétrie lexicographique',\n",
              " \"traduction automatique, paraphrase, restructuration syntaxique, TST (Théorie Sens-Texte), grammaire de dépendance, fonction lexicale, lexique bilingue, GUP (Grammaire d'Unification Polarisée), grammaire de correspondance, grammaires synchrones\",\n",
              " 'langue arabe, paradigmes de flexion verbale, base lexicale, norme ISO 24613, LMF, lexical markup framework, conjugueur des verbes arabes',\n",
              " \"ALAO, apprentissage des langues, diagnostic d'erreur, feed-back d'erreur\",\n",
              " 'français, corpus arboré, sous-catégorisation verbale, lexique-grammaire',\n",
              " \"Grammaire d'Unification Sens-Texte, Théorie Sens-Texte, sémantique, représentation du sens, paraphrasage\",\n",
              " 'systèmes de questions-réponses, validation de réponses',\n",
              " 'ressources linguistiques pour le chinois, linguistique de corpus, NooJ',\n",
              " 'Étiquetage morpho-syntaxique, corpus de textes, langue kabyle, berbère',\n",
              " 'analyseur grec, analyse morpho-syntaxique, syntagme nominal, grec moderne',\n",
              " 'apprentissage symbolique, modèle de Gold, grammaires catégorielles',\n",
              " 'alignement des corpus parallèles, appariement de graphes, classification ascendante hiérarchique, proposition syntaxique, mémoire de traduction, linguistique contrastive',\n",
              " 'acquisition lexicale, lexique de référence du français, modèle du lexique génératif, morphologie constructionnelle, corpus, sémantique',\n",
              " 'analyseur syntaxique, évaluation, français',\n",
              " 'traduction automatique, approche statistique, modélisation linguistique dans un espace continu, analyse morpho-syntaxique, désambiguïsation lexicale',\n",
              " 'réécriture de phrases, dyslexie, automates, correction orthographique',\n",
              " 'méthodologie de contrôle, aide multicritère à la décision, apprentissage automatique de métriques',\n",
              " 'corpus, écrits scientifiques, classes sémantiques, analyse distributionnelle',\n",
              " 'compréhension automatique de la parole, résolution des références, dialogue oral homme-machine',\n",
              " 'analyse sémantique, modèle de langage stochastique, contexte pertinent, information mutuelle moyenne, parole arabe spontanée',\n",
              " \"Recherche d'information, Traitement Automatique des Langues, systèmes de questions-réponses\",\n",
              " 'Annotation temporelle, repérage des événements, TimeML',\n",
              " 'Grammaire Interactive, modèles dynamiques, dialogue homme-machine, système de question-réponse, morphosyntaxe, expérimentation utilisateur, formulation de réponse',\n",
              " 'entités nommées, annotation, grammaires locales, Nooj, base de connaissances',\n",
              " 'Analyse Syntaxique, Japonais, Grammaire',\n",
              " 'Compréhension du langage, langue parlée spontanée',\n",
              " \"Identification d'opinions, Fouille de textes, Traitement automatique du langage naturel\",\n",
              " 'Induction lexicale, transducteurs stochastiques, langues apparentées',\n",
              " 'génération intégrée localisée, architectures de génération, SDRT, segmentation du discours',\n",
              " 'génération automatique, dictionnaire, conditions de structure morphématique',\n",
              " 'citations, contruction et étude de corpus, genre journalistique',\n",
              " 'Question réponse enchainée',\n",
              " 'correction grammaticale, syntagme, unification',\n",
              " \"extraction d'information, annotation, informations spatio-temporelles, tourisme, pages Web\",\n",
              " 'Alignement, proposition syntaxique, études contrastives français-japonais, similarité lexicale',\n",
              " \"Unification, grammaire d'arbres adjoints, arbre de dérivation, grammaire rationnelle d'arbres\",\n",
              " \"Méthodes d'évaluation, segmentation de texte, segmentation thématique\",\n",
              " 'Grammaire Sémantique, Réversibilité, Analyse, Génération, Dialogue',\n",
              " 'Modèle sémantique, analyse syntaxique en dépendance, DRT',\n",
              " 'Lexiques, plate-forme de validation, cadres de sous-catégorisation',\n",
              " \"Classification de textes, Modèle probabiliste, Ressources humaines, Offres d'emploi\",\n",
              " 'Machine finie à états, morphologie à deux niveau',\n",
              " \"Dialogue finalisé, multimodalité, évaluation pour le dialogue homme-machine, paradigme d'évaluation, test utilisateur, diagnostic, paraphrase multimodale\",\n",
              " 'ressource lexicale, morphologie dérivationnelle, traitement automatique des familles de mots',\n",
              " 'morphologie, traduction automatique, génération, néologisme, études empiriques',\n",
              " 'Traitement Automatique du Langage Parlé (TALP), segmentation, chunks, parole conversationnelle, transducteurs, Unitex',\n",
              " \"Regroupement de documents, Suivi d'événement\",\n",
              " 'détection de citations, classification des styles de discours rapporté, identification du locuteur, techniques par apprentissage et base de règles, écrits journalistiques',\n",
              " 'Actes de langage complexes, structure du dialogue, terrain commun',\n",
              " \"Sous-langage, représentation évènementielle, extraction d'information, structure prédicative, structure predicate-arguments\",\n",
              " 'Traduction automatique multi-lingue, approche par objets, génération de lexiques bilingues',\n",
              " 'Entités nommées, Appariement, Mesures de similarité textuelle, Apprentissage supervisé',\n",
              " 'Graphe sémantique, logique, quantification, Théorie Sens-Texte (TST)',\n",
              " 'compréhension automatique de la parole, système de dialogue oral, frames sémantiques, décodage conceptuel, annotation sémantique, inférence sémantique',\n",
              " \"recherche d'information, langue arabe, indexation, lemmatisation, Google\",\n",
              " \"Normalisation syntaxique, Détection d'implication textuelle, Réécriture de graphe\",\n",
              " 'expressions temporelles calendaires, modélisation algébrique, visualisation',\n",
              " \"Extraction d'informations temporelle, TimeML\",\n",
              " 'segmentation en sujets, corpus oraux, cohésion lexicale, indices acoustiques, indices syntaxiques',\n",
              " 'extraction automatique, micro-texte, texte non structuré, petites annonces',\n",
              " 'Système de Questions/Réponses, compacité, densité, combinaison de scores',\n",
              " 'Dialogue homme-machine, cohérence discursive, connecteurs concessifs, sémantique, pragmatique',\n",
              " 'dialogue homme-machine, robustesse, ancrage, compréhension mutuelle',\n",
              " 'Énergie textuelle, Réseaux de neurones, Modèle de Hopfield, Résumé automatique, Frontières thématiques',\n",
              " 'Résumé automatique, pré-filtrage de phrases, optimisation multi-objectif, algorithme génétique',\n",
              " 'Traduction statistique, recherche locale, post-traitement',\n",
              " 'SMS, décodage phonétique, modèles de langage, transducteurs finis',\n",
              " \"Grammaires d'arbres adjoints à composantesmultiples, grammaires à concaténation d'intervalles, légère sensibilité au contexte\",\n",
              " 'Analyseur syntaxique, dépendance',\n",
              " 'TAG, modélisation, grammaire, variation dialectale',\n",
              " 'Analyseur syntaxique statistique, Analyse syntaxique non lexicalisée, Analyse du français',\n",
              " 'Wordnet, corpus alignés, Wikipédia, sémantique lexicale',\n",
              " \"Traitement Automatique du Langage Naturel, réseau lexical, relations typées pondérées, sens d'usage d'un terme, jeu en ligne\",\n",
              " 'Dictionnaire électronique Arabe, usage éditorial, modèle normalisé, LMF, interrogation générique',\n",
              " 'polysémie régulière, métaphore, métonymie, Word-Net, désambiguïsation lexicale',\n",
              " 'Traduction Automatique Statistique, Triggers Inter-Langues, Information Mutuelle, Corpus parallèle, Décodage',\n",
              " 'Paraphrase, Traduction Automatique Statistique basée sur les segments, Aide à la rédaction',\n",
              " \"Traduction Automatique, TA, TAO, architecture linguistique, architecture computationnelle, TA experte, TA par règles, TA empirique, TA statistique, TA par l'exemple\",\n",
              " 'Entités nommées, Analyse syntaxique robuste, Types sémantiques',\n",
              " 'Désambiguïsation non supervisée, treillis de Galois, entités nommées',\n",
              " 'Entités Nommées, métonymie, méthode hybride, analyse syntaxique robuste, approche distributionnelle',\n",
              " 'étiquetage automatique, terminologie médicale arabe, morpho-syntaxe, sémantique',\n",
              " 'Analyse syntaxique, étiquetage morpho-syntaxique, analyseur stochastique, analyseur symbolique superficiel, chunker',\n",
              " 'Analyse et Indexation/méthodes, Medical Subject Headings, Apprentissage Artificiel, Programmation Logique Inductive',\n",
              " 'Apprentissage automatique, classification, co-training',\n",
              " 'Cohésion lexicale, ressources lexicales, analyse distributionnelle, segmentation thématique',\n",
              " 'corpus spécialisé, unité lexicale, lexie, extraction de lexique, chinois',\n",
              " 'espace sémantique, réduction de dimensions, Locality Sensitive Hashing, induction de sens, clustering de mots, objets multi-représentés',\n",
              " 'traduction automatique, web, modèle de langage, méta-moteur de traduction',\n",
              " 'lisibilité, régression logistique, bagging, boosting, modèle de langue',\n",
              " 'syntaxe, grammaires catégorielles abstraites, types dépendant, mouvements explicites, extraction',\n",
              " \"normalisation, entités nommées, traitement de l'information, analyse de corpus, méthodes endogènes, système complexe\",\n",
              " \"Étiquetage d'entités nommées, ressources sémantiques\",\n",
              " 'Distance intertextuelle, arabe, classification, lemmatisation, corpus, statistique lexicale',\n",
              " 'Argumentation, Insinuation, Norme coutumières, Justification',\n",
              " 'Analyse syntaxique probabiliste, corpus arborés, évaluation, analyse du français',\n",
              " 'Analyse morphologique, Annotation sémantique, Composition savante, Noms déverbaux, Règles, Analogie',\n",
              " \"Analyse syntaxique, grammaires de dépendances, grammaires d'interaction, polarité\",\n",
              " 'grammaticalité, analyse syntaxique, contraintes, syntaxe modèle-théorique',\n",
              " \"annotation de corpus, structures de discours, interface d'annotation\",\n",
              " 'Systèmes de questions-réponses, analyse syntaxique, évaluation',\n",
              " 'co-occurrences, collocations, correction grammaticale',\n",
              " 'guesser, lexiques morpho-syntaxiques, aide aux linguistes, induction des règles de flexion',\n",
              " \"fouille d'opinion, langage évaluatif, catégorisation des évaluations\",\n",
              " 'Annotation, expressions temporelles, ontologies, base de connaissance, tourisme',\n",
              " \"Annotation sémantique, valeur de Shapley, plate-forme d'annotation\",\n",
              " 'Emotion, valence émotionnelle, norme lexicale émotionnelle, robot compagnon, compréhension de parole',\n",
              " 'morpho-phonologie lexicale, traitement automatique des familles dérivationnelles, espaces sémantiques',\n",
              " 'Question réponse enchaînée',\n",
              " \"Compréhension mutuelle, processus d'ancrage, référence, génération\",\n",
              " 'gestion du dialogue Homme-machine, dialogue oral arabe, modèle de tâche, modèle de dialogue',\n",
              " 'Correcteur grammatical, analyse syntaxique, forêt partagée',\n",
              " 'TimeML, verbes support, discours, sémantique',\n",
              " 'Lexiques syntaxiques, Lexique-Grammaire, analyse syntaxique',\n",
              " 'verbe, syntaxe, lexique, sous-catégorisation',\n",
              " 'Analyse syntaxique, analyse sémantique, évaluation, Passage',\n",
              " 'Linguistique de corpus, Annotation, Plate-forme logicielle',\n",
              " 'dictionnaire morphologique du français, CMLF, analyse linguistique des textes',\n",
              " 'réutilisation de texte, recouvrement de n-grams hapax, similarités discursives, corpus journalistique francophone',\n",
              " 'systèmes de réponse à une question, expérience, variations linguistiques, réponse en langue naturelle',\n",
              " 'Phonétisation, phonémisation, inférence de règles de réécriture, challenge Pronalsyl, conversion graphème-phonème, translittération',\n",
              " \"Traduction automatique statistique, désambiguïsation lexicale, réévaluation de listes d'hypothèses\",\n",
              " \"Typologie et analyse d'erreurs textuelles, assistance à la saisie de textes\",\n",
              " 'Terminologie, distance sémantique, relations sémantiques, synonymie',\n",
              " 'analyse syntaxique incrémentale, langue arabe, apprentissage automatique, classification, attributs discriminants',\n",
              " 'Rectifications orthographiques de 1990, conversion ancienne / nouvelle orthographe, objectifs didactiques, machines à états finis',\n",
              " \"Résumé automatique de texte, Approches à base de graphes, Extraction d'information\",\n",
              " \"audio-mining, text mining, segmentation, classification, catégorisation, reconnaissance vocale, données textuelles, conversations téléphoniques, centre d'appel\",\n",
              " 'segmentation multiple, langue non segmentée, modélisation statistique du langage',\n",
              " 'Traitement Automatique du Langage Naturel, réseau lexical évolutif, relations typées pondérées, similarité entre sens et usages, arbre des usages',\n",
              " 'Dialogue oral spontané, Analyse linguistique de corpus, Compréhension robuste, Contrôle Aérien, Phraséologie, Disfluences, Modèles de langage, Traitement Automatique du Langage Naturel',\n",
              " \"Analyse syntaxique déductive, grammaires à concaténation d'intervalles\",\n",
              " 'Analyse sémantique tabulaire, contexte dialogique, évaluation',\n",
              " 'Compression de phrases, Résumé automatique, Résumé par extraction, Enertex, Mécanique statistique',\n",
              " 'Catégorisation de textes, écriture en-ligne, n-best candidats, pondération',\n",
              " 'Traduction automatique, dialectes, langues proches, langues germaniques',\n",
              " \"Le modèle PLSI (« Probabilistic Latent semantic Indexing ») offre une approche de l'indexation de documents fondée sur des modèles probabilistes de catégories sémantiques latentes et a conduit à des applications dans différents domaines. Toutefois, ce modèle rend impossible le traitement de documents inconnus au moment de l'apprentissage, problème particulièrement sensible pour la représentation des requêtes dans le cadre de la recherche d'information. Une méthode, dite de « folding-in », permet dans une certaine mesure de contourner ce problème, mais présente des faiblesses. Cet article introduit nouvelle une mesure de similarité document-requête pour PLSI, fondée sur lesmodèles de langue, où le problème du « folding-in » ne se pose pas. Nous comparons cette nouvelle similarité aux noyaux de Fisher, l'état de l'art en la matière. Nous présentons aussi une évaluation de PLSI sur un corpus de recherche d'information de près de 7500 documents et de plus d'un million d'occurrences de termes provenant de la collection TREC–AP, une taille considérable dans le cadre de PLSI.\",\n",
              " 'Segmentation thématique, désambiguïsation sémantique',\n",
              " 'dépendances, chunk, édition',\n",
              " 'Paraphrase, acquisition de données, évaluation de données',\n",
              " 'alignement sous-phrastique, multilinguisme, table de traduction',\n",
              " \"Ontologie, construction d'ontologie, TALN\",\n",
              " \"Recherche d'information, Extraction d'information, Terminologie\",\n",
              " \"morphologie flexionnelle, déclinaison tchèque, acquisition d'une langue étrangère, diagnostic des erreurs et feed-back, ELAO\",\n",
              " 'TA via UNL, démonstrateur de composants UNL, assistant linguistique sur le Web, phrasebook digital multi-lingue, mémoire de traduction, collecte collaborative de corpus',\n",
              " 'Analyse de sentiments',\n",
              " 'Plate-forme, Annotation automatique, Exploration Contextuelle, analyse sémantique, marqueurs discursifs, carte sémantique, multilinguisme',\n",
              " 'Linguistique de corpus, Annotation, Plate-forme logicielle',\n",
              " 'corpus, lexique, analyseur, japonais, chinois',\n",
              " 'Apache UIMA, Applications du TAL, Infrastructure logicielle',\n",
              " 'Apache UIMA, Applications du TAL, Infrastructure logicielle',\n",
              " 'chunking, multi-lingue, endogène, longueur des mots, effectif des mots',\n",
              " 'Morphologie dérivationnelle, morphologie lexématique, similarité morphologique, analogie formelle',\n",
              " \"Analyse syntaxique, grammaires d'interaction\",\n",
              " 'Analyse syntaxique, reconnaissance automatique de la parole',\n",
              " 'Analyseur syntaxique statistique, analyse en constituants/dépendances, étiquetage en fonctions grammaticales',\n",
              " 'fonctions syntaxiques, Conditional Random Fields, corpus arborés',\n",
              " 'Mult-ilinguisme, corpus comparable, extraction de lexiques bilingues',\n",
              " 'Étiquetage, Entités nommées, classification, taxonomie',\n",
              " 'Apprentissage analogique, analogie formelle, analyse morphologique',\n",
              " 'traduction probabiliste, corpus bilingue, alignement de documents, table de traduction',\n",
              " \"Corpus comparable, extraction de lexiques bilingues, points d'ancrage\",\n",
              " 'alignement au niveau des mots, concordancier bilingue, traduction automatique',\n",
              " \"jugement d'évaluation, constituants extra-prédicatifs, constructions et lexiques subjectifs, Appraisal, implémentation informatique, portraits et biographies dans la presse de spécialité et la presse d'information\",\n",
              " \"Traitement automatique des langues naturelles, Génération de texte, Analyse de données, Unité de soins intensifs, Systèmes d'aide à la décision\",\n",
              " 'Adjectifs relationnels, ressources lexicales, morphologie constructionnelle',\n",
              " \"Extraction d'information, fouille de textes, motifs séquentiels, interactions entre gènes\",\n",
              " 'Traduction automatique statistique, contexte source, dépendances syntaxiques',\n",
              " 'Temporalité, typage et caractérisation des expressions temporelles',\n",
              " 'Segmentation thématique, évaluation, distance de Hamming généralisée, WindowDiff',\n",
              " \"repérage automatique de l'obsolescence, indices sémantiques et discursifs, textes encyclopédiques, classification supervisée, aire sous la courbe ROC\",\n",
              " 'résumé automatique, analyse de textes subjectifs, évaluation automatique',\n",
              " \"Cet article décrit une méthodologie visant la réalisation d'une ressource sémantique en français centrée sur la synonymie. De manière complémentaire aux travaux existants, la méthode proposée n'a pas seulement pour objectif d'établir des liens de synonymie entre lexèmes, mais également d'apparier les sens possibles d'un lexème avec les ensembles de synonymes appropriés. En pratique, les sens possibles des lexèmes proviennent des définitions du TLFi et les synonymes de cinq dictionnaires accessibles à l'ATILF. Pour évaluer la méthode d'appariement entre sens d'un lexème et ensemble de synonymes, une ressource de référence a été réalisée pour 27 verbes du français par quatre lexicographes qui ont spécifié manuellement l'association entre verbe, sens (définition TLFi) et ensemble de synonymes. Relativement à ce standard étalon, la méthode d'appariement affiche une F-mesure de 0.706 lorsque l'ensemble des paramètres est pris en compte, notamment la distinction pronominal / non-pronominal pour les verbes du français et de 0.602 sans cette distinction.\",\n",
              " 'Résolution de co-références, apprentissage automatique, linguistique informatique par contraintes',\n",
              " \"Acquisition et correction lexicale, lexique à large couverture, fouille d'erreurs, étiqueteur syntaxique, classifieur d'entropie, analyseur syntaxique\",\n",
              " 'Analyse syntaxique de surface, automates à états finis, déterminisme, désambiguïsation',\n",
              " 'Résumé automatique, structure de documents',\n",
              " \"Entités nommées, fusion d'annotations, UIMA\",\n",
              " 'Traduction Automatique, Unités Lexicales Complexes, Désambiguïsation lexicale, World Wide Web, Terminologie',\n",
              " 'Multimodalité, interaction entre domaines, grammaire, corpus multimodaux',\n",
              " \"annotation, reconnaissance d'entités nommées\",\n",
              " 'Traduction automatique statistique, corpus bilingue, direction de la traduction, langue source, langue cible',\n",
              " 'Désambiguïsation lexicale, Traduction Automatique Statistique, sélection lexicale',\n",
              " 'Évaluation, Dialogue',\n",
              " \"Attribution d'auteur, modèle de langue, stylométrie, n-grammes, vecteurs de traits\",\n",
              " 'densité des idées, analyse prédicative, étiquetage sémantique, psycholinguistique',\n",
              " 'Textométrie, comparaison des segmenteurs chinois, nombre de syllabes',\n",
              " 'relation, entité nommée, grammaire',\n",
              " 'corpus monolingue parallèle, paraphrases, traductions multiples',\n",
              " 'Repérage des événements nominaux, annotation temporelle',\n",
              " \"Analyse d'opinion, Extension de lexique, Annotation d'opinions\",\n",
              " 'Théorie de la Structure Rhétorique, Relations rhétoriques, Marqueurs linguistiques, Résumé automatique de textes arabes',\n",
              " 'Logique Combinatoire, Référentiel énonciatif, Schème sémantico-cognitif, Grammaire Applicative et Cognitive, Haskell',\n",
              " 'Terminologie, définitions terminographiques, sélection des traits, pertinence des traits, extraction de définitions, contextes conceptuels, traitement automatique des définitions.',\n",
              " \"représentation des textes, représentation vectorielle, traitement de textes courts, regroupements d'opinions\",\n",
              " 'corpus comparables monolingues, morphologie constructionnelle, langue de spécialité',\n",
              " \"réseau lexical, arbre des usages nommés d'un terme, pondération des sens d'un terme\",\n",
              " 'Générateur de paraphrase, évaluation des paraphrases',\n",
              " 'Wikipedia, plus court chemin, désambiguïsation, classification, traduction de requête',\n",
              " 'pseudo-phrase, phrase averbale, analyse syntaxique et sémantique',\n",
              " 'Système de question-réponse, questions complexes',\n",
              " 'Langue amazighe, Pseudo-racinisation, Morphologie flexionnelle',\n",
              " \"Interface syntaxe-sémantique, graphe sémantique, grammaires de dépendance, GUP (Grammaire d'unification polarisée), GUST (Grammaire d'unification Sens-Texte)\",\n",
              " 'Analyseur syntaxique, traduction automatique, pronoms clitiques, proclise, enclise',\n",
              " 'sémantique lexicale, antonymie, analyse distributionnelle, patrons lexico-syntaxiques',\n",
              " 'outils de text mining, modélisation de concepts métier, classification supervisée',\n",
              " 'étiquetage grammatical, Modèle de Markov caché, UIMA, Brill, TreeTagger',\n",
              " 'Corpus comparables, Saillance, Segmentation, Textes historiques',\n",
              " 'mots inconnus, incomplétude lexicale, acquisition dynamique des ressources lexicales',\n",
              " 'sémantique lexicale, terminologie, corpus, richesse lexicale, lexicométrie',\n",
              " 'Emotion, valence émotionnelle, norme lexicale émotionnelle, robot compagnon, compréhension de parole',\n",
              " 'Paraphrase, Patrons de correspondances de segments monolingues',\n",
              " 'ressources lexicales françaises, Word-Net, relations sémantiques, distributions syntaxiques',\n",
              " \"entités nommées, évaluation, extraction d'information\",\n",
              " \"entités nommées, évaluation, extraction d'information\",\n",
              " 'Chaînes de référence, relation de co-référence, saillance, genre textuel',\n",
              " \"résolution d'entités nommées, détection d'entités nommées, extraction d'information\",\n",
              " 'système de dialogue oral, compréhension de la parole, composition sémantique, frame sémantique, séparateur à vaste marge',\n",
              " 'Entité nommée, événement, rapports de cause et conséquence',\n",
              " 'Analyse de sentiments, ANEW, Twitter',\n",
              " \"Analyse d'opinion, théorie de l'Appraisal\",\n",
              " \"Fouille de données, motifs séquentiels, extraction d'information, apprentissage de patrons linguistiques\",\n",
              " 'systèmes de question-réponse, extraction de relations, domaine médical',\n",
              " \"Traitement de la langue arabe, reconnaissance des entités nommées, méthode d'apprentissage\",\n",
              " 'Extraction des connaissances, extraction des patrons, relation des entités nommées, arbre syntaxique dépendanciel',\n",
              " \"Reconnaissance d'Entités Nommées, Séquences Hiérarchiques, Motifs, Ester2\",\n",
              " \"recherche d'information multi-lingue, traduction de requêtes, Wikipédia\",\n",
              " \"recherche d'information multi-lingue, traduction de requêtes, Wikipédia\",\n",
              " 'information thématique, construction de corpus, extraction de termes, découverte de contextes définitionnels',\n",
              " 'Passerelle de traduction interactive, IMAG, post-édition de TA, traduction collaborative',\n",
              " 'Étiquetage des entités nommées, langue arabe, système de veille médiatique',\n",
              " 'Génération de texte, synthèse vocale, expressivité',\n",
              " 'Terminologie bilingue, corpus comparable, Wikipédia, ontologie multi-lingue',\n",
              " 'Langue des signes, corpus vidéo comparables, reconnaissance automatique, génération automatique',\n",
              " 'analyse syntaxique, grammaire générative, services web, tei',\n",
              " 'Dialectologie, atlas linguistique, traduction automatique, identification de dialectes',\n",
              " 'SMS, normalisation, application, plugin, serveur',\n",
              " 'Annotation sémantique, interrogation sémantique, domaine médical',\n",
              " \"Analyse syntaxique, grammaires d'interaction, polarités\",\n",
              " 'Traduction automatique statistique, repérage de traductions, alignement de mots, requêtes linguistiques',\n",
              " 'Traduction automatique statistique, repérage de traductions, alignement de mots, requêtes linguistiques',\n",
              " 'Traduction automatique statistique, repérage de traductions, alignement de mots, requêtes linguistiques',\n",
              " 'Traduction statistique, adaptation du modèle de traduction, corpus monolingue, apprentissage non-supervisé',\n",
              " 'Traduction automatique statistique, alignement de mots, traduction rares, contrôle de pertinence',\n",
              " \"Étiquetage morpho-syntaxique, modèles à maximisation d'entropie, français, lexique\",\n",
              " 'extraction de synonymes, similarité sémantique, méthodes distributionnelles',\n",
              " 'Antidote, co-occurrences, collocations, expressions multi-mots',\n",
              " 'Fouille de textes, Random-Indexing, Cognition, Marche aléatoire',\n",
              " \"Analyse syntaxique, dépendance, grammaires d'interaction, polarité\",\n",
              " 'Syntaxe probabiliste, linguistique de corpus, adjectif épithète, régression logistique',\n",
              " 'Complexité syntaxique, analyse syntaxique automatique, parser humain',\n",
              " 'dépendances, analyse syntaxique, TAG, forêt partagée',\n",
              " 'SMS, normalisation, machines à états finis, approche hybride, orienté traduction, orienté correction, apprentissage sur corpus',\n",
              " 'ressources pour le TAL, correction orthographique, Wikipédia',\n",
              " 'Étiqueteur sémantique, Entités nommées, Analyse sémantique, Ontologie',\n",
              " 'paraphrase lexico-syntaxique, paraphrase sémanique, règles de paraphrasage, corpus bilingues, théorie Sens-Texte',\n",
              " 'Annotation de corpus, organisation du discours, structure énumérative, signalisation',\n",
              " 'Structure actancielle, actants et circonstants, features de classification',\n",
              " 'Entité nommée, ontologie, relations verbales, patrons linguistiques',\n",
              " 'classification de genre vidéo, traitement audio de la vidéo, extraction de paramètres linguistiques',\n",
              " \"étiqueteur d'entités nommées, transcription automatique de parole, apprentissage automatique, champs conditionnels aléatoires, machines à vecteurs de support, transducteurs à états finis\",\n",
              " 'disfluences, segment conceptuel, reconnaissance de patrons, parole arabe spontanée',\n",
              " 'Segmentation thématique, documents oraux, cohésion lexicale, relations sémantiques',\n",
              " 'Segmentation thématique, organisation textuelle, cohésion lexicale, voisins distributionnels',\n",
              " \"Extraction d'information, extraction d'événements, segmentation de textes, indices temporels, apprentissage statistique\",\n",
              " \"Mesures d'évaluation, Résumé automatique de textes\",\n",
              " 'Résumés automatiques, résumés par extraction, résumés manuels',\n",
              " 'systèmes de réponse à une question, variations linguistiques, réponse en langue naturelle, oral et écrit',\n",
              " 'apprentissage non-supervisé, système de traduction automatique, corpus comparable, paires de phrases parallèles',\n",
              " \"traitement interactif de la langue, prise en compte de l'usager, outils de traitement de la langue, apprentissage des langues, dictionnaires, livres de phrases, concordanciers, traduction\",\n",
              " 'lexiques syntaxiques, restrictions de sélection, traits sémantiques',\n",
              " 'recherche contextuelle, équivalents terminologiques, banque de terminologie, désambiguïsation par domaine',\n",
              " 'Dépendances, réécriture de graphes, interface syntaxe-sémantique, DMRS',\n",
              " 'Annotation manuelle, évaluation, accord inter-annotateurs',\n",
              " 'classes de vocabulaire, indexation automatique, extraction automatique, corpus, approche basée sur les corpus, vocabulaire savant de base, ressources lexicales, français',\n",
              " 'Analyse morphologique non supervisée, Analogie formelle, Approche à base de graphe',\n",
              " 'Alignement, terminologie, morphologie, analogie, traduction de terme, kanji',\n",
              " 'Lexique morphologique, Persan, Développement de lexiques, Traitements de surface',\n",
              " 'TLFi, indexation, recherche, images, thésaurus',\n",
              " \"Opinion, évaluation, repérage de phrases évaluatives, presse économique et financière, style journalistique, indices/marques/stéréotypes d'écriture\",\n",
              " 'Complexité, lisibilité, allemand, analyse de surface',\n",
              " \"recherche d'information, ambiguïté, classification de requêtes\",\n",
              " \"extraction d'informations, objets pédagogiques, carte sémantique, exploration contextuelle, algorithme Rocchio\",\n",
              " \"REX, rapport d'incident, risque, sûreté industrielle, signaux faibles, classification automatique, clustering, recherche d'information, similarité, subjectivité\",\n",
              " 'Relation de discours, fermeture discursive, évaluation, déduction',\n",
              " \"Détection d'émotion, analyse de sentiments, fouille d'opinion ; Evaluation : métrique d'évaluation, constitution de référence, analyse statistique des résultats\",\n",
              " 'résumé de texte automatique, résumé extractif, statistiques de co-occurrence, collocations, analyse syntaxique, Wikipedia',\n",
              " 'Lisibilité du FLE, unités polylexicales nominales, modèles N-grammes',\n",
              " \"Détection d'entités nommées, adaptation à un nouveau domaine, coopération entre approches probabilistes et symboliques\",\n",
              " 'Ressources lexicales, familles morphologiques, clusters sémantiques, mesure de Lesk',\n",
              " 'génération de questions, analyse syntaxique, transformation syntaxique',\n",
              " 'systèmes de questions réponses, validation de réponses, analyse de documents Web',\n",
              " \"Extraction d'information non supervisée, filtrage, apprentissage automatique, clustering\",\n",
              " \"extraction d'information, événements nominaux, lexiques\",\n",
              " 'Alignement non-supervisé, compréhension de la parole',\n",
              " 'Recherche de passages, enrichissement de requêtes, contexte, Wikipedia, INEX, entropie',\n",
              " 'Adjectifs dénominaux, dérivation morphologique, lexique dérivationnel',\n",
              " 'Ressource lexicale, validation, étiqueteur morpho-syntaxique, persan, catégories, PerLex, MElt',\n",
              " 'cognat, identification de cognats, corpus parallèles alignés au niveau propositionnel',\n",
              " 'ALAO/ELAO, exercices de dictée, alignement, diagnostic, machines à états finis',\n",
              " 'S-DRT, interaction verbale, schizophrénie, dialogue pathologique, incohérence pragmatique',\n",
              " 'corpus alpin français-allemand, structures arborées parallèles, annotation morpho-syntaxique du français',\n",
              " 'Résumé automatique, ordonnancement de phrases',\n",
              " \"outil semi-automatique, grammaire d'arbres adjoints, langue arabe, traits d'unification\",\n",
              " 'thésaurus distributionnel, similarité sémantique, méthodes non supervisées, lexique',\n",
              " 'Extraction de relations, classification, apprentissage paresseux, modèle de langue, analyse linguistique de surface',\n",
              " 'TimeML, discours, sémantique, phénomènes itératifs',\n",
              " \"modifieurs de valence, fouille d'opinion, lexique de valence\",\n",
              " 'Corpus, Annotation, Exploration, GlozzQL',\n",
              " 'Rôles sémantiques, traits syntaxiques, classification, partitionnement semi-supervisé',\n",
              " 'Extraction de voisins sémantiques, similarité sémantique, méthodes distributionnelles',\n",
              " 'Sémantique lexicale, pragmatique, sémantique compositionnelle',\n",
              " 'corpus, annotations, multimodalité, classification supervisée',\n",
              " \"typage d'entités nommées, comparaison de distribution de mots, divergence de Kullback-Leibler\",\n",
              " 'Traduction (automatique), TransSearch, Discours',\n",
              " 'Identification de paraphrases, extraction de patrons, type de discours, domaine médical, corpus comparable monolingue',\n",
              " 'bases de données lexicales, sous-catégorisation verbale, traduction automatique à base linguistique, japonais',\n",
              " 'Extraction des connaissances, relations entre entités nommées, dualité relationnelle',\n",
              " 'Détection des dislocations à gauche, Maximum Entropy, français parlé',\n",
              " 'morphologie constructionnelle, analyse automatique, règles, analogie, familles morphologiques, comparaison, synergie',\n",
              " 'Bidirectionnel, Classification de Séquence, Apprentissage Guidé',\n",
              " 'Réseau phrastique, Appariement de phrases, Analyse textuelle, Navigation textuelle',\n",
              " \"environnement d'étude de corpus, corpus étiquetés et arborés, création de grammaires assistée, visualisation d'information linguistique\",\n",
              " 'terminologie, préterminologie, approches collaboratives, réseaux lexicaux, DSR, jeux sérieux',\n",
              " \"traduction automatique statistique, analyse morphologique, pré-traitement de l'arabe\",\n",
              " \"Construction d'ontologie, patron lexico-syntaxique, structure textuelle\",\n",
              " 'Analyseur syntaxique, traduction automatique, pronom clitique, séquences clitiques',\n",
              " 'Pronoms, ambiguïté pronominale, étiquetage morpho-syntaxique',\n",
              " 'Pronoms, traduction automatique, analyse syntaxique, anaphores pronominales',\n",
              " 'Sémantique lexicale, Inférence, Glissements de sens',\n",
              " \"détection d'opinions, analyse de sentiments, analyse syntaxique robuste, extraction d'information\",\n",
              " \"Extraction d'information médicale, compte-rendus d'hospitalisation, infection nosocomiale, analyse syntaxique\",\n",
              " \"Extraction d'information médicale, compte-rendus d'hospitalisation, infection nosocomiale, analyse syntaxique\",\n",
              " \"Extraction d'information médicale, compte-rendus d'hospitalisation, infection nosocomiale, analyse syntaxique\",\n",
              " \"Extraction d'information médicale, compte-rendus d'hospitalisation, infection nosocomiale, analyse syntaxique\",\n",
              " 'Analyse syntaxique',\n",
              " \"e-réputation, reconnaissance d'entités nommées, classification, clustering, analyse syntaxique, apprentissage\",\n",
              " \"e-réputation, reconnaissance d'entités nommées, classification, clustering, analyse syntaxique, apprentissage\",\n",
              " \"e-réputation, reconnaissance d'entités nommées, classification, clustering, analyse syntaxique, apprentissage\",\n",
              " \"e-réputation, reconnaissance d'entités nommées, classification, clustering, analyse syntaxique, apprentissage\",\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " 'Analyse de Sentiments, Linguistique de Corpus, Dépêches Financières',\n",
              " \"dialogue homme-machine en langage naturel, algorithme de l‟analyse sémantico-syntactique, sémantique intégrale formelle, théorie des K-représentations, SK-langues, représentation sémantique, bases de données linguistiques, réseau sémantique d'une génération nouvelle, réseau sémantique multi-lingue, bioinformatique\",\n",
              " \"dialogue homme-machine en langage naturel, algorithme de l‟analyse sémantico-syntactique, sémantique intégrale formelle, théorie des K-représentations, SK-langues, représentation sémantique, bases de données linguistiques, réseau sémantique d'une génération nouvelle, réseau sémantique multi-lingue, bioinformatique\",\n",
              " \"dialogue homme-machine en langage naturel, algorithme de l‟analyse sémantico-syntactique, sémantique intégrale formelle, théorie des K-représentations, SK-langues, représentation sémantique, bases de données linguistiques, réseau sémantique d'une génération nouvelle, réseau sémantique multi-lingue, bioinformatique\",\n",
              " 'apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentales',\n",
              " 'Étiqueteur, Entités nommées, Lexiques',\n",
              " 'Traitement Automatique du Langage Naturel, Fouille du Web, Titrage automatique',\n",
              " \"extraction d'information, extraction de relations\",\n",
              " 'Résumé cross-lingue, qualité de traduction, graphe',\n",
              " \"Extraction d'information, Indexation contrôlée, Informatique médicale, Concepts médicaux, Prescriptions\",\n",
              " 'Système de dialogue, compréhension de la parole, portabilité à travers les langues, traduction automatique statistique',\n",
              " 'Fouille de données orales, Traitement Automatique de la Parole, Annotation de corpus oraux, Classification en rôles de locuteurs',\n",
              " \"Indexation d'informations calendaires, Recherche d'information, Annotation et extraction d'expressions calendaires\",\n",
              " 'entités nommées, patrons sémantiques, segmentation discursive de surface',\n",
              " 'Désambiguïsation lexicale, Algorithmes à colonies de fourmis, Mesures sémantiques',\n",
              " 'Amazon Mechanical Turk, ressources linguistiques',\n",
              " \"Corpus comparables, comparabilité, lexiques bilingues, recherche d'information interlingue\",\n",
              " 'Analyse de sentiments, lexique de valence, apprentissage supervisé, analyse sémantique latente',\n",
              " 'Sémantique lexicale, similarité distributionnelle, similarité traductionnelle',\n",
              " \"Alignement d'annotations, mesure d'accord inter-annotateurs, linguistique de corpus\",\n",
              " 'Annotation temporelle, corpus, ISO-TimeML',\n",
              " 'Apprentissage automatique, acquisition terminologique, entropie, grammaires de chunking',\n",
              " 'Corpus comparables, lexiques bilingues, métarecherche',\n",
              " 'Réseau lexical, JeuxDeMots, évaluation, outil de MBL, mot sur le bout de la langue',\n",
              " \"Fouille d'opinions, Identification des cibles, Méthode RankSVM\",\n",
              " 'Étiquetagemorpho-syntaxique,Modèle CRF, Ressources lexicales, Segmentation, Unités polylexicales',\n",
              " 'Segmentation non-supervisée, entropie, induction de lexique, unité lexicale, chinois mandarin',\n",
              " 'Évaluation, Morphologie, Ressources, Système de Question-Réponse',\n",
              " 'analogie, tri-grammes inconnus, tri-grammes hapax, modèle de langue tri-grammes, Europarl',\n",
              " 'analyse syntaxique, corpus arboré, apprentissage automatique, ré-ordonnancement discriminant',\n",
              " 'extraction de relation, domaine médical, apprentissage multi-classes, tree kernel',\n",
              " 'dépendance, French Treebank, réécriture de graphes, Dicovalence',\n",
              " 'analyse de sentiments, analyse syntaxique, arbre de dépendances, SVM',\n",
              " 'portée des quantifieurs, cumulatif, collectif, distributif, référent de discours, ancrage',\n",
              " 'Modalité épistémique, Niveau de certitude, Domaine médical',\n",
              " 'Discours, Analyse discursive, Factivité (véracité), Interface syntaxe-sémantique, RST, SDRT, PDTB, FactBank',\n",
              " 'Wikipédia, révisions, identification de paraphrases',\n",
              " 'grammaire du discours, programmation en logique, grammaires logiques',\n",
              " 'Deixis, parole et geste, grammaires multimodales',\n",
              " 'alignement sous-phrastique, traduction automatique par fragments',\n",
              " \"traduction statistique, modèles de traduction à base de segments, modèles d'alignement mot-à-mot\",\n",
              " 'Paraphrase sous-phrastique, corpus parallèle monolingue, hybridation',\n",
              " 'Apprentissage non-supervisé, segmentation, chinois, mandarin',\n",
              " 'Texte, lexique, co-occurrence généralisée, auto-organisation',\n",
              " 'Similarité sémantique, Relations sémantiques, Similarité distributionnelle',\n",
              " 'Traduction statistique, normalisation de textos, algorithme de recherche vorace, modèle de langue',\n",
              " \"Correction automatique, détection de langue, données produite par l'utilisateur\",\n",
              " \"Expressions polylexicales, extraction lexicale, lexique, mesures d'association, corpus, lexicographie\",\n",
              " 'morphologie constructionnelle, néologie, génération morphologique, incomplétude lexicale',\n",
              " 'analyse syntaxique par transitions, structure de dépendance non-projective, grammaire catégorielle de dépendance',\n",
              " 'Arbres syntaxiques, unité illocutoire, unités rectionnelles, micro-syntaxe, macrosyntaxe, entassement',\n",
              " \"fouille d'opinion, modifieurs de valence affective, modifieurs de polarité\",\n",
              " 'diacritisation, traitement automatique, analyse morpho-syntaxique, langue arabe',\n",
              " 'TAL, EIAH, formation en ligne, socio-constructivisme, acquisition des connaissances, apprentissage collaboratif en ligne',\n",
              " 'désambiguïsation lexicale non-supervisée, mesures de similarité sémantique à base de connaissances, algorithmes globaux de propagation de mesures locales',\n",
              " 'résumé automatique, compression de texte, sms, lisibilité, essentialisation',\n",
              " 'séquences verbales figées, reconnaissance automatique, étiquetage, transformations linguistiques, ressources électroniques',\n",
              " 'émotion, forum de santé, traitement automatique de la langue, désambiguïsation lexicale',\n",
              " \"extraction de relations, peuplement d'ontologie, représentation des connaissances\",\n",
              " \"Agent conversationnel éducatif, intelligence artificielle, jeu sérieux, questionnaire à choix multiple, système d'évaluation de réponses libres\",\n",
              " \"Fouille d'opinion, Classification, Intensité de l'Opinion, Résumé de texte d'opinion, Popularité\",\n",
              " 'question-réponse, questions à réponses multiples, question liste',\n",
              " \"Reconnaissance d'entités nommées, approche symbolique, portabilité entre les langues\",\n",
              " 'Langue des signes, Espace de signation, gestes de pointage, capture de mouvement, suivi du regard',\n",
              " \"État de l'art, Fouille d'opinion, Multi-domaines, Cross-domaines\",\n",
              " 'Acquisition de relations, Synonymie, Relations sémantiques, Terminologie, Domaine Biomédical, Corpus de spécialité',\n",
              " \"Extraction de grammaire, grammaire de Lambek, PCFG, transducteur d'arbre, algorithme CYK\",\n",
              " 'annotation collaborative de corpus, annotations concurrentes, dépendances',\n",
              " 'Préférence, dialogue, apprentissage automatique',\n",
              " 'wikipedia, conflit, syntaxe, sémantique, interaction',\n",
              " \"entités nommées, concepts métier, extraction d'information, données conversationnelles, annotation\",\n",
              " 'linguistique de corpus, textométrie, analyse de sentiments, classification automatique supervisée',\n",
              " 'Langue des signes, analyse de corpus, modèle grammatical, synchronisation',\n",
              " 'annotation manuelle, accords inter-annotateurs',\n",
              " \"fouille d'opinion, adaptation à un nouveau domaine, auto-apprentissage\",\n",
              " 'collocations, cooccurrences, profl combinatoire, expressions polylexicales, lexique des émotions',\n",
              " 'équivalents terminologiques, vecteurs contextuels, corpus comparables, terminologie médicale, étude qualitative',\n",
              " 'extraction terminologique, prototype, terminologie bilingue, documents comparables, méthode compositionnelle, mots composés, corpus',\n",
              " \"Extraction d'information, événements, approche symbolique, apprentissage de patrons linguistiques\",\n",
              " 'chunking, apprentissage automatique, French Tree Bank, CRF',\n",
              " 'similarité textuelle, classification de documents, corpus spécialisé',\n",
              " 'Reconnaissance de la parole, traduction automatique statistique, corpus comparables multimodaux, extraction de phrases parallèles',\n",
              " 'Pronoms démonstratifs, résolution des anaphores, traitement de la langue arabe',\n",
              " 'Analyse temporelle, évaluation',\n",
              " 'Discours, corpus annoté manuellement, analyse discursive, PDTB, RST, SDRT',\n",
              " 'Combinaison de ressources, RI contextuelle, recherche web',\n",
              " 'Adaptation non supervisée, Repérage des entités nommées',\n",
              " 'ressources lexicales, morphologie dérivationnelle, analyse de sentiments',\n",
              " 'Structure du discours, segments thématiques, transitions thématiques, annotation',\n",
              " 'terminologie, extraction, langue contrôlée, potentiel terminologique, filtrage de termes',\n",
              " \"Recherche d'information, dysorthographie, correction d'erreurs, xml\",\n",
              " 'Traduction automatique statistique, post-édition, adaptation aux domaines de spécialité',\n",
              " \"Résolution d'entités nommées, Corpus annoté, Corpus arboré de Paris 7\",\n",
              " 'Traduction automatique statistique, fonctions de croyance, apprentissage automatique, estimation de paramètres',\n",
              " \"Centre d'appels, Conversation, Tour de parole, Reconnaissance de Parole\",\n",
              " 'Français écrit des sourds, TAL, Français Langue Etrangère, linguistique de corpus, lexique, syntaxe, méthodologie',\n",
              " 'réécriture de graphes, interface syntaxe-sémantique',\n",
              " 'Traitements multi-vues, navigation enrichie',\n",
              " 'Synthèse de texte, Grammaire attribuée, Syntaxe',\n",
              " 'étiquetage POS, chunking, apprentissage automatique, French Tree Bank, CRF',\n",
              " 'segmentation, phonétisation, alignement, syllabation',\n",
              " \"entités nommées, extraction de relations, création d'ontologies, similarité\",\n",
              " \"recherche d'information, analyse d'opinion, génération de texte, fouille du web\",\n",
              " 'Dictionnaire électronique, dimension bilingue, diversité linguistique, verbes',\n",
              " 'retour visuel, aide à la prononciation, GMM, temps réel, tête parlante',\n",
              " 'corpus, oral, linguistique, logiciel',\n",
              " 'Extraction de relations, simplification de phrases, apprentissage automatique',\n",
              " \"Extraction d'information, projection d'annotation, reconnaissance des entités médicales, apprentissage\",\n",
              " \"Extraction d'information, segmentation de texte, remplissage de formulaires\",\n",
              " 'compositionalité, interface syntaxe-sémantique, interface sémantique-pragmatique, grammaire catégorielle, théorie des types, récit de voyage',\n",
              " 'Mots composés, analyse syntaxique, champs markoviens aléatoires, réordonnanceur',\n",
              " 'nom déverbal, cadre de sous-catégorisation, groupe prépositionnel, analyse en dépendances',\n",
              " 'Calcul de similarité, modèle vectoriel, TF-IDF, Okapi BM-25, vectorisation',\n",
              " 'Etiquetage morpho-syntaxique, français parlé, ressources langagières',\n",
              " 'corpus parallèle, alignement sous-phrastique, traduction automatique statistique',\n",
              " \"Translittération, alignement de mots, construction de dictionnaires multilingues, traduction automatique, recherche d'information interlingue\",\n",
              " 'ressource, lexique, verbes, raffinement, étiquetage de rôles sémantiques',\n",
              " 'analyse distributionnelle, sémantique lexicale, méronymie, évaluation',\n",
              " 'Cohésion thématique, graphe de cooccurrences, marche aléatoire',\n",
              " 'paraphrase, Wikipédia, aide à la rédaction',\n",
              " 'simplification automatique, lisibilité, analyse syntaxique',\n",
              " 'Résumé automatique, approche symbolique, approche numérique, approche hybride, document arabe',\n",
              " 'unités lexicales spécifiques, analyse des mots-clés, analyse des marqueurs lexicaux stables, sémantique quantitative, analyse de régression',\n",
              " 'Fouille de graphes, réseaux phrastiques, analyse textuelle, navigation textuelle',\n",
              " 'acquisition de paraphrases, constitution de corpus',\n",
              " \"Étiquetage morpho-syntaxique, correction automatique, qualité d'annotation\",\n",
              " 'réécriture de graphes, interface syntaxe-sémantique, dépendances, DMRS',\n",
              " 'Treebank hybride, French Treebank, Grammaires de Propriétés',\n",
              " 'Corpus arboré, analyse syntaxique statistique, adaptation de domaine',\n",
              " 'Expression polylexicale, alignement bilingue, traduction automatique statistique',\n",
              " 'grammaires catégorielles, clustering hiérarchique, inférence grammaticale',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzDZxsVA_jeU"
      },
      "source": [
        "J'utilise la librairie disponible à ce [lien](https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer) qui permet la lémmatisation des mots français en se basant sur des ressources académiques du [Lexique des Formes Fléchies du Français](http://pauillac.inria.fr/~sagot/index.html#lefff).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Km3jBUiDOu",
        "outputId": "cfa80c37-d3de-4762-c8f2-c5310443f1f3"
      },
      "source": [
        "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
            "  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-6amagics\n",
            "  Running command git clone -q https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-6amagics\n",
            "Building wheels for collected packages: FrenchLefffLemmatizer\n",
            "  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-cp36-none-any.whl size=3533520 sha256=8ebef7656ab2fd981ad3f26236a959ddcaff9e17b98157607361fa92f5923bcf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wkxmwa3o/wheels/95/b7/c0/e249ca2690c04f6106b9581c5e4111287f71dbd85bac903445\n",
            "Successfully built FrenchLefffLemmatizer\n",
            "Installing collected packages: FrenchLefffLemmatizer\n",
            "Successfully installed FrenchLefffLemmatizer-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gY--5Dk4bj"
      },
      "source": [
        "Les abstracts doivent être nettoyer et épurer des mots d'arrêt basique comme prétraitement avant de faire le tf-idf, je procède à ces étapes :\n",
        "\n",
        "\n",
        "1.   Séparation des résumés en token avec la fonction regex de tokénisation de nltk,\n",
        "\n",
        "2.   Utilisisation de la liste de mots d'arrêt de meilleure qualité que celle de nltk trouvé [ici](https://github.com/cmchurch/nltk_french/blob/master/french-nltk.py) dans la fonction \"get_stopswords\",\n",
        "\n",
        "3.   Comme en travaux pratiques dirigés, le texte est mis en miniscule avec .lower(), a noté que la double boucle est dû à des précédentes méthodes que j'ai utilisé et qui ont donné la forme peut pratique d'une liste de liste, ainsi il est nécessaire pour accéder aux chaines de caractères de faire deux fois des for x ~ in y\n",
        "\n",
        "4.   J'utilise ensuite la fonctionnalité de python sur la génération de liste avec opération sur chaque élement pour retirer les mots d'arrêt simples puis tous les nombres et mots courts de trois lettres ou moins,\n",
        "\n",
        "5. Pour finir j'utilise la librairie référencer plus haut pour lemmatiser la liste de mots d'arrêt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP40M-7zagOv"
      },
      "source": [
        "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora, models\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  lemmatizer = FrenchLefffLemmatizer()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  fr_stop = [\"Ap.\", \"Apr.\", \"GHz\", \"MHz\", \"USD\", \"a\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ait\", \"alors\", \"après\", \"as\", \"attendu\", \"au\", \"au-delà\", \"au-devant\", \"aucun\", \"aucune\", \"audit\", \"auprès\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\", \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autour\", \"autre\", \"autres\", \"autrui\", \"aux\", \"auxdites\", \"auxdits\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\", \"aviez\", \"avions\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"banco\", \"ben\", \"bien\", \"bé\", \"c\", \"c'\", \"c'est\", \"c'était\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-là\", \"celles\", \"celles-ci\", \"celles-là\", \"celui\", \"celui-ci\", \"celui-là\", \"celà\", \"cent\", \"cents\", \"cependant\", \"certain\", \"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-là\", \"cf.\", \"cg\", \"cgr\", \"chacun\", \"chacune\", \"chaque\", \"chez\", \"ci\", \"cinq\", \"cinquante\", \"cinquante-cinq\", \"cinquante-deux\", \"cinquante-et-un\", \"cinquante-huit\", \"cinquante-neuf\", \"cinquante-quatre\", \"cinquante-sept\", \"cinquante-six\", \"cinquante-trois\", \"cl\", \"cm\", \"cm²\", \"comme\", \"contre\", \"d\", \"d'\", \"d'après\", \"d'un\", \"d'une\", \"dans\", \"de\", \"depuis\", \"derrière\", \"des\", \"desdites\", \"desdits\", \"desquelles\", \"desquels\", \"deux\", \"devant\", \"devers\", \"dg\", \"différentes\", \"différents\", \"divers\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dl\", \"dm\", \"donc\", \"dont\", \"douze\", \"du\", \"dudit\", \"duquel\", \"durant\", \"dès\", \"déjà\", \"e\", \"eh\", \"elle\", \"elles\", \"en\", \"en-dehors\", \"encore\", \"enfin\", \"entre\", \"envers\", \"es\", \"est\", \"et\", \"eu\", \"eue\", \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eûmes\", \"eût\", \"eûtes\", \"f\", \"fait\", \"fi\", \"flac\", \"fors\", \"furent\", \"fus\", \"fusse\", \"fussent\", \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"fûmes\", \"fût\", \"fûtes\", \"g\", \"gr\", \"h\", \"ha\", \"han\", \"hein\", \"hem\", \"heu\", \"hg\", \"hl\", \"hm\", \"hm³\", \"holà\", \"hop\", \"hormis\", \"hors\", \"huit\", \"hum\", \"hé\", \"i\", \"ici\", \"il\", \"ils\", \"j\", \"j'\", \"j'ai\", \"j'avais\", \"j'étais\", \"jamais\", \"je\", \"jusqu'\", \"jusqu'au\", \"jusqu'aux\", \"jusqu'à\", \"jusque\", \"k\", \"kg\", \"km\", \"km²\", \"l\", \"l'\", \"l'autre\", \"l'on\", \"l'un\", \"l'une\", \"la\", \"laquelle\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lez\", \"lors\", \"lorsqu'\", \"lorsque\", \"lui\", \"lès\", \"m\", \"m'\", \"ma\", \"maint\", \"mainte\", \"maintes\", \"maints\", \"mais\", \"malgré\", \"me\", \"mes\", \"mg\", \"mgr\", \"mil\", \"mille\", \"milliards\", \"millions\", \"ml\", \"mm\", \"mm²\", \"moi\", \"moins\", \"mon\", \"moyennant\", \"mt\", \"m²\", \"m³\", \"même\", \"mêmes\", \"n\", \"n'avait\", \"n'y\", \"ne\", \"neuf\", \"ni\", \"non\", \"nonante\", \"nonobstant\", \"nos\", \"notre\", \"nous\", \"nul\", \"nulle\", \"nº\", \"néanmoins\", \"o\", \"octante\", \"oh\", \"on\", \"ont\", \"onze\", \"or\", \"ou\", \"outre\", \"où\", \"p\", \"par\", \"par-delà\", \"parbleu\", \"parce\", \"parmi\", \"pas\", \"passé\", \"pendant\", \"personne\", \"peu\", \"plus\", \"plus_d'un\", \"plus_d'une\", \"plusieurs\", \"pour\", \"pourquoi\", \"pourtant\", \"pourvu\", \"près\", \"puisqu'\", \"puisque\", \"q\", \"qu\", \"qu'\", \"qu'elle\", \"qu'elles\", \"qu'il\", \"qu'ils\", \"qu'on\", \"quand\", \"quant\", \"quarante\", \"quarante-cinq\", \"quarante-deux\", \"quarante-et-un\", \"quarante-huit\", \"quarante-neuf\", \"quarante-quatre\", \"quarante-sept\", \"quarante-six\", \"quarante-trois\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatre-vingt-cinq\", \"quatre-vingt-deux\", \"quatre-vingt-dix\", \"quatre-vingt-dix-huit\", \"quatre-vingt-dix-neuf\", \"quatre-vingt-dix-sept\", \"quatre-vingt-douze\", \"quatre-vingt-huit\", \"quatre-vingt-neuf\", \"quatre-vingt-onze\", \"quatre-vingt-quatorze\", \"quatre-vingt-quatre\", \"quatre-vingt-quinze\", \"quatre-vingt-seize\", \"quatre-vingt-sept\", \"quatre-vingt-six\", \"quatre-vingt-treize\", \"quatre-vingt-trois\", \"quatre-vingt-un\", \"quatre-vingt-une\", \"quatre-vingts\", \"que\", \"quel\", \"quelle\", \"quelles\", \"quelqu'\", \"quelqu'un\", \"quelqu'une\", \"quelque\", \"quelques\", \"quelques-unes\", \"quelques-uns\", \"quels\", \"qui\", \"quiconque\", \"quinze\", \"quoi\", \"quoiqu'\", \"quoique\", \"r\", \"revoici\", \"revoilà\", \"rien\", \"s\", \"s'\", \"sa\", \"sans\", \"sauf\", \"se\", \"seize\", \"selon\", \"sept\", \"septante\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\", \"serions\", \"serons\", \"seront\", \"ses\", \"si\", \"sinon\", \"six\", \"soi\", \"soient\", \"sois\", \"soit\", \"soixante\", \"soixante-cinq\", \"soixante-deux\", \"soixante-dix\", \"soixante-dix-huit\", \"soixante-dix-neuf\", \"soixante-dix-sept\", \"soixante-douze\", \"soixante-et-onze\", \"soixante-et-un\", \"soixante-et-une\", \"soixante-huit\", \"soixante-neuf\", \"soixante-quatorze\", \"soixante-quatre\", \"soixante-quinze\", \"soixante-seize\", \"soixante-sept\", \"soixante-six\", \"soixante-treize\", \"soixante-trois\", \"sommes\", \"son\", \"sont\", \"sous\", \"soyez\", \"soyons\", \"suis\", \"suite\", \"sur\", \"sus\", \"t\", \"t'\", \"ta\", \"tacatac\", \"tandis\", \"te\", \"tel\", \"telle\", \"telles\", \"tels\", \"tes\", \"toi\", \"ton\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"trente-cinq\", \"trente-deux\", \"trente-et-un\", \"trente-huit\", \"trente-neuf\", \"trente-quatre\", \"trente-sept\", \"trente-six\", \"trente-trois\", \"trois\", \"très\", \"tu\", \"u\", \"un\", \"une\", \"unes\", \"uns\", \"v\", \"vers\", \"via\", \"vingt\", \"vingt-cinq\", \"vingt-deux\", \"vingt-huit\", \"vingt-neuf\", \"vingt-quatre\", \"vingt-sept\", \"vingt-six\", \"vingt-trois\", \"vis-à-vis\", \"voici\", \"voilà\", \"vos\", \"votre\", \"vous\", \"w\", \"x\", \"y\", \"z\", \"zéro\", \"à\", \"ç'\", \"ça\", \"ès\", \"étaient\", \"étais\", \"était\", \"étant\", \"étiez\", \"étions\", \"été\", \"étée\", \"étées\", \"étés\", \"êtes\", \"être\", \"ô\"]\n",
        "  cleaned_text = []\n",
        "  for abstract in text:\n",
        "      lowercase_text = abstract.lower()\n",
        "      words = tokenizer.tokenize(lowercase_text)\n",
        "      non_stopped_words = [lemmatizer.lemmatize(i) for i in words if not i in fr_stop and not bool(re.search(\"\\d+\",i)) and len(i)>3]\n",
        "      cleaned_text.append(non_stopped_words)\n",
        "  return cleaned_text\n",
        "  \n",
        "def doLDA(cleaned_text):\n",
        "  dictionary = corpora.Dictionary(cleaned_text)\n",
        "  corpus = [dictionary.doc2bow(abstract) for abstract in cleaned_text]\n",
        "  ldamodel = models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary)\n",
        "  print(ldamodel.print_topics(num_topics=2, num_words=4))\n",
        "  return ldamodel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_be4mFnn36"
      },
      "source": [
        "Comme dans les exemples trouvables sur internet, j'ai utilisé l'implémentation de tfidf de sklearn ce qui me permet de récupérer le résulat final soit forme d'un Dataframe pandas avec en abscisse les mots d'arrêt et en ordonné l'index des résumés."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV5HzTpfoJ5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "20b57d74-606e-4141-e6c4-12faa3be8f0c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "text = clean_text(text = abstracts)\n",
        "corpus = [' '.join(doc) for doc in text]\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns=feature_names)\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonné</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrégé</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>académiques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptées</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordé</th>\n",
              "      <th>accès</th>\n",
              "      <th>accéder</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquière</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activité</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>étiquetagemorpho</th>\n",
              "      <th>étiqueteur</th>\n",
              "      <th>étiquettage</th>\n",
              "      <th>étiquette</th>\n",
              "      <th>étiqueté</th>\n",
              "      <th>étiquetés</th>\n",
              "      <th>étranger</th>\n",
              "      <th>étude</th>\n",
              "      <th>étudiant</th>\n",
              "      <th>étudier</th>\n",
              "      <th>étudions</th>\n",
              "      <th>étudié</th>\n",
              "      <th>étudiées</th>\n",
              "      <th>étudiés</th>\n",
              "      <th>étymologie</th>\n",
              "      <th>évaluatif</th>\n",
              "      <th>évaluation</th>\n",
              "      <th>évaluative</th>\n",
              "      <th>évaluatives</th>\n",
              "      <th>évaluer</th>\n",
              "      <th>évaluerons</th>\n",
              "      <th>évaluée</th>\n",
              "      <th>éventail</th>\n",
              "      <th>éventualité</th>\n",
              "      <th>évidence</th>\n",
              "      <th>évident</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolutif</th>\n",
              "      <th>évolutifs</th>\n",
              "      <th>évolution</th>\n",
              "      <th>évolutive</th>\n",
              "      <th>évolutives</th>\n",
              "      <th>évolutivité</th>\n",
              "      <th>évoque</th>\n",
              "      <th>évoquées</th>\n",
              "      <th>évènementielle</th>\n",
              "      <th>évènements</th>\n",
              "      <th>événement</th>\n",
              "      <th>événementielle</th>\n",
              "      <th>événementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1501 rows × 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      abandonnant  abandonné  able  ...  événement  événementielle  événementiels\n",
              "0             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "2             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "3             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "4             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "...           ...        ...   ...  ...        ...             ...            ...\n",
              "1496          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1497          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1498          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1499          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1500          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "\n",
              "[1501 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwRd1wxUoaHp"
      },
      "source": [
        "Les mots ayant un tfidf de 0 ne sont pas présent dans les résumés des lignes correspondantes, ils ne sont donc pas pertinent, je crée donc un deuxième jeu de donnée fait des valeurs strictement positives.\n",
        "\n",
        "La fonction describe donne des statistiques sur le jeu de donnée, celle ci est utile pour connaitre la répartition des valeurs td idf pertinentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "cvHML79AXhg0",
        "outputId": "a5467dd8-bef8-4905-f00e-0e829f90faff"
      },
      "source": [
        "desc = df[df > 0].describe()\n",
        "desc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonné</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrégé</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>académiques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptées</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordé</th>\n",
              "      <th>accès</th>\n",
              "      <th>accéder</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquière</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activité</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>étiquetagemorpho</th>\n",
              "      <th>étiqueteur</th>\n",
              "      <th>étiquettage</th>\n",
              "      <th>étiquette</th>\n",
              "      <th>étiqueté</th>\n",
              "      <th>étiquetés</th>\n",
              "      <th>étranger</th>\n",
              "      <th>étude</th>\n",
              "      <th>étudiant</th>\n",
              "      <th>étudier</th>\n",
              "      <th>étudions</th>\n",
              "      <th>étudié</th>\n",
              "      <th>étudiées</th>\n",
              "      <th>étudiés</th>\n",
              "      <th>étymologie</th>\n",
              "      <th>évaluatif</th>\n",
              "      <th>évaluation</th>\n",
              "      <th>évaluative</th>\n",
              "      <th>évaluatives</th>\n",
              "      <th>évaluer</th>\n",
              "      <th>évaluerons</th>\n",
              "      <th>évaluée</th>\n",
              "      <th>éventail</th>\n",
              "      <th>éventualité</th>\n",
              "      <th>évidence</th>\n",
              "      <th>évident</th>\n",
              "      <th>éviter</th>\n",
              "      <th>évolutif</th>\n",
              "      <th>évolutifs</th>\n",
              "      <th>évolution</th>\n",
              "      <th>évolutive</th>\n",
              "      <th>évolutives</th>\n",
              "      <th>évolutivité</th>\n",
              "      <th>évoque</th>\n",
              "      <th>évoquées</th>\n",
              "      <th>évènementielle</th>\n",
              "      <th>évènements</th>\n",
              "      <th>événement</th>\n",
              "      <th>événementielle</th>\n",
              "      <th>événementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.108237</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.342702</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.279619</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.376711</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.385082</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.381658</td>\n",
              "      <td>0.341043</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.296847</td>\n",
              "      <td>0.417863</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.360660</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.410997</td>\n",
              "      <td>0.318679</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.243023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.308624</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105788</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.089011</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.254174</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440063</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023640</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.156819</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.184360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.163013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.179554</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.104128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.055251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.133793</td>\n",
              "      <td>0.067838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.189427</td>\n",
              "      <td>0.032545</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.207922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.079683</td>\n",
              "      <td>0.232430</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.096411</td>\n",
              "      <td>0.136131</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.120218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.058638</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.102108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.174677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.052591</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.070434</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.118352</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.351925</td>\n",
              "      <td>0.108891</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.372931</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.062085</td>\n",
              "      <td>0.360501</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.138369</td>\n",
              "      <td>0.123565</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.096134</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.319018</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.079687</td>\n",
              "      <td>0.326456</td>\n",
              "      <td>0.058839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.055999</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.170236</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.174820</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.376107</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.102025</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.275764</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.131590</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.310124</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.359586</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.360251</td>\n",
              "      <td>0.250554</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.392465</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.230344</td>\n",
              "      <td>0.380424</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.205342</td>\n",
              "      <td>0.135071</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.243898</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.386965</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.154782</td>\n",
              "      <td>0.360542</td>\n",
              "      <td>0.091839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.245567</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.072856</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.060956</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.093946</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.197336</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.236578</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.396827</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.113916</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.350694</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383865</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.445103</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.461537</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.368577</td>\n",
              "      <td>0.329032</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.350722</td>\n",
              "      <td>0.400347</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.317559</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.454911</td>\n",
              "      <td>0.378852</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.291897</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.301311</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105908</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.091875</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.224435</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440921</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.126838</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.417633</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.387685</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.462888</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.487033</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.396525</td>\n",
              "      <td>0.426920</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.431534</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.379694</td>\n",
              "      <td>0.446544</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.339287</td>\n",
              "      <td>0.158084</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.535561</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.456986</td>\n",
              "      <td>0.525753</td>\n",
              "      <td>0.304972</td>\n",
              "      <td>0.428715</td>\n",
              "      <td>0.362058</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.354599</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.138840</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.119930</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.125694</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.296143</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.360094</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.469429</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.127969</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.523828</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.458937</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.537448</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.498902</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.424473</td>\n",
              "      <td>0.478975</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.451068</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.474284</td>\n",
              "      <td>0.492741</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.406260</td>\n",
              "      <td>0.169591</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.667564</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.459062</td>\n",
              "      <td>0.538022</td>\n",
              "      <td>0.380066</td>\n",
              "      <td>0.462802</td>\n",
              "      <td>0.404369</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.694558</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.174313</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.135269</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.141568</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.367850</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.421852</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.541786</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       abandonnant  abandonné  ...  événementielle  événementiels\n",
              "count     1.000000   1.000000  ...        1.000000       1.000000\n",
              "mean      0.082296   0.096364  ...        0.594895       0.524093\n",
              "std            NaN        NaN  ...             NaN            NaN\n",
              "min       0.082296   0.096364  ...        0.594895       0.524093\n",
              "25%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "50%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "75%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "max       0.082296   0.096364  ...        0.594895       0.524093\n",
              "\n",
              "[8 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqOsQ-KppbNy"
      },
      "source": [
        "J'extraie la ligne des moyennes que je place dans une variable sous forme d'un tableau trié de manière descendante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SsMCyMEZa--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662a1c08-3ce4-4690-fc2a-f1ba2fbbe17b"
      },
      "source": [
        "tf_idf_mean = desc.iloc[1,:]\n",
        "mean_of_means = tf_idf_mean.sort_values(ascending=False).values\n",
        "mean_of_means"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88552986, 0.87503543, 0.85792386, ..., 0.04208241, 0.04208241,\n",
              "       0.04208241])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wGgunJlpzUq"
      },
      "source": [
        "La coupe se fait sur l'index de la partie entière du quart de la longueur du tableau, la valeur ext extraite dans une variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3Cd3s00Tnb",
        "outputId": "1dba7062-253b-4013-dc7e-78a1842dfa52"
      },
      "source": [
        "mean_of_means = mean_of_means[int(len(mean_of_means)*1/4)]\n",
        "mean_of_means"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4300170482020056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VVGbSoYqJIK"
      },
      "source": [
        "Les mots finaux sont ceux qui ont un score tfidf supérieur ou égale à la valeur discriminatoire déterminer plus tôt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L2UeAZL56A8E",
        "outputId": "722491c6-00f2-4a39-9816-13acc423fbd3"
      },
      "source": [
        "words = tf_idf_mean[tf_idf_mean >= mean_of_means].index\n",
        "words = pd.DataFrame(words)\n",
        "words = words.rename(columns={0:\"words\"})\n",
        "words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>able</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>actant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>activation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adapatabilité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>évolutivité</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>évènements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>événement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>événementielle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>événementiels</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>751 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              words\n",
              "0              able\n",
              "1            actant\n",
              "2        activation\n",
              "3            active\n",
              "4     adapatabilité\n",
              "..              ...\n",
              "746     évolutivité\n",
              "747      évènements\n",
              "748       événement\n",
              "749  événementielle\n",
              "750   événementiels\n",
              "\n",
              "[751 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxYxZrCi20N1"
      },
      "source": [
        "J'épure le texte des mots d'arrêts déterminés par tfidf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKnNtPtIpQok",
        "outputId": "b9970bd7-d35b-4bc2-d37e-81e86934d51b"
      },
      "source": [
        "final_text = [i for i in text if i in words.values]\n",
        "final_text"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['déplacer',\n",
              "  'pied',\n",
              "  'moyen',\n",
              "  'activité',\n",
              "  'humaine',\n",
              "  'courante',\n",
              "  'trouver',\n",
              "  'chemin',\n",
              "  'suppose',\n",
              "  'souvent',\n",
              "  'aide',\n",
              "  'type',\n",
              "  'verbal',\n",
              "  'description',\n",
              "  'itinéraire',\n",
              "  'iconique',\n",
              "  'croquis',\n",
              "  'carte',\n",
              "  'présentons',\n",
              "  'article',\n",
              "  'système',\n",
              "  'capable',\n",
              "  'produire',\n",
              "  'description',\n",
              "  'itinéraire',\n",
              "  'métro',\n",
              "  'générateur',\n",
              "  'fondé',\n",
              "  'cognitif',\n",
              "  'production',\n",
              "  'description',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'montrons',\n",
              "  'comment',\n",
              "  'facteur',\n",
              "  'importance',\n",
              "  'relative',\n",
              "  'information',\n",
              "  'choix',\n",
              "  'stylistique',\n",
              "  'peuvent',\n",
              "  'faire',\n",
              "  'varier',\n",
              "  'foi',\n",
              "  'contenu',\n",
              "  'forme',\n",
              "  'description',\n",
              "  'itinéraire'],\n",
              " ['expression',\n",
              "  'spatio',\n",
              "  'temporalité',\n",
              "  'traditionnellement',\n",
              "  'scindée',\n",
              "  'paradigme',\n",
              "  'localisation',\n",
              "  'déplacement',\n",
              "  'localisation',\n",
              "  'exprime',\n",
              "  'nombre',\n",
              "  'relation',\n",
              "  'entité',\n",
              "  'localiser',\n",
              "  'site',\n",
              "  'déplacement',\n",
              "  'exprime',\n",
              "  'changement',\n",
              "  'relation',\n",
              "  'temps',\n",
              "  'omettre',\n",
              "  'autonomie',\n",
              "  'richesse',\n",
              "  'déplacement',\n",
              "  'exprimer',\n",
              "  'rapport',\n",
              "  'localisation',\n",
              "  'opposer',\n",
              "  'paradigme',\n",
              "  'partagent',\n",
              "  'nombre',\n",
              "  'type',\n",
              "  'contrainte',\n",
              "  'topologie',\n",
              "  'distance',\n",
              "  'proposons',\n",
              "  'observer',\n",
              "  'domaine',\n",
              "  'spatio',\n",
              "  'temporel',\n",
              "  'articulation',\n",
              "  'façon',\n",
              "  'oppose',\n",
              "  'montre',\n",
              "  'contraire',\n",
              "  'partagent',\n",
              "  'travail',\n",
              "  'formalisation',\n",
              "  'analyse',\n",
              "  'destiné',\n",
              "  'élaboration',\n",
              "  'mécanisme',\n",
              "  'compréhension',\n",
              "  'automatique'],\n",
              " ['objectif',\n",
              "  'étude',\n",
              "  'concerne',\n",
              "  'traitement',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'système',\n",
              "  'reconnaissance',\n",
              "  'parole',\n",
              "  'exploitant',\n",
              "  'contrainte',\n",
              "  'accord',\n",
              "  'phrase',\n",
              "  'reconnaître',\n",
              "  'nombre',\n",
              "  'contrainte',\n",
              "  'peut',\n",
              "  'traité',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'portée',\n",
              "  'locale',\n",
              "  'type',\n",
              "  'gram',\n",
              "  'utilisés',\n",
              "  'habituellement',\n",
              "  'modèle',\n",
              "  'proposés',\n",
              "  'modèle',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'modèle',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'permettent',\n",
              "  'résoudre',\n",
              "  'homophonie',\n",
              "  'méthode',\n",
              "  'modèle',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'permet',\n",
              "  'introduire',\n",
              "  'contrainte',\n",
              "  'syntaxiques',\n",
              "  'modèle',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'objet',\n",
              "  'discriminer',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'manière',\n",
              "  'robuste',\n",
              "  'sensible',\n",
              "  'mauvais',\n",
              "  'reconnaissance',\n",
              "  'sein',\n",
              "  'phrase'],\n",
              " ['article',\n",
              "  'présente',\n",
              "  'identification',\n",
              "  'corpus',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'considérés',\n",
              "  'linguiste',\n",
              "  'hautement',\n",
              "  'dénominatifs',\n",
              "  'approche',\n",
              "  'utilise',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologique',\n",
              "  'applique',\n",
              "  'corpus',\n",
              "  'préalablement',\n",
              "  'étiqueté',\n",
              "  'lemmatisé',\n",
              "  'avoir',\n",
              "  'rappelé',\n",
              "  'propriété',\n",
              "  'linguistique',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'présenterons',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'modification',\n",
              "  'apportées',\n",
              "  'effectuer',\n",
              "  'identification',\n",
              "  'évaluerons',\n",
              "  'caractère',\n",
              "  'dénominatif',\n",
              "  'adjectif',\n",
              "  'terme',\n",
              "  'nominaux',\n",
              "  'apparaissent',\n",
              "  'comparant',\n",
              "  'thesaurus',\n",
              "  'conclurons',\n",
              "  'intérêt',\n",
              "  'adjectif',\n",
              "  'foi',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'problématique',\n",
              "  'extraction',\n",
              "  'connaissance',\n",
              "  'partir',\n",
              "  'corpus',\n",
              "  'mise',\n",
              "  'jour',\n",
              "  'thesaurus'],\n",
              " ['sémantique', 'lexicale', 'prédicat', 'lexique', 'génératif'],\n",
              " ['kimball',\n",
              "  'préférence',\n",
              "  'attachement',\n",
              "  'association',\n",
              "  'droite',\n",
              "  'attachement',\n",
              "  'minimal',\n",
              "  'essentiellement',\n",
              "  'formulées',\n",
              "  'terme',\n",
              "  'arbre',\n",
              "  'constituant',\n",
              "  'forme',\n",
              "  'nombre',\n",
              "  'noeud',\n",
              "  'présentons',\n",
              "  'principe',\n",
              "  'préférence',\n",
              "  'attachement',\n",
              "  'formulés',\n",
              "  'terme',\n",
              "  'arbre',\n",
              "  'dérivation',\n",
              "  'information',\n",
              "  'dépendancielle',\n",
              "  'cadre',\n",
              "  'formalisme',\n",
              "  'grammaire',\n",
              "  'arbre',\n",
              "  'adjoint',\n",
              "  'lexicalisées',\n",
              "  'ltag',\n",
              "  'montrons',\n",
              "  'type',\n",
              "  'approche',\n",
              "  'permet',\n",
              "  'remédier',\n",
              "  'défaut',\n",
              "  'approche',\n",
              "  'structurales',\n",
              "  'exprimées',\n",
              "  'terme',\n",
              "  'arbre',\n",
              "  'constituant',\n",
              "  'rendent',\n",
              "  'compte',\n",
              "  'heuristique',\n",
              "  'largement',\n",
              "  'acceptées',\n",
              "  'argument',\n",
              "  'modifieur',\n",
              "  'idiome'],\n",
              " ['intéressons',\n",
              "  'méthode',\n",
              "  'alignement',\n",
              "  'automatique',\n",
              "  'destinée',\n",
              "  'produire',\n",
              "  'corpus',\n",
              "  'textuels',\n",
              "  'utile',\n",
              "  'traducteur',\n",
              "  'terminologue',\n",
              "  'linguistique',\n",
              "  'technique',\n",
              "  'obtenu',\n",
              "  'résultat',\n",
              "  'probants',\n",
              "  'appuyant',\n",
              "  'détermination',\n",
              "  'empirique',\n",
              "  'cognat',\n",
              "  'anglais',\n",
              "  'cognate',\n",
              "  'mot',\n",
              "  'traduisent',\n",
              "  'présentent',\n",
              "  'ressemblance',\n",
              "  'graphique',\n",
              "  'cognat',\n",
              "  'généralement',\n",
              "  'captés',\n",
              "  'moyen',\n",
              "  'approximation',\n",
              "  'abrupte',\n",
              "  'nature',\n",
              "  'opératoire',\n",
              "  'considère',\n",
              "  'gramme',\n",
              "  'mot',\n",
              "  'possédant',\n",
              "  'lettre',\n",
              "  'commun',\n",
              "  'cognat',\n",
              "  'potentiel',\n",
              "  'étude',\n",
              "  'faite',\n",
              "  'connaissance',\n",
              "  'propos',\n",
              "  'validité',\n",
              "  'approximation',\n",
              "  'démontrer',\n",
              "  'possibilité',\n",
              "  'limite',\n",
              "  'cherché',\n",
              "  'déterminer',\n",
              "  'empiriquement',\n",
              "  'qualité',\n",
              "  'simplification',\n",
              "  'terme',\n",
              "  'bruit',\n",
              "  'silence',\n",
              "  'manière',\n",
              "  'complémentaire',\n",
              "  'précision',\n",
              "  'rappel',\n",
              "  'ensuite',\n",
              "  'essayé',\n",
              "  'développer',\n",
              "  'filtrage',\n",
              "  'efficace',\n",
              "  'basé',\n",
              "  'utilisation',\n",
              "  'chaîne',\n",
              "  'maximale',\n",
              "  'corrélé',\n",
              "  'amélioration',\n",
              "  'filtrage',\n",
              "  'résultat',\n",
              "  'alignement',\n",
              "  'basant',\n",
              "  'méthode',\n",
              "  'générale',\n",
              "  'développée',\n",
              "  'constater',\n",
              "  'progrès',\n",
              "  'terme',\n",
              "  'rappel',\n",
              "  'précision',\n",
              "  'alignement'],\n",
              " ['inférence',\n",
              "  'grammaticale',\n",
              "  'régulière',\n",
              "  'analyse',\n",
              "  'corrective',\n",
              "  'évaluation',\n",
              "  'modèle',\n",
              "  'language'],\n",
              " ['article',\n",
              "  'montrons',\n",
              "  'travers',\n",
              "  'exposé',\n",
              "  'résultat',\n",
              "  'expérience',\n",
              "  'menée',\n",
              "  'corpus',\n",
              "  'comment',\n",
              "  'connaissance',\n",
              "  'thème',\n",
              "  'apparaissent',\n",
              "  'mot',\n",
              "  'mise',\n",
              "  'évidence',\n",
              "  'similarité',\n",
              "  'différence',\n",
              "  'voisinage',\n",
              "  'occurrence',\n",
              "  'partie',\n",
              "  'texte',\n",
              "  'abordant',\n",
              "  'thème',\n",
              "  'permettent',\n",
              "  'mettre',\n",
              "  'jour',\n",
              "  'différence',\n",
              "  'fine',\n",
              "  'acception',\n",
              "  'associées',\n",
              "  'mot',\n",
              "  'thème',\n",
              "  'méthode',\n",
              "  'proposée',\n",
              "  'faire',\n",
              "  'presque',\n",
              "  'entièrement',\n",
              "  'automatique',\n",
              "  'basée',\n",
              "  'calcul',\n",
              "  'intersection',\n",
              "  'différence',\n",
              "  'ensemblistes',\n",
              "  'séquence',\n",
              "  'mot',\n",
              "  'constituant',\n",
              "  'contexte'],\n",
              " ['traitons',\n",
              "  'papier',\n",
              "  'problème',\n",
              "  'détection',\n",
              "  'correction',\n",
              "  'graphie',\n",
              "  'fautif',\n",
              "  'texte',\n",
              "  'arabe',\n",
              "  'commençons',\n",
              "  'présenter',\n",
              "  'expérience',\n",
              "  'visant',\n",
              "  'mesurer',\n",
              "  'manière',\n",
              "  'comparative',\n",
              "  'difficulté',\n",
              "  'problème',\n",
              "  'arabe',\n",
              "  'français',\n",
              "  'anglais',\n",
              "  'idée',\n",
              "  'évaluer',\n",
              "  'degré',\n",
              "  'ressemblance',\n",
              "  'proximité',\n",
              "  'mot',\n",
              "  'sein',\n",
              "  'langue',\n",
              "  'ensuite',\n",
              "  'algorithme',\n",
              "  'base',\n",
              "  'méthode',\n",
              "  'correction',\n",
              "  'présentés'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'robuste',\n",
              "  'devenue',\n",
              "  'technique',\n",
              "  'essentielle',\n",
              "  'application',\n",
              "  'touche',\n",
              "  'contenu',\n",
              "  'document',\n",
              "  'analyseur',\n",
              "  'inscrit',\n",
              "  'approche',\n",
              "  'permettent',\n",
              "  'extraire',\n",
              "  'information',\n",
              "  'ordre',\n",
              "  'linguistique',\n",
              "  'peuvent',\n",
              "  'exploité',\n",
              "  'postérieurement',\n",
              "  'traitement',\n",
              "  'linguistique',\n",
              "  'profond',\n",
              "  'système',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'caractéristique',\n",
              "  'principale',\n",
              "  'outil',\n",
              "  'robustesse',\n",
              "  'robustesse',\n",
              "  'souvent',\n",
              "  'diminuée',\n",
              "  'grand',\n",
              "  'hétérogénéité',\n",
              "  'phénomène',\n",
              "  'linguistique',\n",
              "  'extralinguistiques',\n",
              "  'présent',\n",
              "  'texte',\n",
              "  'venant',\n",
              "  'article',\n",
              "  'présente',\n",
              "  'abord',\n",
              "  'section',\n",
              "  'notion',\n",
              "  'robustesse',\n",
              "  'caractérise',\n",
              "  'section',\n",
              "  'système',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'robuste',\n",
              "  'article',\n",
              "  'présente',\n",
              "  'section',\n",
              "  'inventaire',\n",
              "  'phénomène',\n",
              "  'linguistique',\n",
              "  'extralinguistiques',\n",
              "  'standard',\n",
              "  'attestés',\n",
              "  'corpus',\n",
              "  'finalement',\n",
              "  'section',\n",
              "  'architecture',\n",
              "  'propose',\n",
              "  'traiter',\n",
              "  'phénomène'],\n",
              " ['traduction',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'transfert',\n",
              "  'lexico',\n",
              "  'structural',\n",
              "  'sémantique',\n",
              "  'élément',\n",
              "  'lexicaux'],\n",
              " ['paradigme',\n",
              "  'monodimensionnel',\n",
              "  'prédication',\n",
              "  'monodimensionnelle',\n",
              "  'prédicat',\n",
              "  'prédicat',\n",
              "  'verbal',\n",
              "  'sémantique'],\n",
              " ['grammaire',\n",
              "  'grammaire',\n",
              "  'transductive',\n",
              "  'grammaire',\n",
              "  'générative',\n",
              "  'grammaire',\n",
              "  'formelle',\n",
              "  'grammaire',\n",
              "  'dépendance',\n",
              "  'lexie'],\n",
              " ['entité',\n",
              "  'nommée',\n",
              "  'expression',\n",
              "  'régulière',\n",
              "  'acquisition',\n",
              "  'lexicale',\n",
              "  'marqueur',\n",
              "  'marqueur',\n",
              "  'discursif',\n",
              "  'moteur',\n",
              "  'recherche'],\n",
              " ['corpus', 'concordancier', 'parser', 'expression', 'régulière'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'reconnaissance',\n",
              "  'automatique',\n",
              "  'procédure',\n",
              "  'incrémentielle'],\n",
              " ['sémantique', 'représentation', 'discours', 'temporalité', 'narration'],\n",
              " ['reformulation',\n",
              "  'requête',\n",
              "  'recherche',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'personnalisation'],\n",
              " ['amorce', 'extraction', 'information', 'ontologie', 'patron', 'indexation'],\n",
              " ['proposons',\n",
              "  'montrer',\n",
              "  'comment',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'automatique',\n",
              "  'aujourd',\n",
              "  'tournant',\n",
              "  'évolution',\n",
              "  'mettant',\n",
              "  'accent',\n",
              "  'évolution',\n",
              "  'modèle',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'langage',\n",
              "  'programmation',\n",
              "  'compilation',\n",
              "  'analyse',\n",
              "  'langue',\n",
              "  'cadre',\n",
              "  'analyse',\n",
              "  'langue',\n",
              "  'analyse',\n",
              "  'combinatoire',\n",
              "  'analyse',\n",
              "  'calculatoire',\n",
              "  'passant',\n",
              "  'tagging',\n",
              "  'chunking',\n",
              "  'synthèse',\n",
              "  'section',\n",
              "  'marquera',\n",
              "  'abord',\n",
              "  'poids',\n",
              "  'historique',\n",
              "  'grammaire',\n",
              "  'formelles',\n",
              "  'outil',\n",
              "  'modélisation',\n",
              "  'langue',\n",
              "  'langage',\n",
              "  'formels',\n",
              "  'section',\n",
              "  'comment',\n",
              "  'compilation',\n",
              "  'transposée',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'bernard',\n",
              "  'vauquois',\n",
              "  'analysera',\n",
              "  'ensuite',\n",
              "  'possible',\n",
              "  'obtenir',\n",
              "  'analyse',\n",
              "  'langue',\n",
              "  'fonctionnement',\n",
              "  'analogue',\n",
              "  'compilation',\n",
              "  'complexité',\n",
              "  'linéaire',\n",
              "  'compilation',\n",
              "  'transposée',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'section',\n",
              "  'code',\n",
              "  'analysé',\n",
              "  'fondamentalement',\n",
              "  'tagging',\n",
              "  'montré',\n",
              "  'voie',\n",
              "  'pris',\n",
              "  'acte',\n",
              "  'abandonnant',\n",
              "  'compilation',\n",
              "  'transposée',\n",
              "  'dictionnaire',\n",
              "  'exhaustif',\n",
              "  'entrée',\n",
              "  'grammaire',\n",
              "  'formelle',\n",
              "  'modéliser',\n",
              "  'structure',\n",
              "  'linguistique',\n",
              "  'section',\n",
              "  'montrerons',\n",
              "  'comment',\n",
              "  'analyseur',\n",
              "  'implémenté',\n",
              "  'solution',\n",
              "  'calculatoire',\n",
              "  'complexité',\n",
              "  'linéaire',\n",
              "  'section',\n",
              "  'conclurons',\n",
              "  'section',\n",
              "  'pointant',\n",
              "  'évolution',\n",
              "  'tâche',\n",
              "  'analyse',\n",
              "  'syntaxique'],\n",
              " ['temps',\n",
              "  'linguistique',\n",
              "  'valeur',\n",
              "  'aspectuelles',\n",
              "  'schèmes',\n",
              "  'sémantico',\n",
              "  'cognitifs',\n",
              "  'graphe',\n",
              "  'conceptuels'],\n",
              " ['classification', 'numérique', 'texte', 'grams', 'multilinguisme'],\n",
              " ['interrogation',\n",
              "  'langage',\n",
              "  'naturel',\n",
              "  'modèle',\n",
              "  'relationnel',\n",
              "  'classe',\n",
              "  'objet'],\n",
              " ['système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'entité',\n",
              "  'nommée',\n",
              "  'variante',\n",
              "  'terminologique',\n",
              "  'recherche',\n",
              "  'information'],\n",
              " ['liaison',\n",
              "  'lecture',\n",
              "  'spontané',\n",
              "  'débit',\n",
              "  'parole',\n",
              "  'longueur',\n",
              "  'fréquence',\n",
              "  'lexicale'],\n",
              " ['extraction',\n",
              "  'motif',\n",
              "  'arbre',\n",
              "  'stratifié',\n",
              "  'ordonnés',\n",
              "  'distance',\n",
              "  'édition',\n",
              "  'séquence'],\n",
              " ['morphologie', 'dérivationnelle', 'analogie', 'structure', 'lexique'],\n",
              " ['synonymie',\n",
              "  'relative',\n",
              "  'synonymie',\n",
              "  'subjective',\n",
              "  'approche',\n",
              "  'statistique',\n",
              "  'distance',\n",
              "  'thématique'],\n",
              " ['mémoire',\n",
              "  'traduction',\n",
              "  'phrastique',\n",
              "  'traduction',\n",
              "  'assisté',\n",
              "  'ordinateur',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'base',\n",
              "  'exemple'],\n",
              " ['structure',\n",
              "  'textuelles',\n",
              "  'énumération',\n",
              "  'représentation',\n",
              "  'classification',\n",
              "  'modèle',\n",
              "  'texte'],\n",
              " ['dictionnairique',\n",
              "  'aide',\n",
              "  'compréhension',\n",
              "  'lecture',\n",
              "  'active',\n",
              "  'sélection',\n",
              "  'acception'],\n",
              " ['extraction', 'information', 'génomique', 'transducteur', 'linguistique'],\n",
              " ['reconnaissance',\n",
              "  'automatique',\n",
              "  'parole',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'statistique',\n",
              "  'serveur',\n",
              "  'dialogue',\n",
              "  'arbre',\n",
              "  'décision'],\n",
              " ['ressource',\n",
              "  'linguistique',\n",
              "  'base',\n",
              "  'donnée',\n",
              "  'textuelles',\n",
              "  'dictionn',\n",
              "  'aire'],\n",
              " ['cartographie',\n",
              "  'texte',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'apprentissage',\n",
              "  'automatique'],\n",
              " ['réponse', 'courriel', 'analyse', 'texte', 'analyse', 'corpus'],\n",
              " ['morphologie',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'variante',\n",
              "  'terme',\n",
              "  'médecine',\n",
              "  'terminologie',\n",
              "  'cismef',\n",
              "  'mesh'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'dictionnaire',\n",
              "  'propriété',\n",
              "  'distributionnelles',\n",
              "  'collocation',\n",
              "  'classe',\n",
              "  'objet'],\n",
              " ['désambiguïsation',\n",
              "  'sémantique',\n",
              "  'corpus',\n",
              "  'sémantiquement',\n",
              "  'étiqueté',\n",
              "  'occurrence'],\n",
              " ['génération',\n",
              "  'automatique',\n",
              "  'texte',\n",
              "  'annotation',\n",
              "  'coréférence',\n",
              "  'rôle',\n",
              "  'thématique'],\n",
              " ['agent',\n",
              "  'conversationnels',\n",
              "  'analyse',\n",
              "  'distribuée',\n",
              "  'micro',\n",
              "  'système',\n",
              "  'sémantique',\n",
              "  'procédurale'],\n",
              " ['automate',\n",
              "  'état',\n",
              "  'fini',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'extraction',\n",
              "  'automatique',\n",
              "  'phrase',\n",
              "  'classification',\n",
              "  'automatique',\n",
              "  'phrase',\n",
              "  'intex'],\n",
              " ['filtrage',\n",
              "  'information',\n",
              "  'mail',\n",
              "  'classification',\n",
              "  'message',\n",
              "  'propriété',\n",
              "  'linguistique',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'filtrage',\n",
              "  'e-mail'],\n",
              " ['recherche',\n",
              "  'documentaire',\n",
              "  'modèle',\n",
              "  'vectoriel',\n",
              "  'réduction',\n",
              "  'dimension',\n",
              "  'analyse',\n",
              "  'factorielle',\n",
              "  'réseau',\n",
              "  'neurone'],\n",
              " ['traduction', 'statistique', 'adapatabilité', 'terminologie'],\n",
              " ['réaccentuation',\n",
              "  'mot',\n",
              "  'inconnu',\n",
              "  'étiquetage',\n",
              "  'langue',\n",
              "  'spécialité',\n",
              "  'médecine'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'descendant',\n",
              "  'analyse',\n",
              "  'calculatoire',\n",
              "  'corpus',\n",
              "  'multi',\n",
              "  'lingue'],\n",
              " ['analyse', 'syntaxique', 'tabulation'],\n",
              " ['syntaxe',\n",
              "  'linguistique',\n",
              "  'mathématique',\n",
              "  'apprentissage',\n",
              "  'statistique',\n",
              "  'scfg',\n",
              "  'gibbs'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'modélisation',\n",
              "  'construction',\n",
              "  'ontologie',\n",
              "  'corpus',\n",
              "  'dégradé'],\n",
              " ['représentation',\n",
              "  'thématique',\n",
              "  'vecteur',\n",
              "  'conceptuels',\n",
              "  'antonymie',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'fonction',\n",
              "  'lexicales'],\n",
              " ['similarité',\n",
              "  'textuelles',\n",
              "  'repréesentation',\n",
              "  'vectorielle',\n",
              "  'texte',\n",
              "  'sémantique',\n",
              "  'distributionnelle',\n",
              "  'contexte',\n",
              "  'occurrence'],\n",
              " ['langue',\n",
              "  'parlée',\n",
              "  'spontanée',\n",
              "  'compréhension',\n",
              "  'automatique',\n",
              "  'méthode',\n",
              "  'formelles'],\n",
              " ['exercice', 'contextuels', 'lexique', 'corpus', 'alao'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'question',\n",
              "  'connaissance',\n",
              "  'sémantique',\n",
              "  'détection',\n",
              "  'focus'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'automatique',\n",
              "  'analyse',\n",
              "  'endogène',\n",
              "  'productivité',\n",
              "  'argument',\n",
              "  'circonstant'],\n",
              " ['taux',\n",
              "  'polysémie',\n",
              "  'taux',\n",
              "  'synonymie',\n",
              "  'lexique',\n",
              "  'sémantique',\n",
              "  'word',\n",
              "  'semcor'],\n",
              " ['morphologie',\n",
              "  'dérivationnelle',\n",
              "  'affixation',\n",
              "  'conversion',\n",
              "  'acquisition',\n",
              "  'trait',\n",
              "  'sémantique'],\n",
              " ['morphologie',\n",
              "  'dérivationnelle',\n",
              "  'ressource',\n",
              "  'lexicale',\n",
              "  'corpus',\n",
              "  'analogie'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'reconnaissance',\n",
              "  'incrémentielle',\n",
              "  'apprentissage',\n",
              "  'surcomposition',\n",
              "  'référentielle'],\n",
              " ['partage',\n",
              "  'révision',\n",
              "  'représentation',\n",
              "  'interlingue',\n",
              "  'coédition',\n",
              "  'texte',\n",
              "  'graphe',\n",
              "  'communication',\n",
              "  'multi',\n",
              "  'lingue'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'focus',\n",
              "  'patron',\n",
              "  'extraction'],\n",
              " ['ressource',\n",
              "  'linguistique',\n",
              "  'francophone',\n",
              "  'dialogue',\n",
              "  'oral',\n",
              "  'communication',\n",
              "  'homme',\n",
              "  'machine'],\n",
              " ['anaphore', 'complexe', 'référence', 'préposition', 'relatif'],\n",
              " ['métaphore',\n",
              "  'analyse',\n",
              "  'sémantique',\n",
              "  'latente',\n",
              "  'interprétation',\n",
              "  'détection',\n",
              "  'texte',\n",
              "  'littéraire'],\n",
              " ['grammaire',\n",
              "  'arbre',\n",
              "  'adjoint',\n",
              "  'métagrammaire',\n",
              "  'développement',\n",
              "  'construction',\n",
              "  'adjectivales'],\n",
              " ['langage',\n",
              "  'multimodal',\n",
              "  'coordination',\n",
              "  'mode',\n",
              "  'expression',\n",
              "  'sémantiquement',\n",
              "  'équivalentes'],\n",
              " ['dialogue',\n",
              "  'attente',\n",
              "  'pragmatique',\n",
              "  'analyse',\n",
              "  'statistique',\n",
              "  'aspect',\n",
              "  'cognitifs'],\n",
              " ['analyse',\n",
              "  'discours',\n",
              "  'compositionnalité',\n",
              "  'lambda',\n",
              "  'calcul',\n",
              "  'sdrt',\n",
              "  'acte',\n",
              "  'langage'],\n",
              " ['ressource',\n",
              "  'linguistique',\n",
              "  'corpus',\n",
              "  'dictionnaire',\n",
              "  'lexique',\n",
              "  'frantext',\n",
              "  'tlfi',\n",
              "  'stella'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'robustesse',\n",
              "  'analyse',\n",
              "  'hpsg',\n",
              "  'système',\n",
              "  'multi',\n",
              "  'agent',\n",
              "  'agentbuilder'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'profil',\n",
              "  'utilisateur',\n",
              "  'résumé',\n",
              "  'multi',\n",
              "  'document'],\n",
              " ['polysémie',\n",
              "  'calcul',\n",
              "  'sens',\n",
              "  'construction',\n",
              "  'syntaxique',\n",
              "  'espace',\n",
              "  'sémantique',\n",
              "  'préposition'],\n",
              " ['langage', 'pivot', 'phrase', 'description', 'formalisation'],\n",
              " ['anglais',\n",
              "  'étiquetage',\n",
              "  'morphologique',\n",
              "  'ambiguïté',\n",
              "  'dues',\n",
              "  'morphologie',\n",
              "  'grammaire',\n",
              "  'locale',\n",
              "  'contexte'],\n",
              " ['dérivation',\n",
              "  'suffixe',\n",
              "  'finnois',\n",
              "  'tranducteurs',\n",
              "  'nombre',\n",
              "  'fini',\n",
              "  'état'],\n",
              " ['annotation', 'sémantique', 'désambiguisation', 'sémantique', 'lexicale'],\n",
              " ['tokenisation',\n",
              "  'segmentation',\n",
              "  'chinois',\n",
              "  'gramme',\n",
              "  'approche',\n",
              "  'statistique',\n",
              "  'maximum',\n",
              "  'matching'],\n",
              " ['dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'gestion',\n",
              "  'dialogue',\n",
              "  'gestion',\n",
              "  'tâche',\n",
              "  'compréhension',\n",
              "  'interprétation'],\n",
              " ['filtrage',\n",
              "  'information',\n",
              "  'mail',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'apprentissage',\n",
              "  'spam'],\n",
              " ['désambiguïsation',\n",
              "  'sémantique',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'sémantiquement',\n",
              "  'étiqueté',\n",
              "  'occurrence'],\n",
              " ['détection', 'thème', 'création', 'vocabulaire', 'combinaison'],\n",
              " ['acquisition',\n",
              "  'lexique',\n",
              "  'extraction',\n",
              "  'patron',\n",
              "  'morpho',\n",
              "  'syntaxiques',\n",
              "  'sémantique',\n",
              "  'lexique',\n",
              "  'génératif',\n",
              "  'programmation',\n",
              "  'logique',\n",
              "  'inductive',\n",
              "  'bootstrapping',\n",
              "  'apprentissage',\n",
              "  'semi',\n",
              "  'supervisé'],\n",
              " ['grammaire',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'ressource',\n",
              "  'lexicales',\n",
              "  'ltag',\n",
              "  'représentation',\n",
              "  'compacte',\n",
              "  'lexique'],\n",
              " ['système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'fiabilité',\n",
              "  'réponse'],\n",
              " ['grammaire',\n",
              "  'dépendance',\n",
              "  'ordre',\n",
              "  'mot',\n",
              "  'prosodie',\n",
              "  'topologie',\n",
              "  'générateur',\n",
              "  'parole',\n",
              "  'grec'],\n",
              " ['compréhension',\n",
              "  'parole',\n",
              "  'concept',\n",
              "  'sémantique',\n",
              "  'réseau',\n",
              "  'bayésiens',\n",
              "  'étiquetage',\n",
              "  'sémantique',\n",
              "  'catégorisation',\n",
              "  'automatique'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'mémoire',\n",
              "  'traduction',\n",
              "  'phrastique',\n",
              "  'alignement',\n",
              "  'phrastique'],\n",
              " ['démonstratif',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'annotation',\n",
              "  'corpus',\n",
              "  'génération',\n",
              "  'texte'],\n",
              " ['stsg',\n",
              "  'gibbs',\n",
              "  'markov',\n",
              "  'maximum',\n",
              "  'entropie',\n",
              "  'vraisemblance',\n",
              "  'conditionnelle'],\n",
              " ['créole', 'martiniquais', 'grammaire', 'génération'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'recherche',\n",
              "  'dinformation',\n",
              "  'interface',\n",
              "  'graphique'],\n",
              " ['classification',\n",
              "  'automatique',\n",
              "  'rocchio',\n",
              "  'kppv',\n",
              "  'internet',\n",
              "  'filtrage',\n",
              "  'information'],\n",
              " ['acquisition',\n",
              "  'automatique',\n",
              "  'inférence',\n",
              "  'grammaticale',\n",
              "  'modèle',\n",
              "  'gold',\n",
              "  'prégroupe'],\n",
              " ['analyse',\n",
              "  'automatique',\n",
              "  'discours',\n",
              "  'cadre',\n",
              "  'discours',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'document',\n",
              "  'géographique'],\n",
              " ['traitement',\n",
              "  'aspectuo',\n",
              "  'temporel',\n",
              "  'temps',\n",
              "  'temporalité',\n",
              "  'exploration',\n",
              "  'contextuelle',\n",
              "  'analyse',\n",
              "  'sémantique',\n",
              "  'surface',\n",
              "  'ressource',\n",
              "  'linguistique'],\n",
              " ['reconnaissance',\n",
              "  'terme',\n",
              "  'évaluation',\n",
              "  'reconnaissance',\n",
              "  'terme',\n",
              "  'fastr',\n",
              "  'syrete'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'robuste',\n",
              "  'grammaire',\n",
              "  'dépendance',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'désambiguïsation',\n",
              "  'rattachement',\n",
              "  'prépositionnel'],\n",
              " ['sarfiyya',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'arabe',\n",
              "  'automate',\n",
              "  'filtrage',\n",
              "  'information',\n",
              "  'citation'],\n",
              " ['reconnaissance',\n",
              "  'lécriture',\n",
              "  'manuscrite',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'gramme',\n",
              "  'classe',\n",
              "  'perplexité'],\n",
              " ['evaluation',\n",
              "  'dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'prototypage',\n",
              "  'rapide',\n",
              "  'wizard'],\n",
              " ['langue',\n",
              "  'arabe',\n",
              "  'erreur',\n",
              "  'orthographique',\n",
              "  'correction',\n",
              "  'automatique',\n",
              "  'contexte'],\n",
              " ['indexation',\n",
              "  'automatique',\n",
              "  'terminologie',\n",
              "  'médicale',\n",
              "  'vocabulaire',\n",
              "  'contrôlé'],\n",
              " ['analyse',\n",
              "  'multimodale',\n",
              "  'linguistique',\n",
              "  'formelle',\n",
              "  'développement',\n",
              "  'grammaire',\n",
              "  'grammaire',\n",
              "  'propriété'],\n",
              " ['annotation',\n",
              "  'syntaxique',\n",
              "  'corpus',\n",
              "  'oral',\n",
              "  'nfce',\n",
              "  'annotation',\n",
              "  'référence'],\n",
              " ['automate',\n",
              "  'fini',\n",
              "  'grammaire',\n",
              "  'locale',\n",
              "  'dictionnaire',\n",
              "  'électronique',\n",
              "  'levée',\n",
              "  'ambiguïté',\n",
              "  'lexique',\n",
              "  'grammaire'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'grammaire',\n",
              "  'catégorielles',\n",
              "  'théorie',\n",
              "  'type',\n",
              "  'assistant',\n",
              "  'preuve'],\n",
              " ['dictionnaire', 'électronique', 'formalisé', 'structure', 'définitionnelle'],\n",
              " ['apprentissage',\n",
              "  'décision',\n",
              "  'automatique',\n",
              "  'recherche',\n",
              "  'documentaire',\n",
              "  'expansion',\n",
              "  'requête',\n",
              "  'évaluation',\n",
              "  'difficulté'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'architecture',\n",
              "  'interlingue',\n",
              "  'sémantique',\n",
              "  'lexicale',\n",
              "  'génération',\n",
              "  'sémanticosyntaxique',\n",
              "  'structure',\n",
              "  'syntaxique',\n",
              "  'profonde'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'slovaque',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'morphologie',\n",
              "  'flexionnelle',\n",
              "  'morphologie',\n",
              "  'dérivationnelle'],\n",
              " ['inflexion',\n",
              "  'vocalique',\n",
              "  'codage',\n",
              "  'génération',\n",
              "  'automatique',\n",
              "  'luxembourgeois'],\n",
              " ['self',\n",
              "  'organizing',\n",
              "  'text',\n",
              "  'mining',\n",
              "  'classification',\n",
              "  'vectorisation',\n",
              "  'texte',\n",
              "  'syntagme',\n",
              "  'évaluation',\n",
              "  'visuel'],\n",
              " ['sémantique', 'présupposition', 'compositionnalité'],\n",
              " ['base',\n",
              "  'lexicale',\n",
              "  'multilingue',\n",
              "  'construction',\n",
              "  'automatique',\n",
              "  'lexie',\n",
              "  'axies',\n",
              "  'acception',\n",
              "  'interlingue'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'traducteur',\n",
              "  'multilingue',\n",
              "  'multilinguisme',\n",
              "  'document',\n",
              "  'multilingue'],\n",
              " ['extraction', 'information', 'synonymie', 'entité', 'nommées', 'génomique'],\n",
              " ['macro',\n",
              "  'sémantique',\n",
              "  'analyse',\n",
              "  'rhétorique',\n",
              "  'structure',\n",
              "  'discours',\n",
              "  'extraction',\n",
              "  'information'],\n",
              " ['segmentation',\n",
              "  'thématique',\n",
              "  'métrique',\n",
              "  'beeferman',\n",
              "  'windowdiff',\n",
              "  'cohésion',\n",
              "  'lexicale',\n",
              "  'chaîne',\n",
              "  'lexicales'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'automatique',\n",
              "  'ambiguïté',\n",
              "  'rattachement',\n",
              "  'prépositionnel',\n",
              "  'procédure',\n",
              "  'endogènes',\n",
              "  'ressource',\n",
              "  'exogènes',\n",
              "  'approche',\n",
              "  'mixte'],\n",
              " ['lexique',\n",
              "  'sémantique',\n",
              "  'acquisition',\n",
              "  'corpus',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'lexique',\n",
              "  'génératif',\n",
              "  'extension',\n",
              "  'requête'],\n",
              " ['désambiguïsation',\n",
              "  'sémantique',\n",
              "  'réseau',\n",
              "  'petit',\n",
              "  'monde',\n",
              "  'hiérarchiques',\n",
              "  'dictionnaire'],\n",
              " ['analyse',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'partielle',\n",
              "  'automate',\n",
              "  'fini',\n",
              "  'pondérés'],\n",
              " ['document',\n",
              "  'auto',\n",
              "  'explicatifs',\n",
              "  'désambiguïsation',\n",
              "  'interactive',\n",
              "  'document',\n",
              "  'actif'],\n",
              " ['interprétariat',\n",
              "  'distance',\n",
              "  'réseau',\n",
              "  'collecte',\n",
              "  'corpus',\n",
              "  'oral',\n",
              "  'bilingue',\n",
              "  'dialogue',\n",
              "  'spontanés',\n",
              "  'communication',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'mutualisation',\n",
              "  'ressource'],\n",
              " ['terminologie', 'bilingue', 'corpus', 'comparable', 'terme', 'complexe'],\n",
              " ['résumé',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'ciblé',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'génération',\n",
              "  'multi',\n",
              "  'lingue'],\n",
              " ['anonymisation',\n",
              "  'désidentification',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'texte',\n",
              "  'juridiques'],\n",
              " ['accès', 'lexical', 'relation', 'sémantique', 'association', 'svetlan'],\n",
              " ['architecture',\n",
              "  'textuelle',\n",
              "  'synthèse',\n",
              "  'parole',\n",
              "  'stratégie',\n",
              "  'oralisation'],\n",
              " ['désambiguïsation',\n",
              "  'sémantique',\n",
              "  'algorithme',\n",
              "  'lesk',\n",
              "  'naive',\n",
              "  'bayes',\n",
              "  'wordnet'],\n",
              " ['grammaire',\n",
              "  'propriété',\n",
              "  'traitement',\n",
              "  'langage',\n",
              "  'naturel',\n",
              "  'contrainte',\n",
              "  'configuration'],\n",
              " ['détection',\n",
              "  'thème',\n",
              "  'étiquetage',\n",
              "  'thématique',\n",
              "  'statistique',\n",
              "  'kappa',\n",
              "  'erreur',\n",
              "  'bayes'],\n",
              " ['référence',\n",
              "  'anaphore',\n",
              "  'pronominale',\n",
              "  'dialogue',\n",
              "  'oral',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'analyse',\n",
              "  'usage',\n",
              "  'corpus'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'traitement',\n",
              "  'document',\n",
              "  'xpath'],\n",
              " ['génération',\n",
              "  'texte',\n",
              "  'logique',\n",
              "  'description',\n",
              "  'détermination',\n",
              "  'contenu',\n",
              "  'base',\n",
              "  'connaissance',\n",
              "  'assistant',\n",
              "  'preuve'],\n",
              " ['apprentissage',\n",
              "  'partiel',\n",
              "  'inférence',\n",
              "  'grammaticale',\n",
              "  'grammaire',\n",
              "  'catégorielles'],\n",
              " ['formalisme',\n",
              "  'grammatical',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'spécification',\n",
              "  'polarité'],\n",
              " ['structure', 'temporelle', 'texte', 'narratif', 'langage'],\n",
              " ['modulation',\n",
              "  'discours',\n",
              "  'modèle',\n",
              "  'dialogue',\n",
              "  'interaction',\n",
              "  'verbale',\n",
              "  'annotation'],\n",
              " ['traduction',\n",
              "  'dialogue',\n",
              "  'évaluation',\n",
              "  'subjective',\n",
              "  'objective',\n",
              "  'composant',\n",
              "  'taln'],\n",
              " ['reformulation', 'requête', 'extraction', 'information', 'personnalisation'],\n",
              " ['dialogue', 'attente', 'magicien', 'pragmatique', 'analyse', 'statistique'],\n",
              " ['évaluation', 'résumé', 'automatique', 'texte', 'français', 'géraf'],\n",
              " ['terminologie',\n",
              "  'corpus',\n",
              "  'spécialisés',\n",
              "  'structuration',\n",
              "  'terminologie',\n",
              "  'relation',\n",
              "  'transversale',\n",
              "  'verbe'],\n",
              " ['grammaire',\n",
              "  'construction',\n",
              "  'référence',\n",
              "  'extensionnelle',\n",
              "  'domaine',\n",
              "  'référence'],\n",
              " ['traitement',\n",
              "  'corpus',\n",
              "  'segment',\n",
              "  'répétés',\n",
              "  'recherche',\n",
              "  'relation',\n",
              "  'automate',\n",
              "  'transducteur'],\n",
              " ['traduction', 'parole', 'modèle', 'langage', 'représentation', 'pivot'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'analyse',\n",
              "  'sémantique',\n",
              "  'latente',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'racinisation'],\n",
              " ['analyse',\n",
              "  'texte',\n",
              "  'structure',\n",
              "  'évènements',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'sémantique',\n",
              "  'temps'],\n",
              " ['linguistique',\n",
              "  'systémique',\n",
              "  'fonctionnelle',\n",
              "  'détection',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'fouille',\n",
              "  'texte'],\n",
              " ['analyse',\n",
              "  'acoustique',\n",
              "  'arabe',\n",
              "  'standard',\n",
              "  'gémination',\n",
              "  'durée',\n",
              "  'reconnaissance',\n",
              "  'parole'],\n",
              " ['corpus', 'alao', 'indexation', 'pédagogique', 'ressource', 'textuelles'],\n",
              " ['phonologie', 'phonétique', 'classifieur', 'réseau', 'neurone'],\n",
              " ['etiquetage',\n",
              "  'memory',\n",
              "  'based',\n",
              "  'leaning',\n",
              "  'base',\n",
              "  'règle',\n",
              "  'morphosyntaxique',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['unité',\n",
              "  'discours',\n",
              "  'réseau',\n",
              "  'cohésion',\n",
              "  'analyse',\n",
              "  'thématique',\n",
              "  'littérature',\n",
              "  'potentielle'],\n",
              " ['modèle',\n",
              "  'statistique',\n",
              "  'langage',\n",
              "  'modèle',\n",
              "  'classe',\n",
              "  'décodage',\n",
              "  'sémantique',\n",
              "  'approche',\n",
              "  'componentielle',\n",
              "  'sélective'],\n",
              " ['système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'ressource',\n",
              "  'sémantique',\n",
              "  'évaluation',\n",
              "  'reformulation'],\n",
              " ['cartographie',\n",
              "  'corpus',\n",
              "  'analyse',\n",
              "  'thématique',\n",
              "  'logiciel',\n",
              "  'individu',\n",
              "  'centré',\n",
              "  'analyse',\n",
              "  'donnée',\n",
              "  'textuelles'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'morphologie',\n",
              "  'constructionnelle',\n",
              "  'incomplétude',\n",
              "  'lexicale'],\n",
              " ['alignement',\n",
              "  'corpus',\n",
              "  'parallèle',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'japonais',\n",
              "  'partielle',\n",
              "  'mémoire',\n",
              "  'traduction'],\n",
              " ['traduction',\n",
              "  'corpus',\n",
              "  'relation',\n",
              "  'lexicales',\n",
              "  'bilingue',\n",
              "  'acquisition',\n",
              "  'semi',\n",
              "  'automatique',\n",
              "  'world',\n",
              "  'wide'],\n",
              " ['langue', 'tchatée', 'ressource', 'linguistique', 'collecte', 'donnée'],\n",
              " ['apprentissage',\n",
              "  'relation',\n",
              "  'prédicat',\n",
              "  'argument',\n",
              "  'extraction',\n",
              "  'information'],\n",
              " ['syntaxe', 'analyseur', 'désambiguïsation', 'forêt', 'partagée'],\n",
              " ['navigation', 'textuelle', 'apprentissage', 'lingusitique', 'textuelle'],\n",
              " ['syntaxe', 'lexique', 'liage', 'interface', 'syntaxe', 'sémantique'],\n",
              " ['dialogue',\n",
              "  'incarné',\n",
              "  'personnage',\n",
              "  'virtuels',\n",
              "  'personnalité',\n",
              "  'génération',\n",
              "  'automatique'],\n",
              " ['segmenteur',\n",
              "  'texte',\n",
              "  'arabe',\n",
              "  'segmentation',\n",
              "  'phrase',\n",
              "  'exploration',\n",
              "  'contextuelle',\n",
              "  'expression',\n",
              "  'rationnelles'],\n",
              " ['mémoire',\n",
              "  'traduction',\n",
              "  'traduction',\n",
              "  'probabiliste',\n",
              "  'alignement',\n",
              "  'multiple',\n",
              "  'ordonnancement',\n",
              "  'postériori'],\n",
              " ['trouble',\n",
              "  'langage',\n",
              "  'simplification',\n",
              "  'syntaxique',\n",
              "  'règle',\n",
              "  'réécriture',\n",
              "  'validation',\n",
              "  'interactive',\n",
              "  'traitement',\n",
              "  'texte'],\n",
              " ['indexation',\n",
              "  'automatique',\n",
              "  'terminologie',\n",
              "  'médicale',\n",
              "  'vocabulaire',\n",
              "  'contrôlé'],\n",
              " ['système',\n",
              "  'dialogue',\n",
              "  'simulation',\n",
              "  'dialogue',\n",
              "  'modèle',\n",
              "  'utilisateur',\n",
              "  'optimisation'],\n",
              " ['correction',\n",
              "  'automatique',\n",
              "  'temps',\n",
              "  'réel',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'grammaire',\n",
              "  'contrainte'],\n",
              " ['théorie',\n",
              "  'sens',\n",
              "  'texte',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'synchronisation',\n",
              "  'grammaire',\n",
              "  'unification',\n",
              "  'polarisée',\n",
              "  'grammaire',\n",
              "  'dépendance',\n",
              "  'grammaire',\n",
              "  'topologique',\n",
              "  'génération',\n",
              "  'texte'],\n",
              " ['indexation',\n",
              "  'sémantique',\n",
              "  'recherche',\n",
              "  'documentaire',\n",
              "  'redondance',\n",
              "  'minimale',\n",
              "  'ontologie'],\n",
              " ['antonymie',\n",
              "  'morphologie',\n",
              "  'antonymie',\n",
              "  'complémentaire',\n",
              "  'antonymie',\n",
              "  'scalaire',\n",
              "  'antonymie',\n",
              "  'duale',\n",
              "  'répartition',\n",
              "  'statistique'],\n",
              " ['langue',\n",
              "  'spécialité',\n",
              "  'langue',\n",
              "  'générale',\n",
              "  'structuration',\n",
              "  'terminologie',\n",
              "  'synonyme',\n",
              "  'portabilité',\n",
              "  'filtrage'],\n",
              " ['analyse', 'syntaxique', 'analyse', 'superficielle', 'analyse', 'profonde'],\n",
              " ['français',\n",
              "  'langue',\n",
              "  'étranger',\n",
              "  'itinéraire',\n",
              "  'acquisition',\n",
              "  'évaluation',\n",
              "  'annotation',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'partielle'],\n",
              " ['pronom',\n",
              "  'impersonnel',\n",
              "  'explétif',\n",
              "  'pronom',\n",
              "  'anaphorique',\n",
              "  'lexique',\n",
              "  'grammaire',\n",
              "  'automate',\n",
              "  'résolution',\n",
              "  'anaphore',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'modulaire'],\n",
              " ['erreur',\n",
              "  'orthographiques',\n",
              "  'cachées',\n",
              "  'détection',\n",
              "  'correction',\n",
              "  'système',\n",
              "  'multiagent',\n",
              "  'analyse',\n",
              "  'linguistique',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['logique',\n",
              "  'premier',\n",
              "  'ordre',\n",
              "  'calcul',\n",
              "  'prédicat',\n",
              "  'représentation',\n",
              "  'sémantique',\n",
              "  'relation',\n",
              "  'prédicat',\n",
              "  'argument',\n",
              "  'quantificateur',\n",
              "  'grammaire',\n",
              "  'unification',\n",
              "  'polarisée',\n",
              "  'grammaire',\n",
              "  'dépendance',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique'],\n",
              " ['résumé', 'automatique', 'compression', 'phrase', 'analyse', 'syntaxique'],\n",
              " ['segmentation', 'automatique', 'texte', 'analyse', 'sémantique', 'latente'],\n",
              " ['navigation',\n",
              "  'intra',\n",
              "  'documentaire',\n",
              "  'analyse',\n",
              "  'thématique',\n",
              "  'structure',\n",
              "  'discours',\n",
              "  'relation',\n",
              "  'discursives',\n",
              "  'subordination',\n",
              "  'coordination',\n",
              "  'parallélisme',\n",
              "  'lexico',\n",
              "  'syntaxico',\n",
              "  'sémantique',\n",
              "  'modèle',\n",
              "  'apprentissage',\n",
              "  'analyse',\n",
              "  'linguistique'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'segment',\n",
              "  'discontinu',\n",
              "  'modèle',\n",
              "  'linéaire'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'terme',\n",
              "  'terminologie',\n",
              "  'biomédicale',\n",
              "  'apprentissage',\n",
              "  'artificiel',\n",
              "  'inférence',\n",
              "  'transducteur'],\n",
              " ['facteur',\n",
              "  'saillance',\n",
              "  'saillance',\n",
              "  'linguistique',\n",
              "  'saillance',\n",
              "  'visuel',\n",
              "  'principe',\n",
              "  'primordialité',\n",
              "  'principe',\n",
              "  'singularité',\n",
              "  'structure',\n",
              "  'communicative',\n",
              "  'méthode',\n",
              "  'quantification'],\n",
              " ['syntaxe', 'subordination', 'dépendance', 'topologie'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'sémantique',\n",
              "  'arbre',\n",
              "  'dépendance',\n",
              "  'forêt',\n",
              "  'partagée',\n",
              "  'forêt',\n",
              "  'dérivation'],\n",
              " ['modèle', 'langage', 'statistique', 'gramme', 'multigramme', 'évaluation'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'ambiguïté',\n",
              "  'rattachement',\n",
              "  'prépositionnel',\n",
              "  'catégorisation',\n",
              "  'syntaxique'],\n",
              " ['lexique',\n",
              "  'informatisé',\n",
              "  'incomplétude',\n",
              "  'lexicale',\n",
              "  'mot',\n",
              "  'inconnu',\n",
              "  'typologie'],\n",
              " ['information',\n",
              "  'biographique',\n",
              "  'modélisation',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'transducteur',\n",
              "  'état',\n",
              "  'fini',\n",
              "  'entité',\n",
              "  'nommée',\n",
              "  'relation',\n",
              "  'base',\n",
              "  'connaissance'],\n",
              " ['repérage',\n",
              "  'automatique',\n",
              "  'information',\n",
              "  'évolutives',\n",
              "  'corpus',\n",
              "  'texte',\n",
              "  'encyclopédiques',\n",
              "  'marqueur',\n",
              "  'textuels',\n",
              "  'discursifs'],\n",
              " ['terme',\n",
              "  'complexe',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'monde',\n",
              "  'lexicaux',\n",
              "  'world',\n",
              "  'wide'],\n",
              " ['chaîne',\n",
              "  'coréférentielle',\n",
              "  'détection',\n",
              "  'automatique',\n",
              "  'variante',\n",
              "  'terme',\n",
              "  'anaphore',\n",
              "  'nominale'],\n",
              " ['compréhension',\n",
              "  'texte',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'désambiguïsation',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'reconnaissance',\n",
              "  'schéma',\n",
              "  'logique',\n",
              "  'prédicat',\n",
              "  'unification',\n",
              "  'rôle',\n",
              "  'thématique',\n",
              "  'contrainte',\n",
              "  'sélection',\n",
              "  'verbnet',\n",
              "  'wordnet',\n",
              "  'link',\n",
              "  'grammar',\n",
              "  'parser'],\n",
              " ['langue',\n",
              "  'signe',\n",
              "  'représentation',\n",
              "  'lexique',\n",
              "  'paramètre',\n",
              "  'géométrie',\n",
              "  'spatiale'],\n",
              " ['lexique',\n",
              "  'syntaxique',\n",
              "  'hpsg',\n",
              "  'lexical',\n",
              "  'markup',\n",
              "  'framework',\n",
              "  'projection',\n",
              "  'lexicale'],\n",
              " ['taln',\n",
              "  'nooj',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'analyse',\n",
              "  'lexicale',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'grammaire',\n",
              "  'morphologique',\n",
              "  'agglutination',\n",
              "  'voyellation'],\n",
              " ['hypothèse',\n",
              "  'concurrentes',\n",
              "  'architecture',\n",
              "  'contrôle',\n",
              "  'aide',\n",
              "  'multicritère',\n",
              "  'décision'],\n",
              " ['classifieur', 'bayésien', 'naïf', 'coréférence', 'entité', 'nommées'],\n",
              " ['désambiguïsation',\n",
              "  'sémantique',\n",
              "  'modèle',\n",
              "  'vectoriel',\n",
              "  'traitement',\n",
              "  'parole',\n",
              "  'arabe',\n",
              "  'influence',\n",
              "  'sémantique'],\n",
              " ['correcteur',\n",
              "  'orthographique',\n",
              "  'correcteur',\n",
              "  'grammatical',\n",
              "  'français',\n",
              "  'outil',\n",
              "  'correction',\n",
              "  'linguistique',\n",
              "  'microsoft',\n",
              "  'réforme',\n",
              "  'orthographe',\n",
              "  'féminisation',\n",
              "  'nom',\n",
              "  'métier'],\n",
              " ['polysémie',\n",
              "  'occurrence',\n",
              "  'correspondance',\n",
              "  'traduction',\n",
              "  'prédiction',\n",
              "  'traduction'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'motif',\n",
              "  'lexico',\n",
              "  'syntaxiques',\n",
              "  'analyse',\n",
              "  'lexicale',\n",
              "  'ressource',\n",
              "  'linguistique',\n",
              "  'format',\n",
              "  'échange',\n",
              "  'automate',\n",
              "  'fini',\n",
              "  'réseau',\n",
              "  'transition',\n",
              "  'récursifs'],\n",
              " ['acquisition', 'concept', 'bilingue', 'alignement', 'superficiel'],\n",
              " ['système', 'question', 'réponse', 'question', 'booléennes'],\n",
              " ['morphologie',\n",
              "  'corpus',\n",
              "  'journalistique',\n",
              "  'able',\n",
              "  'productivité',\n",
              "  'morphologique',\n",
              "  'quantitative'],\n",
              " ['dictionnaire', 'électronique', 'flexion', 'forme', 'dérivée'],\n",
              " ['référence', 'anaphore', 'contexte', 'perception', 'visuel', 'saillance'],\n",
              " ['traduction',\n",
              "  'probabiliste',\n",
              "  'adaptabilité',\n",
              "  'aspiration',\n",
              "  'texte',\n",
              "  'mémoire',\n",
              "  'traduction'],\n",
              " ['sémantique', 'inférentielle', 'raisonnement', 'monot', 'causalité'],\n",
              " ['résolution',\n",
              "  'référence',\n",
              "  'dialogue',\n",
              "  'humain',\n",
              "  'évaluation',\n",
              "  'quantitative'],\n",
              " ['lexique',\n",
              "  'syntaxe',\n",
              "  'lexique',\n",
              "  'grammaire',\n",
              "  'catégorisation',\n",
              "  'standardisation'],\n",
              " ['question', 'réponse', 'prédiction', 'difficulté', 'arbre', 'décision'],\n",
              " ['évolution',\n",
              "  'terminologique',\n",
              "  'corpus',\n",
              "  'diachronique',\n",
              "  'terme',\n",
              "  'complexe',\n",
              "  'variation',\n",
              "  'terminologique',\n",
              "  'distance'],\n",
              " ['ressource',\n",
              "  'lexico',\n",
              "  'sémantique',\n",
              "  'dictionnaire',\n",
              "  'sémique',\n",
              "  'sémantique',\n",
              "  'textuelle',\n",
              "  'classification',\n",
              "  'automatique',\n",
              "  'jaccard'],\n",
              " ['phrase',\n",
              "  'nominale',\n",
              "  'arabe',\n",
              "  'grammaire',\n",
              "  'hpsg',\n",
              "  'schéma',\n",
              "  'adapté',\n",
              "  'analyse',\n",
              "  'syntaxique'],\n",
              " ['segmentation', 'automatique', 'évaluation', 'accord', 'interjuges'],\n",
              " ['analyseur',\n",
              "  'syntaxique',\n",
              "  'modèle',\n",
              "  'patron',\n",
              "  'indice',\n",
              "  'corrélation',\n",
              "  'grammaire',\n",
              "  'propriété',\n",
              "  'technique',\n",
              "  'analyse',\n",
              "  'hybride'],\n",
              " ['modélisation',\n",
              "  'statistique',\n",
              "  'langage',\n",
              "  'modèle',\n",
              "  'distants',\n",
              "  'combinaison',\n",
              "  'linéaire'],\n",
              " ['dictionnaire',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'banque',\n",
              "  'terminologique',\n",
              "  'juridique',\n",
              "  'édition',\n",
              "  'terme'],\n",
              " ['gestion',\n",
              "  'lexique',\n",
              "  'base',\n",
              "  'donnée',\n",
              "  'linguistique',\n",
              "  'ressource',\n",
              "  'linguistique',\n",
              "  'multilinguisme',\n",
              "  'architecture',\n",
              "  'linguistique'],\n",
              " ['réseau',\n",
              "  'neurone',\n",
              "  'perceptron',\n",
              "  'multi',\n",
              "  'couche',\n",
              "  'classification',\n",
              "  'poème',\n",
              "  'arabe',\n",
              "  'syllabe',\n",
              "  'analyse',\n",
              "  'phonétique'],\n",
              " ['traduction',\n",
              "  'assisté',\n",
              "  'ordinateur',\n",
              "  'mémoire',\n",
              "  'traduction',\n",
              "  'phrastique',\n",
              "  'récupération',\n",
              "  'sensible',\n",
              "  'contexte',\n",
              "  'détection',\n",
              "  'domaine',\n",
              "  'traduction'],\n",
              " ['analyse',\n",
              "  'syntaxico',\n",
              "  'sémantique',\n",
              "  'ontologie',\n",
              "  'représentation',\n",
              "  'ontologiques',\n",
              "  'sémantique'],\n",
              " ['thésaurus', 'vecteur', 'conceptuels', 'notion', 'base', 'évolutivité'],\n",
              " ['grammaire',\n",
              "  'syntaxe',\n",
              "  'lexicalisation',\n",
              "  'réseau',\n",
              "  'transition',\n",
              "  'récursifs'],\n",
              " ['analyseur', 'syntaxique', 'clitique', 'traitement', 'multi', 'lingue'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'partielle',\n",
              "  'proposition',\n",
              "  'syntaxique',\n",
              "  'subordination',\n",
              "  'prolog'],\n",
              " ['métaphore',\n",
              "  'conceptuelles',\n",
              "  'visualisation',\n",
              "  'corpus',\n",
              "  'linguistique',\n",
              "  'corpus'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'coordination',\n",
              "  'ellipse',\n",
              "  'forêt',\n",
              "  'partagée',\n",
              "  'forêt',\n",
              "  'dérivation'],\n",
              " ['classification',\n",
              "  'spectrale',\n",
              "  'continue',\n",
              "  'segmentation',\n",
              "  'texte',\n",
              "  'identification',\n",
              "  'langue'],\n",
              " ['modèle',\n",
              "  'langage',\n",
              "  'adaptation',\n",
              "  'utilisateur',\n",
              "  'thème',\n",
              "  'aide',\n",
              "  'handicap'],\n",
              " ['analogie',\n",
              "  'proportion',\n",
              "  'chaîness',\n",
              "  'symbole',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'divergence',\n",
              "  'langue'],\n",
              " ['commande',\n",
              "  'langue',\n",
              "  'naturel',\n",
              "  'analyse',\n",
              "  'structurelle',\n",
              "  'surface',\n",
              "  'modélisation',\n",
              "  'logique',\n",
              "  'ontologie'],\n",
              " ['alao', 'détection', 'erreur', 'morphologie', 'flexionnelle', 'rétroaction'],\n",
              " ['définition',\n",
              "  'terminographique',\n",
              "  'annotation',\n",
              "  'automatique',\n",
              "  'repérage',\n",
              "  'frontière',\n",
              "  'indice',\n",
              "  'morpho',\n",
              "  'syntaxiques',\n",
              "  'langage'],\n",
              " ['fonction',\n",
              "  'lexicales',\n",
              "  'standard',\n",
              "  'modélisation',\n",
              "  'relation',\n",
              "  'sémanticolexicales',\n",
              "  'dico'],\n",
              " ['communication',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'multimodale',\n",
              "  'référence',\n",
              "  'saillance'],\n",
              " ['réseau', 'sémantique', 'accès', 'lexical', 'profil', 'utilisateur'],\n",
              " ['ressource',\n",
              "  'prédicative',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'patron',\n",
              "  'lexico',\n",
              "  'syntaxiques'],\n",
              " ['corpus',\n",
              "  'requête',\n",
              "  'assistance',\n",
              "  'agent',\n",
              "  'conversationnel',\n",
              "  'activité',\n",
              "  'conversationnelle',\n",
              "  'acte',\n",
              "  'dialogue'],\n",
              " ['alignement',\n",
              "  'multilingue',\n",
              "  'corpus',\n",
              "  'parrallèles',\n",
              "  'multitextes',\n",
              "  'multi',\n",
              "  'document',\n",
              "  'extraction',\n",
              "  'structure',\n",
              "  'alignement',\n",
              "  'endogène'],\n",
              " ['système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'évaluation',\n",
              "  'focus'],\n",
              " ['segment',\n",
              "  'information',\n",
              "  'évolutive',\n",
              "  'segmentation',\n",
              "  'algorithme',\n",
              "  'texttiling'],\n",
              " ['génération', 'dialogue', 'architecture', 'modulaire', 'portabilité'],\n",
              " ['analyse',\n",
              "  'discours',\n",
              "  'résolution',\n",
              "  'anaphorique',\n",
              "  'anaphore',\n",
              "  'pronominales',\n",
              "  'anaphore',\n",
              "  'grammaire',\n",
              "  'propriété',\n",
              "  'grammaire',\n",
              "  'fonctionnelle',\n",
              "  'analyse',\n",
              "  'dynamique',\n",
              "  'discours',\n",
              "  'oral'],\n",
              " ['antidote',\n",
              "  'sixième',\n",
              "  'édition',\n",
              "  'antidote',\n",
              "  'logiciel',\n",
              "  'aide',\n",
              "  'rédaction',\n",
              "  'développé',\n",
              "  'commercialisé',\n",
              "  'société',\n",
              "  'druide',\n",
              "  'informatique',\n",
              "  'antidote',\n",
              "  'comporte',\n",
              "  'correcteur',\n",
              "  'grammatical',\n",
              "  'avancé',\n",
              "  'dictionnaire',\n",
              "  'consultation',\n",
              "  'guide',\n",
              "  'linguistique',\n",
              "  'fonctionne',\n",
              "  'système',\n",
              "  'exploitation',\n",
              "  'window',\n",
              "  'linux'],\n",
              " ['cordial',\n",
              "  'correcteur',\n",
              "  'efficace',\n",
              "  'discret',\n",
              "  'enrichi',\n",
              "  'grand',\n",
              "  'nombre',\n",
              "  'fonction',\n",
              "  'aide',\n",
              "  'rédaction',\n",
              "  'analyse',\n",
              "  'document',\n",
              "  'riche',\n",
              "  'multiple',\n",
              "  'dictionnaire',\n",
              "  'souvent',\n",
              "  'pertinent',\n",
              "  'proposition',\n",
              "  'cordial',\n",
              "  'compagnon',\n",
              "  'précieux',\n",
              "  'permet',\n",
              "  'assurer',\n",
              "  'qualité',\n",
              "  'écrit',\n",
              "  'version',\n",
              "  'cordial',\n",
              "  'intègre',\n",
              "  'vaste',\n",
              "  'éventail',\n",
              "  'logiciel',\n",
              "  'traitement',\n",
              "  'texte',\n",
              "  'word',\n",
              "  'open',\n",
              "  'office',\n",
              "  'word',\n",
              "  'perfect',\n",
              "  'client',\n",
              "  'messagerie',\n",
              "  'outlook',\n",
              "  'note',\n",
              "  'thunderbird',\n",
              "  'webmails',\n",
              "  'navigateur',\n",
              "  'explorer',\n",
              "  'mozilla'],\n",
              " ['traduction',\n",
              "  'assisté',\n",
              "  'ordinateur',\n",
              "  'vérification',\n",
              "  'automatique',\n",
              "  'traduction',\n",
              "  'révision',\n",
              "  'traduction'],\n",
              " ['créé',\n",
              "  'initiative',\n",
              "  'centre',\n",
              "  'national',\n",
              "  'recherche',\n",
              "  'scientifique',\n",
              "  'cnrtl',\n",
              "  'propose',\n",
              "  'plate',\n",
              "  'forme',\n",
              "  'unifiée',\n",
              "  'accès',\n",
              "  'ressource',\n",
              "  'document',\n",
              "  'électronique',\n",
              "  'destinés',\n",
              "  'étude',\n",
              "  'analyse',\n",
              "  'langue',\n",
              "  'français',\n",
              "  'service',\n",
              "  'cnrtl',\n",
              "  'comprennent',\n",
              "  'recensement',\n",
              "  'documentation',\n",
              "  'méta',\n",
              "  'donnée',\n",
              "  'normalisation',\n",
              "  'archivage',\n",
              "  'enrichissement',\n",
              "  'diffusion',\n",
              "  'ressource',\n",
              "  'pérennité',\n",
              "  'service',\n",
              "  'donnée',\n",
              "  'garantie',\n",
              "  'soutien',\n",
              "  'institutionnel',\n",
              "  'cnrs',\n",
              "  'adossement',\n",
              "  'laboratoire',\n",
              "  'recherche',\n",
              "  'linguistique',\n",
              "  'informatique',\n",
              "  'cnrs',\n",
              "  'nancy',\n",
              "  'université',\n",
              "  'atilf',\n",
              "  'analyse',\n",
              "  'traitement',\n",
              "  'informatique',\n",
              "  'langue',\n",
              "  'français',\n",
              "  'ainsi',\n",
              "  'intégration',\n",
              "  'réseau',\n",
              "  'européen',\n",
              "  'clarin',\n",
              "  'common',\n",
              "  'language',\n",
              "  'resources',\n",
              "  'technology',\n",
              "  'infrastructure',\n",
              "  'european'],\n",
              " ['réseau',\n",
              "  'neurone',\n",
              "  'réseau',\n",
              "  'hopfield',\n",
              "  'résumé',\n",
              "  'frontière',\n",
              "  'thématique'],\n",
              " ['réseau',\n",
              "  'bayésiens',\n",
              "  'résolution',\n",
              "  'anaphore',\n",
              "  'connaissance',\n",
              "  'linguistique',\n",
              "  'indice',\n",
              "  'surface'],\n",
              " ['évaluation',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'mot',\n",
              "  'inconnu',\n",
              "  'morphologie',\n",
              "  'constructionnelle'],\n",
              " ['analyse',\n",
              "  'morphosémantique',\n",
              "  'composition',\n",
              "  'savant',\n",
              "  'terminologie',\n",
              "  'médicale'],\n",
              " ['traduction',\n",
              "  'artificielle',\n",
              "  'terminologie',\n",
              "  'biomédicale',\n",
              "  'apprentissage',\n",
              "  'artificiel',\n",
              "  'modèle',\n",
              "  'langue'],\n",
              " ['corpus', 'correction', 'orthographique', 'tilt', 'evaluation'],\n",
              " ['grammaire',\n",
              "  'catégorielles',\n",
              "  'dépendance',\n",
              "  'grammaire',\n",
              "  'multimodales',\n",
              "  'analyseur',\n",
              "  'syntaxique'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'désambiguïsation',\n",
              "  'sémantique',\n",
              "  'polysémie',\n",
              "  'adjectivale',\n",
              "  'construction',\n",
              "  'dynamique',\n",
              "  'sens',\n",
              "  'synonymie',\n",
              "  'classe',\n",
              "  'distributionnelles',\n",
              "  'corpus',\n",
              "  'espace',\n",
              "  'sémantique',\n",
              "  'espace',\n",
              "  'distributionnel'],\n",
              " ['désambiguïsation',\n",
              "  'contextuelle',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'substituabilité',\n",
              "  'traduction'],\n",
              " ['préposition', 'lexique', 'analyse', 'syntaxique'],\n",
              " ['lexique', 'syntaxique', 'lexique', 'grammaire', 'dicovalence', 'lefff'],\n",
              " ['étiqueteur', 'sémantique', 'dictionnaire', 'xpath'],\n",
              " ['erreur',\n",
              "  'cachée',\n",
              "  'erreur',\n",
              "  'sémantique',\n",
              "  'détection',\n",
              "  'correction',\n",
              "  'système',\n",
              "  'multi',\n",
              "  'agent',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['multilingue',\n",
              "  'framenet',\n",
              "  'annotation',\n",
              "  'sémantique',\n",
              "  'automatique',\n",
              "  'sémantique',\n",
              "  'lexicale',\n",
              "  'projection',\n",
              "  'annotation',\n",
              "  'rôle',\n",
              "  'rôle',\n",
              "  'sémantique'],\n",
              " ['antidote',\n",
              "  'occurrence',\n",
              "  'collocation',\n",
              "  'corpus',\n",
              "  'analyseur',\n",
              "  'correcteur'],\n",
              " ['alignement',\n",
              "  'monolingue',\n",
              "  'distance',\n",
              "  'édition',\n",
              "  'déplacement',\n",
              "  'critique',\n",
              "  'génétique',\n",
              "  'textuelle'],\n",
              " ['famille', 'morphologiques', 'classification', 'apprentissage', 'supervisé'],\n",
              " ['alignement',\n",
              "  'phrase',\n",
              "  'corpus',\n",
              "  'parallèle',\n",
              "  'recherche',\n",
              "  'cross',\n",
              "  'lingue',\n",
              "  'information'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'sémantiquement',\n",
              "  'étiqueté',\n",
              "  'occurrence',\n",
              "  'sélection',\n",
              "  'indice',\n",
              "  'algorithme',\n",
              "  'génétique'],\n",
              " ['linguistique', 'textuelle', 'énonciation', 'représentation', 'sémantique'],\n",
              " ['chunker',\n",
              "  'super',\n",
              "  'chunk',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'patron',\n",
              "  'lexico',\n",
              "  'syntaxiques'],\n",
              " ['prédiction',\n",
              "  'satisfaction',\n",
              "  'usager',\n",
              "  'classification',\n",
              "  'dialogue',\n",
              "  'machine'],\n",
              " ['réalisation', 'surface', 'grammaire', 'arbre', 'adjoint', 'réversibilité'],\n",
              " ['linguistique',\n",
              "  'corpus',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'algorithme',\n",
              "  'apprentissage',\n",
              "  'analyse',\n",
              "  'stylistique',\n",
              "  'degré',\n",
              "  'comparabilité'],\n",
              " ['plateforme',\n",
              "  'annotation',\n",
              "  'linguistique',\n",
              "  'passage',\n",
              "  'échelle',\n",
              "  'robustesse'],\n",
              " ['alao',\n",
              "  'apprentissage',\n",
              "  'langue',\n",
              "  'diagnostic',\n",
              "  'erreur',\n",
              "  'feed',\n",
              "  'back',\n",
              "  'erreur'],\n",
              " ['ressource', 'linguistique', 'chinois', 'linguistique', 'corpus', 'nooj'],\n",
              " ['étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'corpus',\n",
              "  'texte',\n",
              "  'langue',\n",
              "  'kabyle',\n",
              "  'berbère'],\n",
              " ['analyseur',\n",
              "  'grec',\n",
              "  'analyse',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'syntagme',\n",
              "  'nominal',\n",
              "  'grec',\n",
              "  'moderne'],\n",
              " ['apprentissage',\n",
              "  'symbolique',\n",
              "  'modèle',\n",
              "  'gold',\n",
              "  'grammaire',\n",
              "  'catégorielles'],\n",
              " ['acquisition',\n",
              "  'lexicale',\n",
              "  'lexique',\n",
              "  'référence',\n",
              "  'français',\n",
              "  'modèle',\n",
              "  'lexique',\n",
              "  'génératif',\n",
              "  'morphologie',\n",
              "  'constructionnelle',\n",
              "  'corpus',\n",
              "  'sémantique'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'approche',\n",
              "  'statistique',\n",
              "  'modélisation',\n",
              "  'linguistique',\n",
              "  'espace',\n",
              "  'continu',\n",
              "  'analyse',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'désambiguïsation',\n",
              "  'lexicale'],\n",
              " ['réécriture',\n",
              "  'phrase',\n",
              "  'dyslexie',\n",
              "  'automate',\n",
              "  'correction',\n",
              "  'orthographique'],\n",
              " ['méthodologie',\n",
              "  'contrôle',\n",
              "  'aide',\n",
              "  'multicritère',\n",
              "  'décision',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'métrique'],\n",
              " ['annotation', 'temporelle', 'repérage', 'événement', 'timeml'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'annotation',\n",
              "  'grammaire',\n",
              "  'locale',\n",
              "  'nooj',\n",
              "  'base',\n",
              "  'connaissance'],\n",
              " ['analyse', 'syntaxique', 'japonais', 'grammaire'],\n",
              " ['compréhension', 'langage', 'langue', 'parlée', 'spontanée'],\n",
              " ['induction',\n",
              "  'lexicale',\n",
              "  'transducteur',\n",
              "  'stochastique',\n",
              "  'langue',\n",
              "  'apparentées'],\n",
              " ['génération',\n",
              "  'intégrée',\n",
              "  'localisée',\n",
              "  'architecture',\n",
              "  'génération',\n",
              "  'sdrt',\n",
              "  'segmentation',\n",
              "  'discours'],\n",
              " ['génération',\n",
              "  'automatique',\n",
              "  'dictionnaire',\n",
              "  'condition',\n",
              "  'structure',\n",
              "  'morphématique'],\n",
              " ['citation', 'contruction', 'étude', 'corpus', 'genre', 'journalistique'],\n",
              " ['question', 'réponse', 'enchainée'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'annotation',\n",
              "  'information',\n",
              "  'spatio',\n",
              "  'temporelles',\n",
              "  'tourisme',\n",
              "  'page'],\n",
              " ['alignement',\n",
              "  'proposition',\n",
              "  'syntaxique',\n",
              "  'étude',\n",
              "  'contrastives',\n",
              "  'français',\n",
              "  'japonais',\n",
              "  'similarité',\n",
              "  'lexicale'],\n",
              " ['grammaire',\n",
              "  'sémantique',\n",
              "  'réversibilité',\n",
              "  'analyse',\n",
              "  'génération',\n",
              "  'dialogue'],\n",
              " ['dialogue',\n",
              "  'finalisé',\n",
              "  'multimodalité',\n",
              "  'évaluation',\n",
              "  'dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'paradigme',\n",
              "  'évaluation',\n",
              "  'test',\n",
              "  'utilisateur',\n",
              "  'diagnostic',\n",
              "  'paraphrase',\n",
              "  'multimodale'],\n",
              " ['ressource',\n",
              "  'lexicale',\n",
              "  'morphologie',\n",
              "  'dérivationnelle',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'famille',\n",
              "  'mot'],\n",
              " ['morphologie',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'génération',\n",
              "  'néologisme',\n",
              "  'étude',\n",
              "  'empiriques'],\n",
              " ['regroupement', 'document', 'suivi', 'événement'],\n",
              " ['acte', 'langage', 'complexe', 'structure', 'dialogue', 'terrain', 'commun'],\n",
              " ['langage',\n",
              "  'représentation',\n",
              "  'évènementielle',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'structure',\n",
              "  'prédicative',\n",
              "  'structure',\n",
              "  'predicate',\n",
              "  'argument'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'indexation',\n",
              "  'lemmatisation',\n",
              "  'google'],\n",
              " ['normalisation',\n",
              "  'syntaxique',\n",
              "  'détection',\n",
              "  'implication',\n",
              "  'textuelle',\n",
              "  'réécriture',\n",
              "  'graphe'],\n",
              " ['expression',\n",
              "  'temporelles',\n",
              "  'calendaires',\n",
              "  'modélisation',\n",
              "  'algébrique',\n",
              "  'visualisation'],\n",
              " ['extraction', 'information', 'temporelle', 'timeml'],\n",
              " ['extraction',\n",
              "  'automatique',\n",
              "  'micro',\n",
              "  'texte',\n",
              "  'texte',\n",
              "  'structuré',\n",
              "  'petit',\n",
              "  'annonce'],\n",
              " ['système',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'compacité',\n",
              "  'densité',\n",
              "  'combinaison',\n",
              "  'score'],\n",
              " ['dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'cohérence',\n",
              "  'discursive',\n",
              "  'connecteur',\n",
              "  'concessifs',\n",
              "  'sémantique',\n",
              "  'pragmatique'],\n",
              " ['dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'robustesse',\n",
              "  'ancrage',\n",
              "  'compréhension',\n",
              "  'mutuelle'],\n",
              " ['énergie',\n",
              "  'textuelle',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'modèle',\n",
              "  'hopfield',\n",
              "  'résumé',\n",
              "  'automatique',\n",
              "  'frontière',\n",
              "  'thématique'],\n",
              " ['résumé',\n",
              "  'automatique',\n",
              "  'filtrage',\n",
              "  'phrase',\n",
              "  'optimisation',\n",
              "  'multi',\n",
              "  'objectif',\n",
              "  'algorithme',\n",
              "  'génétique'],\n",
              " ['traduction', 'statistique', 'recherche', 'locale', 'post', 'traitement'],\n",
              " ['modélisation', 'grammaire', 'variation', 'dialectale'],\n",
              " ['wordnet', 'corpus', 'alignés', 'wikipédia', 'sémantique', 'lexicale'],\n",
              " ['polysémie',\n",
              "  'régulière',\n",
              "  'métaphore',\n",
              "  'métonymie',\n",
              "  'word',\n",
              "  'désambiguïsation',\n",
              "  'lexicale'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'triggers',\n",
              "  'inter',\n",
              "  'langue',\n",
              "  'information',\n",
              "  'mutuelle',\n",
              "  'corpus',\n",
              "  'parallèle',\n",
              "  'décodage'],\n",
              " ['désambiguïsation', 'supervisée', 'treillis', 'galois', 'entité', 'nommées'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'métonymie',\n",
              "  'méthode',\n",
              "  'hybride',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'robuste',\n",
              "  'approche',\n",
              "  'distributionnelle'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'analyseur',\n",
              "  'stochastique',\n",
              "  'analyseur',\n",
              "  'symbolique',\n",
              "  'superficiel',\n",
              "  'chunker'],\n",
              " ['apprentissage', 'automatique', 'classification', 'training'],\n",
              " ['corpus',\n",
              "  'spécialisé',\n",
              "  'unité',\n",
              "  'lexicale',\n",
              "  'lexie',\n",
              "  'extraction',\n",
              "  'lexique',\n",
              "  'chinois'],\n",
              " ['lisibilité',\n",
              "  'régression',\n",
              "  'logistique',\n",
              "  'bagging',\n",
              "  'boosting',\n",
              "  'modèle',\n",
              "  'langue'],\n",
              " ['syntaxe',\n",
              "  'grammaire',\n",
              "  'catégorielles',\n",
              "  'abstraites',\n",
              "  'type',\n",
              "  'dépendant',\n",
              "  'mouvement',\n",
              "  'explicites',\n",
              "  'extraction'],\n",
              " ['normalisation',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'traitement',\n",
              "  'information',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'méthode',\n",
              "  'endogènes',\n",
              "  'système',\n",
              "  'complexe'],\n",
              " ['distance',\n",
              "  'intertextuelle',\n",
              "  'arabe',\n",
              "  'classification',\n",
              "  'lemmatisation',\n",
              "  'corpus',\n",
              "  'statistique',\n",
              "  'lexicale'],\n",
              " ['argumentation', 'insinuation', 'norme', 'coutumières', 'justification'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'probabiliste',\n",
              "  'corpus',\n",
              "  'arborés',\n",
              "  'évaluation',\n",
              "  'analyse',\n",
              "  'français'],\n",
              " ['analyse',\n",
              "  'morphologique',\n",
              "  'annotation',\n",
              "  'sémantique',\n",
              "  'composition',\n",
              "  'savant',\n",
              "  'nom',\n",
              "  'déverbal',\n",
              "  'règle',\n",
              "  'analogie'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'grammaire',\n",
              "  'dépendance',\n",
              "  'grammaire',\n",
              "  'interaction',\n",
              "  'polarité'],\n",
              " ['grammaticalité',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'contrainte',\n",
              "  'syntaxe',\n",
              "  'modèle',\n",
              "  'théorique'],\n",
              " ['guesser',\n",
              "  'lexique',\n",
              "  'morpho',\n",
              "  'syntaxiques',\n",
              "  'aide',\n",
              "  'linguiste',\n",
              "  'induction',\n",
              "  'règle',\n",
              "  'flexion'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'langage',\n",
              "  'évaluatif',\n",
              "  'catégorisation',\n",
              "  'évaluation'],\n",
              " ['annotation',\n",
              "  'expression',\n",
              "  'temporelles',\n",
              "  'ontologie',\n",
              "  'base',\n",
              "  'connaissance',\n",
              "  'tourisme'],\n",
              " ['annotation',\n",
              "  'sémantique',\n",
              "  'valeur',\n",
              "  'shapley',\n",
              "  'plate',\n",
              "  'forme',\n",
              "  'annotation'],\n",
              " ['emotion',\n",
              "  'valence',\n",
              "  'émotionnelle',\n",
              "  'norme',\n",
              "  'lexicale',\n",
              "  'émotionnelle',\n",
              "  'robot',\n",
              "  'compagnon',\n",
              "  'compréhension',\n",
              "  'parole'],\n",
              " ['morpho',\n",
              "  'phonologie',\n",
              "  'lexicale',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'famille',\n",
              "  'dérivationnelles',\n",
              "  'espace',\n",
              "  'sémantique'],\n",
              " ['question', 'réponse', 'enchaînée'],\n",
              " ['compréhension',\n",
              "  'mutuelle',\n",
              "  'processus',\n",
              "  'ancrage',\n",
              "  'référence',\n",
              "  'génération'],\n",
              " ['gestion',\n",
              "  'dialogue',\n",
              "  'homme',\n",
              "  'machine',\n",
              "  'dialogue',\n",
              "  'oral',\n",
              "  'arabe',\n",
              "  'modèle',\n",
              "  'tâche',\n",
              "  'modèle',\n",
              "  'dialogue'],\n",
              " ['correcteur', 'grammatical', 'analyse', 'syntaxique', 'forêt', 'partagée'],\n",
              " ['timeml', 'verbe', 'support', 'discours', 'sémantique'],\n",
              " ['dictionnaire',\n",
              "  'morphologique',\n",
              "  'français',\n",
              "  'cmlf',\n",
              "  'analyse',\n",
              "  'linguistique',\n",
              "  'texte'],\n",
              " ['réutilisation',\n",
              "  'texte',\n",
              "  'recouvrement',\n",
              "  'grams',\n",
              "  'hapax',\n",
              "  'similarité',\n",
              "  'discursives',\n",
              "  'corpus',\n",
              "  'journalistique',\n",
              "  'francophone'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'désambiguïsation',\n",
              "  'lexicale',\n",
              "  'réévaluation',\n",
              "  'liste',\n",
              "  'hypothèse'],\n",
              " ['typologie',\n",
              "  'analyse',\n",
              "  'erreur',\n",
              "  'textuelles',\n",
              "  'assistance',\n",
              "  'saisie',\n",
              "  'texte'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'incrémentale',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'classification',\n",
              "  'attribut',\n",
              "  'discriminant'],\n",
              " ['rectification',\n",
              "  'orthographiques',\n",
              "  'conversion',\n",
              "  'ancien',\n",
              "  'nouvelle',\n",
              "  'orthographe',\n",
              "  'objectif',\n",
              "  'didactique',\n",
              "  'machine',\n",
              "  'état',\n",
              "  'fini'],\n",
              " ['segmentation',\n",
              "  'multiple',\n",
              "  'langue',\n",
              "  'segmentée',\n",
              "  'modélisation',\n",
              "  'statistique',\n",
              "  'langage'],\n",
              " ['dialogue',\n",
              "  'oral',\n",
              "  'spontané',\n",
              "  'analyse',\n",
              "  'linguistique',\n",
              "  'corpus',\n",
              "  'compréhension',\n",
              "  'robuste',\n",
              "  'contrôle',\n",
              "  'aérien',\n",
              "  'phraséologie',\n",
              "  'disfluences',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langage',\n",
              "  'naturel'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'déductive',\n",
              "  'grammaire',\n",
              "  'concaténation',\n",
              "  'intervalle'],\n",
              " ['analyse',\n",
              "  'sémantique',\n",
              "  'tabulaire',\n",
              "  'contexte',\n",
              "  'dialogique',\n",
              "  'évaluation'],\n",
              " ['compression',\n",
              "  'phrase',\n",
              "  'résumé',\n",
              "  'automatique',\n",
              "  'résumé',\n",
              "  'extraction',\n",
              "  'enertex',\n",
              "  'mécanique',\n",
              "  'statistique'],\n",
              " ['catégorisation',\n",
              "  'texte',\n",
              "  'écriture',\n",
              "  'ligne',\n",
              "  'best',\n",
              "  'candidat',\n",
              "  'pondération'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'dialecte',\n",
              "  'langue',\n",
              "  'proche',\n",
              "  'langue',\n",
              "  'germanique'],\n",
              " ['modèle',\n",
              "  'plsi',\n",
              "  'probabilistic',\n",
              "  'latent',\n",
              "  'semantic',\n",
              "  'indexing',\n",
              "  'offre',\n",
              "  'approche',\n",
              "  'indexation',\n",
              "  'document',\n",
              "  'fondé',\n",
              "  'modèle',\n",
              "  'probabiliste',\n",
              "  'catégorie',\n",
              "  'sémantique',\n",
              "  'latentes',\n",
              "  'conduit',\n",
              "  'application',\n",
              "  'domaine',\n",
              "  'modèle',\n",
              "  'rend',\n",
              "  'impossible',\n",
              "  'traitement',\n",
              "  'document',\n",
              "  'inconnu',\n",
              "  'moment',\n",
              "  'apprentissage',\n",
              "  'problème',\n",
              "  'particulièrement',\n",
              "  'sensible',\n",
              "  'représentation',\n",
              "  'requête',\n",
              "  'cadre',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'méthode',\n",
              "  'dite',\n",
              "  'folding',\n",
              "  'permet',\n",
              "  'mesure',\n",
              "  'contourner',\n",
              "  'problème',\n",
              "  'présente',\n",
              "  'faiblesse',\n",
              "  'article',\n",
              "  'introduit',\n",
              "  'nouvelle',\n",
              "  'mesure',\n",
              "  'similarité',\n",
              "  'document',\n",
              "  'requête',\n",
              "  'plsi',\n",
              "  'fondé',\n",
              "  'lesmodèles',\n",
              "  'langue',\n",
              "  'problème',\n",
              "  'folding',\n",
              "  'pose',\n",
              "  'comparons',\n",
              "  'nouvelle',\n",
              "  'similarité',\n",
              "  'noyau',\n",
              "  'fisher',\n",
              "  'état',\n",
              "  'matière',\n",
              "  'présentons',\n",
              "  'évaluation',\n",
              "  'plsi',\n",
              "  'corpus',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'document',\n",
              "  'million',\n",
              "  'occurrence',\n",
              "  'terme',\n",
              "  'provenant',\n",
              "  'collection',\n",
              "  'trec',\n",
              "  'taille',\n",
              "  'considérable',\n",
              "  'cadre',\n",
              "  'plsi'],\n",
              " ['alignement', 'phrastique', 'multilinguisme', 'table', 'traduction'],\n",
              " ['démonstrateur',\n",
              "  'composant',\n",
              "  'assistant',\n",
              "  'linguistique',\n",
              "  'phrasebook',\n",
              "  'digital',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'mémoire',\n",
              "  'traduction',\n",
              "  'collecte',\n",
              "  'collaborative',\n",
              "  'corpus'],\n",
              " ['corpus', 'lexique', 'analyseur', 'japonais', 'chinois'],\n",
              " ['apache', 'uima', 'application', 'infrastructure', 'logicielle'],\n",
              " ['apache', 'uima', 'application', 'infrastructure', 'logicielle'],\n",
              " ['chunking',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'endogène',\n",
              "  'longueur',\n",
              "  'mot',\n",
              "  'effectif',\n",
              "  'mot'],\n",
              " ['morphologie',\n",
              "  'dérivationnelle',\n",
              "  'morphologie',\n",
              "  'lexématique',\n",
              "  'similarité',\n",
              "  'morphologique',\n",
              "  'analogie',\n",
              "  'formelle'],\n",
              " ['fonction',\n",
              "  'syntaxiques',\n",
              "  'conditional',\n",
              "  'random',\n",
              "  'fields',\n",
              "  'corpus',\n",
              "  'arborés'],\n",
              " ['mult',\n",
              "  'ilinguisme',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'extraction',\n",
              "  'lexique',\n",
              "  'bilingue'],\n",
              " ['étiquetage', 'entité', 'nommées', 'classification', 'taxonomie'],\n",
              " ['apprentissage',\n",
              "  'analogique',\n",
              "  'analogie',\n",
              "  'formelle',\n",
              "  'analyse',\n",
              "  'morphologique'],\n",
              " ['traduction',\n",
              "  'probabiliste',\n",
              "  'corpus',\n",
              "  'bilingue',\n",
              "  'alignement',\n",
              "  'document',\n",
              "  'table',\n",
              "  'traduction'],\n",
              " ['corpus',\n",
              "  'comparable',\n",
              "  'extraction',\n",
              "  'lexique',\n",
              "  'bilingue',\n",
              "  'point',\n",
              "  'ancrage'],\n",
              " ['alignement',\n",
              "  'niveau',\n",
              "  'mot',\n",
              "  'concordancier',\n",
              "  'bilingue',\n",
              "  'traduction',\n",
              "  'automatique'],\n",
              " ['jugement',\n",
              "  'évaluation',\n",
              "  'constituant',\n",
              "  'extra',\n",
              "  'prédicatifs',\n",
              "  'construction',\n",
              "  'lexique',\n",
              "  'subjectif',\n",
              "  'appraisal',\n",
              "  'implémentation',\n",
              "  'informatique',\n",
              "  'portrait',\n",
              "  'biographie',\n",
              "  'presse',\n",
              "  'spécialité',\n",
              "  'presse',\n",
              "  'information'],\n",
              " ['adjectif',\n",
              "  'relationnels',\n",
              "  'ressource',\n",
              "  'lexicales',\n",
              "  'morphologie',\n",
              "  'constructionnelle'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'fouille',\n",
              "  'texte',\n",
              "  'motif',\n",
              "  'séquentiels',\n",
              "  'interaction',\n",
              "  'gène'],\n",
              " ['temporalité', 'typage', 'caractérisation', 'expression', 'temporelles'],\n",
              " ['segmentation',\n",
              "  'thématique',\n",
              "  'évaluation',\n",
              "  'distance',\n",
              "  'hamming',\n",
              "  'généralisée',\n",
              "  'windowdiff'],\n",
              " ['repérage',\n",
              "  'automatique',\n",
              "  'obsolescence',\n",
              "  'indice',\n",
              "  'sémantique',\n",
              "  'discursifs',\n",
              "  'texte',\n",
              "  'encyclopédiques',\n",
              "  'classification',\n",
              "  'supervisée',\n",
              "  'aire',\n",
              "  'courbe'],\n",
              " ['résumé',\n",
              "  'automatique',\n",
              "  'analyse',\n",
              "  'texte',\n",
              "  'subjectif',\n",
              "  'évaluation',\n",
              "  'automatique'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'surface',\n",
              "  'automate',\n",
              "  'état',\n",
              "  'fini',\n",
              "  'déterminisme',\n",
              "  'désambiguïsation'],\n",
              " ['entité', 'nommées', 'fusion', 'annotation', 'uima'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'unité',\n",
              "  'lexicales',\n",
              "  'complexe',\n",
              "  'désambiguïsation',\n",
              "  'lexicale',\n",
              "  'world',\n",
              "  'wide',\n",
              "  'terminologie'],\n",
              " ['multimodalité',\n",
              "  'interaction',\n",
              "  'domaine',\n",
              "  'grammaire',\n",
              "  'corpus',\n",
              "  'multimodaux'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'corpus',\n",
              "  'bilingue',\n",
              "  'direction',\n",
              "  'traduction',\n",
              "  'langue',\n",
              "  'source',\n",
              "  'langue',\n",
              "  'cible'],\n",
              " ['attribution',\n",
              "  'auteur',\n",
              "  'modèle',\n",
              "  'langue',\n",
              "  'stylométrie',\n",
              "  'gramme',\n",
              "  'vecteur',\n",
              "  'trait'],\n",
              " ['densité',\n",
              "  'idée',\n",
              "  'analyse',\n",
              "  'prédicative',\n",
              "  'étiquetage',\n",
              "  'sémantique',\n",
              "  'psycholinguistique'],\n",
              " ['textométrie', 'comparaison', 'segmenteurs', 'chinois', 'nombre', 'syllabe'],\n",
              " ['relation', 'entité', 'nommée', 'grammaire'],\n",
              " ['repérage', 'événement', 'nominaux', 'annotation', 'temporelle'],\n",
              " ['analyse', 'opinion', 'extension', 'lexique', 'annotation', 'opinion'],\n",
              " ['théorie',\n",
              "  'structure',\n",
              "  'rhétorique',\n",
              "  'relation',\n",
              "  'rhétorique',\n",
              "  'marqueur',\n",
              "  'linguistique',\n",
              "  'résumé',\n",
              "  'automatique',\n",
              "  'texte',\n",
              "  'arabe'],\n",
              " ['corpus',\n",
              "  'comparables',\n",
              "  'monolingue',\n",
              "  'morphologie',\n",
              "  'constructionnelle',\n",
              "  'langue',\n",
              "  'spécialité'],\n",
              " ['réseau',\n",
              "  'lexical',\n",
              "  'arbre',\n",
              "  'usage',\n",
              "  'nommés',\n",
              "  'terme',\n",
              "  'pondération',\n",
              "  'sens',\n",
              "  'terme'],\n",
              " ['pseudo',\n",
              "  'phrase',\n",
              "  'phrase',\n",
              "  'averbale',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'sémantique'],\n",
              " ['langue',\n",
              "  'amazighe',\n",
              "  'pseudo',\n",
              "  'racinisation',\n",
              "  'morphologie',\n",
              "  'flexionnelle'],\n",
              " ['analyseur',\n",
              "  'syntaxique',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'pronom',\n",
              "  'clitique',\n",
              "  'proclise',\n",
              "  'enclise'],\n",
              " ['sémantique',\n",
              "  'lexicale',\n",
              "  'antonymie',\n",
              "  'analyse',\n",
              "  'distributionnelle',\n",
              "  'patron',\n",
              "  'lexico',\n",
              "  'syntaxiques'],\n",
              " ['étiquetage',\n",
              "  'grammatical',\n",
              "  'modèle',\n",
              "  'markov',\n",
              "  'caché',\n",
              "  'uima',\n",
              "  'brill',\n",
              "  'treetagger'],\n",
              " ['corpus', 'comparables', 'saillance', 'segmentation', 'texte', 'historique'],\n",
              " ['mot',\n",
              "  'inconnu',\n",
              "  'incomplétude',\n",
              "  'lexicale',\n",
              "  'acquisition',\n",
              "  'dynamique',\n",
              "  'ressource',\n",
              "  'lexicales'],\n",
              " ['sémantique',\n",
              "  'lexicale',\n",
              "  'terminologie',\n",
              "  'corpus',\n",
              "  'richesse',\n",
              "  'lexicale',\n",
              "  'lexicométrie'],\n",
              " ['emotion',\n",
              "  'valence',\n",
              "  'émotionnelle',\n",
              "  'norme',\n",
              "  'lexicale',\n",
              "  'émotionnelle',\n",
              "  'robot',\n",
              "  'compagnon',\n",
              "  'compréhension',\n",
              "  'parole'],\n",
              " ['chaîne',\n",
              "  'référence',\n",
              "  'relation',\n",
              "  'référence',\n",
              "  'saillance',\n",
              "  'genre',\n",
              "  'textuel'],\n",
              " ['entité', 'nommée', 'événement', 'rapport', 'cause', 'conséquence'],\n",
              " ['analyse', 'sentiment', 'anew', 'twitter'],\n",
              " ['analyse', 'opinion', 'théorie', 'appraisal'],\n",
              " ['fouille',\n",
              "  'donnée',\n",
              "  'motif',\n",
              "  'séquentiels',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'apprentissage',\n",
              "  'patron',\n",
              "  'linguistique'],\n",
              " ['extraction',\n",
              "  'connaissance',\n",
              "  'extraction',\n",
              "  'patron',\n",
              "  'relation',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'arbre',\n",
              "  'syntaxique',\n",
              "  'dépendanciel'],\n",
              " ['reconnaissance', 'entité', 'nommées', 'séquence', 'hiérarchiques', 'motif'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'traduction',\n",
              "  'requête',\n",
              "  'wikipédia'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'traduction',\n",
              "  'requête',\n",
              "  'wikipédia'],\n",
              " ['information',\n",
              "  'thématique',\n",
              "  'construction',\n",
              "  'corpus',\n",
              "  'extraction',\n",
              "  'terme',\n",
              "  'découverte',\n",
              "  'contexte',\n",
              "  'définitionnels'],\n",
              " ['passerelle',\n",
              "  'traduction',\n",
              "  'interactive',\n",
              "  'imag',\n",
              "  'post',\n",
              "  'édition',\n",
              "  'traduction',\n",
              "  'collaborative'],\n",
              " ['étiquetage',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'système',\n",
              "  'veille',\n",
              "  'médiatique'],\n",
              " ['génération', 'texte', 'synthèse', 'vocale', 'expressivité'],\n",
              " ['terminologie',\n",
              "  'bilingue',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'wikipédia',\n",
              "  'ontologie',\n",
              "  'multi',\n",
              "  'lingue'],\n",
              " ['langue',\n",
              "  'signe',\n",
              "  'corpus',\n",
              "  'vidéo',\n",
              "  'comparables',\n",
              "  'reconnaissance',\n",
              "  'automatique',\n",
              "  'génération',\n",
              "  'automatique'],\n",
              " ['analyse', 'syntaxique', 'grammaire', 'générative', 'service'],\n",
              " ['dialectologie',\n",
              "  'atlas',\n",
              "  'linguistique',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'identification',\n",
              "  'dialecte'],\n",
              " ['normalisation', 'application', 'plugin', 'serveur'],\n",
              " ['analyse', 'syntaxique', 'grammaire', 'interaction', 'polarité'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'alignement',\n",
              "  'mot',\n",
              "  'traduction',\n",
              "  'rares',\n",
              "  'contrôle',\n",
              "  'pertinence'],\n",
              " ['étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'modèle',\n",
              "  'maximisation',\n",
              "  'entropie',\n",
              "  'français',\n",
              "  'lexique'],\n",
              " ['extraction',\n",
              "  'synonyme',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'méthode',\n",
              "  'distributionnelles'],\n",
              " ['antidote', 'occurrence', 'collocation', 'expression', 'multi', 'mot'],\n",
              " ['fouille',\n",
              "  'texte',\n",
              "  'random',\n",
              "  'indexing',\n",
              "  'cognition',\n",
              "  'marche',\n",
              "  'aléatoire'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'dépendance',\n",
              "  'grammaire',\n",
              "  'interaction',\n",
              "  'polarité'],\n",
              " ['syntaxe',\n",
              "  'probabiliste',\n",
              "  'linguistique',\n",
              "  'corpus',\n",
              "  'adjectif',\n",
              "  'épithète',\n",
              "  'régression',\n",
              "  'logistique'],\n",
              " ['complexité',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'automatique',\n",
              "  'parser',\n",
              "  'humain'],\n",
              " ['dépendance', 'analyse', 'syntaxique', 'forêt', 'partagée'],\n",
              " ['normalisation',\n",
              "  'machine',\n",
              "  'état',\n",
              "  'fini',\n",
              "  'approche',\n",
              "  'hybride',\n",
              "  'orienté',\n",
              "  'traduction',\n",
              "  'orienté',\n",
              "  'correction',\n",
              "  'apprentissage',\n",
              "  'corpus'],\n",
              " ['ressource', 'correction', 'orthographique', 'wikipédia'],\n",
              " ['annotation',\n",
              "  'corpus',\n",
              "  'organisation',\n",
              "  'discours',\n",
              "  'structure',\n",
              "  'énumérative',\n",
              "  'signalisation'],\n",
              " ['structure',\n",
              "  'actancielle',\n",
              "  'actant',\n",
              "  'circonstant',\n",
              "  'features',\n",
              "  'classification'],\n",
              " ['entité',\n",
              "  'nommée',\n",
              "  'ontologie',\n",
              "  'relation',\n",
              "  'verbales',\n",
              "  'patron',\n",
              "  'linguistique'],\n",
              " ['classification',\n",
              "  'genre',\n",
              "  'vidéo',\n",
              "  'traitement',\n",
              "  'audio',\n",
              "  'vidéo',\n",
              "  'extraction',\n",
              "  'paramètre',\n",
              "  'linguistique'],\n",
              " ['segmentation',\n",
              "  'thématique',\n",
              "  'organisation',\n",
              "  'textuelle',\n",
              "  'cohésion',\n",
              "  'lexicale',\n",
              "  'voisin',\n",
              "  'distributionnels'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'extraction',\n",
              "  'événement',\n",
              "  'segmentation',\n",
              "  'texte',\n",
              "  'indice',\n",
              "  'temporel',\n",
              "  'apprentissage',\n",
              "  'statistique'],\n",
              " ['résumé', 'automatique', 'résumé', 'extraction', 'résumé', 'manuel'],\n",
              " ['apprentissage',\n",
              "  'supervisé',\n",
              "  'système',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'paire',\n",
              "  'phrase',\n",
              "  'parallèle'],\n",
              " ['traitement',\n",
              "  'interactif',\n",
              "  'langue',\n",
              "  'prise',\n",
              "  'compte',\n",
              "  'usager',\n",
              "  'outil',\n",
              "  'traitement',\n",
              "  'langue',\n",
              "  'apprentissage',\n",
              "  'langue',\n",
              "  'dictionnaire',\n",
              "  'livre',\n",
              "  'phrase',\n",
              "  'concordancier',\n",
              "  'traduction'],\n",
              " ['recherche',\n",
              "  'contextuelle',\n",
              "  'équivalent',\n",
              "  'terminologiques',\n",
              "  'banque',\n",
              "  'terminologie',\n",
              "  'désambiguïsation',\n",
              "  'domaine'],\n",
              " ['dépendance',\n",
              "  'réécriture',\n",
              "  'graphe',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'dmrs'],\n",
              " ['annotation', 'manuelle', 'évaluation', 'accord', 'inter', 'annotateur'],\n",
              " ['classe',\n",
              "  'vocabulaire',\n",
              "  'indexation',\n",
              "  'automatique',\n",
              "  'extraction',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'approche',\n",
              "  'basée',\n",
              "  'corpus',\n",
              "  'vocabulaire',\n",
              "  'savant',\n",
              "  'base',\n",
              "  'ressource',\n",
              "  'lexicales',\n",
              "  'français'],\n",
              " ['alignement',\n",
              "  'terminologie',\n",
              "  'morphologie',\n",
              "  'analogie',\n",
              "  'traduction',\n",
              "  'terme',\n",
              "  'kanji'],\n",
              " ['lexique',\n",
              "  'morphologique',\n",
              "  'persan',\n",
              "  'développement',\n",
              "  'lexique',\n",
              "  'traitement',\n",
              "  'surface'],\n",
              " ['tlfi', 'indexation', 'recherche', 'image', 'thésaurus'],\n",
              " ['opinion',\n",
              "  'évaluation',\n",
              "  'repérage',\n",
              "  'phrase',\n",
              "  'évaluatives',\n",
              "  'presse',\n",
              "  'économique',\n",
              "  'financière',\n",
              "  'style',\n",
              "  'journalistique',\n",
              "  'indice',\n",
              "  'marque',\n",
              "  'stéréotype',\n",
              "  'écriture'],\n",
              " ['complexité', 'lisibilité', 'allemand', 'analyse', 'surface'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'objet',\n",
              "  'pédagogiques',\n",
              "  'carte',\n",
              "  'sémantique',\n",
              "  'exploration',\n",
              "  'contextuelle',\n",
              "  'algorithme',\n",
              "  'rocchio'],\n",
              " ['relation',\n",
              "  'discours',\n",
              "  'fermeture',\n",
              "  'discursive',\n",
              "  'évaluation',\n",
              "  'déduction'],\n",
              " ['résumé',\n",
              "  'texte',\n",
              "  'automatique',\n",
              "  'résumé',\n",
              "  'extractif',\n",
              "  'statistique',\n",
              "  'occurrence',\n",
              "  'collocation',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'wikipedia'],\n",
              " ['lisibilité', 'unité', 'polylexicales', 'nominales', 'modèle', 'gramme'],\n",
              " ['détection',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'adaptation',\n",
              "  'nouveau',\n",
              "  'domaine',\n",
              "  'coopération',\n",
              "  'approche',\n",
              "  'probabiliste',\n",
              "  'symbolique'],\n",
              " ['ressource',\n",
              "  'lexicales',\n",
              "  'famille',\n",
              "  'morphologiques',\n",
              "  'clusters',\n",
              "  'sémantique',\n",
              "  'mesure',\n",
              "  'lesk'],\n",
              " ['extraction', 'information', 'événement', 'nominaux', 'lexique'],\n",
              " ['recherche',\n",
              "  'passage',\n",
              "  'enrichissement',\n",
              "  'requête',\n",
              "  'contexte',\n",
              "  'wikipedia',\n",
              "  'inex',\n",
              "  'entropie'],\n",
              " ['adjectif',\n",
              "  'dénominaux',\n",
              "  'dérivation',\n",
              "  'morphologique',\n",
              "  'lexique',\n",
              "  'dérivationnel'],\n",
              " ['ressource',\n",
              "  'lexicale',\n",
              "  'validation',\n",
              "  'étiqueteur',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'persan',\n",
              "  'catégorie',\n",
              "  'perlex',\n",
              "  'melt'],\n",
              " ['cognat',\n",
              "  'identification',\n",
              "  'cognat',\n",
              "  'corpus',\n",
              "  'parallèle',\n",
              "  'alignés',\n",
              "  'niveau',\n",
              "  'propositionnel'],\n",
              " ['alao',\n",
              "  'elao',\n",
              "  'exercice',\n",
              "  'dictée',\n",
              "  'alignement',\n",
              "  'diagnostic',\n",
              "  'machine',\n",
              "  'état',\n",
              "  'fini'],\n",
              " ['interaction',\n",
              "  'verbale',\n",
              "  'schizophrénie',\n",
              "  'dialogue',\n",
              "  'pathologique',\n",
              "  'incohérence',\n",
              "  'pragmatique'],\n",
              " ['corpus',\n",
              "  'alpin',\n",
              "  'français',\n",
              "  'allemand',\n",
              "  'structure',\n",
              "  'arborées',\n",
              "  'parallèle',\n",
              "  'annotation',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'français'],\n",
              " ['thésaurus',\n",
              "  'distributionnel',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'méthode',\n",
              "  'supervisées',\n",
              "  'lexique'],\n",
              " ['extraction',\n",
              "  'relation',\n",
              "  'classification',\n",
              "  'apprentissage',\n",
              "  'paresseux',\n",
              "  'modèle',\n",
              "  'langue',\n",
              "  'analyse',\n",
              "  'linguistique',\n",
              "  'surface'],\n",
              " ['timeml', 'discours', 'sémantique', 'phénomène', 'itératifs'],\n",
              " ['modifieurs', 'valence', 'fouille', 'opinion', 'lexique', 'valence'],\n",
              " ['corpus', 'annotation', 'exploration', 'glozzql'],\n",
              " ['rôle',\n",
              "  'sémantique',\n",
              "  'trait',\n",
              "  'syntaxiques',\n",
              "  'classification',\n",
              "  'partitionnement',\n",
              "  'semi',\n",
              "  'supervisé'],\n",
              " ['extraction',\n",
              "  'voisin',\n",
              "  'sémantique',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'méthode',\n",
              "  'distributionnelles'],\n",
              " ['corpus', 'annotation', 'multimodalité', 'classification', 'supervisée'],\n",
              " ['typage',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'comparaison',\n",
              "  'distribution',\n",
              "  'mot',\n",
              "  'divergence',\n",
              "  'kullback',\n",
              "  'leibler'],\n",
              " ['traduction', 'automatique', 'transsearch', 'discours'],\n",
              " ['identification',\n",
              "  'paraphrase',\n",
              "  'extraction',\n",
              "  'patron',\n",
              "  'type',\n",
              "  'discours',\n",
              "  'domaine',\n",
              "  'médical',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'monolingue'],\n",
              " ['base',\n",
              "  'donnée',\n",
              "  'lexicales',\n",
              "  'catégorisation',\n",
              "  'verbale',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'base',\n",
              "  'linguistique',\n",
              "  'japonais'],\n",
              " ['extraction',\n",
              "  'connaissance',\n",
              "  'relation',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'dualité',\n",
              "  'relationnelle'],\n",
              " ['détection',\n",
              "  'dislocation',\n",
              "  'gauche',\n",
              "  'maximum',\n",
              "  'entropy',\n",
              "  'français',\n",
              "  'parlé'],\n",
              " ['morphologie',\n",
              "  'constructionnelle',\n",
              "  'analyse',\n",
              "  'automatique',\n",
              "  'règle',\n",
              "  'analogie',\n",
              "  'famille',\n",
              "  'morphologiques',\n",
              "  'comparaison',\n",
              "  'synergie'],\n",
              " ['bidirectionnel', 'classification', 'séquence', 'apprentissage', 'guidé'],\n",
              " ['réseau',\n",
              "  'phrastique',\n",
              "  'appariement',\n",
              "  'phrase',\n",
              "  'analyse',\n",
              "  'textuelle',\n",
              "  'navigation',\n",
              "  'textuelle'],\n",
              " ['environnement',\n",
              "  'étude',\n",
              "  'corpus',\n",
              "  'corpus',\n",
              "  'étiquetés',\n",
              "  'arborés',\n",
              "  'création',\n",
              "  'grammaire',\n",
              "  'assisté',\n",
              "  'visualisation',\n",
              "  'information',\n",
              "  'linguistique'],\n",
              " ['terminologie',\n",
              "  'préterminologie',\n",
              "  'approche',\n",
              "  'collaboratives',\n",
              "  'réseau',\n",
              "  'lexicaux',\n",
              "  'jeu',\n",
              "  'sérieux'],\n",
              " ['analyseur',\n",
              "  'syntaxique',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'pronom',\n",
              "  'clitique',\n",
              "  'séquence',\n",
              "  'clitique'],\n",
              " ['pronom', 'ambiguïté', 'pronominale', 'étiquetage', 'morpho', 'syntaxique'],\n",
              " ['pronom',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'anaphore',\n",
              "  'pronominales'],\n",
              " ['sémantique', 'lexicale', 'inférence', 'glissement', 'sens'],\n",
              " ['réputation',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'classification',\n",
              "  'clustering',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'apprentissage'],\n",
              " ['réputation',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'classification',\n",
              "  'clustering',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'apprentissage'],\n",
              " ['réputation',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'classification',\n",
              "  'clustering',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'apprentissage'],\n",
              " ['réputation',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'classification',\n",
              "  'clustering',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'apprentissage'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['analyse', 'sentiment', 'linguistique', 'corpus', 'dépêche', 'financière'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langage',\n",
              "  'naturel',\n",
              "  'fouille',\n",
              "  'titrage',\n",
              "  'automatique'],\n",
              " ['résumé', 'cross', 'lingue', 'qualité', 'traduction', 'graphe'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'indexation',\n",
              "  'contrôlée',\n",
              "  'informatique',\n",
              "  'médicale',\n",
              "  'concept',\n",
              "  'médicaux',\n",
              "  'prescription'],\n",
              " ['système',\n",
              "  'dialogue',\n",
              "  'compréhension',\n",
              "  'parole',\n",
              "  'portabilité',\n",
              "  'travers',\n",
              "  'langue',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'statistique'],\n",
              " ['indexation',\n",
              "  'information',\n",
              "  'calendaires',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'annotation',\n",
              "  'extraction',\n",
              "  'expression',\n",
              "  'calendaires'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'algorithme',\n",
              "  'colonie',\n",
              "  'fourmi',\n",
              "  'mesure',\n",
              "  'sémantique'],\n",
              " ['amazon', 'mechanical', 'turk', 'ressource', 'linguistique'],\n",
              " ['analyse',\n",
              "  'sentiment',\n",
              "  'lexique',\n",
              "  'valence',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'analyse',\n",
              "  'sémantique',\n",
              "  'latente'],\n",
              " ['sémantique',\n",
              "  'lexicale',\n",
              "  'similarité',\n",
              "  'distributionnelle',\n",
              "  'similarité',\n",
              "  'traductionnelle'],\n",
              " ['alignement',\n",
              "  'annotation',\n",
              "  'mesure',\n",
              "  'accord',\n",
              "  'inter',\n",
              "  'annotateur',\n",
              "  'linguistique',\n",
              "  'corpus'],\n",
              " ['annotation', 'temporelle', 'corpus', 'timeml'],\n",
              " ['corpus', 'comparables', 'lexique', 'bilingue', 'métarecherche'],\n",
              " ['réseau', 'lexical', 'jeuxdemots', 'évaluation', 'outil', 'bout', 'langue'],\n",
              " ['fouille', 'opinion', 'identification', 'cible', 'méthode', 'ranksvm'],\n",
              " ['étiquetagemorpho',\n",
              "  'syntaxique',\n",
              "  'modèle',\n",
              "  'ressource',\n",
              "  'lexicales',\n",
              "  'segmentation',\n",
              "  'unité',\n",
              "  'polylexicales'],\n",
              " ['segmentation',\n",
              "  'supervisée',\n",
              "  'entropie',\n",
              "  'induction',\n",
              "  'lexique',\n",
              "  'unité',\n",
              "  'lexicale',\n",
              "  'chinois',\n",
              "  'mandarin'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'corpus',\n",
              "  'arboré',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'ordonnancement',\n",
              "  'discriminant'],\n",
              " ['extraction',\n",
              "  'relation',\n",
              "  'domaine',\n",
              "  'médical',\n",
              "  'apprentissage',\n",
              "  'multi',\n",
              "  'classe',\n",
              "  'tree',\n",
              "  'kernel'],\n",
              " ['dépendance', 'french', 'treebank', 'réécriture', 'graphe', 'dicovalence'],\n",
              " ['portée',\n",
              "  'quantifieurs',\n",
              "  'cumulatif',\n",
              "  'collectif',\n",
              "  'distributif',\n",
              "  'référent',\n",
              "  'discours',\n",
              "  'ancrage'],\n",
              " ['modalité', 'épistémique', 'niveau', 'certitude', 'domaine', 'médical'],\n",
              " ['wikipédia', 'révision', 'identification', 'paraphrase'],\n",
              " ['deixis', 'parole', 'geste', 'grammaire', 'multimodales'],\n",
              " ['alignement', 'phrastique', 'traduction', 'automatique', 'fragment'],\n",
              " ['paraphrase',\n",
              "  'phrastique',\n",
              "  'corpus',\n",
              "  'parallèle',\n",
              "  'monolingue',\n",
              "  'hybridation'],\n",
              " ['apprentissage', 'supervisé', 'segmentation', 'chinois', 'mandarin'],\n",
              " ['texte', 'lexique', 'occurrence', 'généralisée', 'auto', 'organisation'],\n",
              " ['traduction',\n",
              "  'statistique',\n",
              "  'normalisation',\n",
              "  'texto',\n",
              "  'algorithme',\n",
              "  'recherche',\n",
              "  'vorace',\n",
              "  'modèle',\n",
              "  'langue'],\n",
              " ['morphologie',\n",
              "  'constructionnelle',\n",
              "  'néologie',\n",
              "  'génération',\n",
              "  'morphologique',\n",
              "  'incomplétude',\n",
              "  'lexicale'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'transition',\n",
              "  'structure',\n",
              "  'dépendance',\n",
              "  'projective',\n",
              "  'grammaire',\n",
              "  'catégorielle',\n",
              "  'dépendance'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'modifieurs',\n",
              "  'valence',\n",
              "  'affectif',\n",
              "  'modifieurs',\n",
              "  'polarité'],\n",
              " ['diacritisation',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'analyse',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['résumé',\n",
              "  'automatique',\n",
              "  'compression',\n",
              "  'texte',\n",
              "  'lisibilité',\n",
              "  'essentialisation'],\n",
              " ['émotion',\n",
              "  'forum',\n",
              "  'santé',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'désambiguïsation',\n",
              "  'lexicale'],\n",
              " ['extraction',\n",
              "  'relation',\n",
              "  'peuplement',\n",
              "  'ontologie',\n",
              "  'représentation',\n",
              "  'connaissance'],\n",
              " ['reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'approche',\n",
              "  'symbolique',\n",
              "  'portabilité',\n",
              "  'langue'],\n",
              " ['état', 'fouille', 'opinion', 'multi', 'domaine', 'cross', 'domaine'],\n",
              " ['extraction',\n",
              "  'grammaire',\n",
              "  'grammaire',\n",
              "  'lambek',\n",
              "  'pcfg',\n",
              "  'transducteur',\n",
              "  'arbre',\n",
              "  'algorithme'],\n",
              " ['annotation',\n",
              "  'collaborative',\n",
              "  'corpus',\n",
              "  'annotation',\n",
              "  'concurrentes',\n",
              "  'dépendance'],\n",
              " ['préférence', 'dialogue', 'apprentissage', 'automatique'],\n",
              " ['wikipedia', 'conflit', 'syntaxe', 'sémantique', 'interaction'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'concept',\n",
              "  'métier',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'donnée',\n",
              "  'conversationnelles',\n",
              "  'annotation'],\n",
              " ['linguistique',\n",
              "  'corpus',\n",
              "  'textométrie',\n",
              "  'analyse',\n",
              "  'sentiment',\n",
              "  'classification',\n",
              "  'automatique',\n",
              "  'supervisée'],\n",
              " ['langue',\n",
              "  'signe',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'modèle',\n",
              "  'grammatical',\n",
              "  'synchronisation'],\n",
              " ['annotation', 'manuelle', 'accord', 'inter', 'annotateur'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'adaptation',\n",
              "  'nouveau',\n",
              "  'domaine',\n",
              "  'auto',\n",
              "  'apprentissage'],\n",
              " ['collocation',\n",
              "  'cooccurrences',\n",
              "  'profl',\n",
              "  'combinatoire',\n",
              "  'expression',\n",
              "  'polylexicales',\n",
              "  'lexique',\n",
              "  'émotion'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'événement',\n",
              "  'approche',\n",
              "  'symbolique',\n",
              "  'apprentissage',\n",
              "  'patron',\n",
              "  'linguistique'],\n",
              " ['chunking', 'apprentissage', 'automatique', 'french', 'tree', 'bank'],\n",
              " ['reconnaissance',\n",
              "  'parole',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'corpus',\n",
              "  'comparables',\n",
              "  'multimodaux',\n",
              "  'extraction',\n",
              "  'phrase',\n",
              "  'parallèle'],\n",
              " ['pronom',\n",
              "  'démonstratif',\n",
              "  'résolution',\n",
              "  'anaphore',\n",
              "  'traitement',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['analyse', 'temporelle', 'évaluation'],\n",
              " ['ressource',\n",
              "  'lexicales',\n",
              "  'morphologie',\n",
              "  'dérivationnelle',\n",
              "  'analyse',\n",
              "  'sentiment'],\n",
              " ['structure',\n",
              "  'discours',\n",
              "  'segment',\n",
              "  'thématique',\n",
              "  'transition',\n",
              "  'thématique',\n",
              "  'annotation'],\n",
              " ['recherche', 'information', 'dysorthographie', 'correction', 'erreur'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'post',\n",
              "  'édition',\n",
              "  'adaptation',\n",
              "  'domaine',\n",
              "  'spécialité'],\n",
              " ['résolution',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'corpus',\n",
              "  'annoté',\n",
              "  'corpus',\n",
              "  'arboré',\n",
              "  'pari'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'fonction',\n",
              "  'croyance',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'estimation',\n",
              "  'paramètre'],\n",
              " ['centre',\n",
              "  'appel',\n",
              "  'conversation',\n",
              "  'tour',\n",
              "  'parole',\n",
              "  'reconnaissance',\n",
              "  'parole'],\n",
              " ['traitement', 'multi', 'vue', 'navigation', 'enrichie'],\n",
              " ['synthèse', 'texte', 'grammaire', 'attribuée', 'syntaxe'],\n",
              " ['étiquetage',\n",
              "  'chunking',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'french',\n",
              "  'tree',\n",
              "  'bank'],\n",
              " ['segmentation', 'phonétisation', 'alignement', 'syllabation'],\n",
              " ['retour',\n",
              "  'visuel',\n",
              "  'aide',\n",
              "  'prononciation',\n",
              "  'temps',\n",
              "  'réel',\n",
              "  'tête',\n",
              "  'parlante'],\n",
              " ['extraction',\n",
              "  'relation',\n",
              "  'simplification',\n",
              "  'phrase',\n",
              "  'apprentissage',\n",
              "  'automatique'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'projection',\n",
              "  'annotation',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'médicales',\n",
              "  'apprentissage'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'segmentation',\n",
              "  'texte',\n",
              "  'remplissage',\n",
              "  'formulaire'],\n",
              " ['compositionalité',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'interface',\n",
              "  'sémantique',\n",
              "  'pragmatique',\n",
              "  'grammaire',\n",
              "  'catégorielle',\n",
              "  'théorie',\n",
              "  'type',\n",
              "  'récit',\n",
              "  'voyage'],\n",
              " ['mot',\n",
              "  'composé',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'champ',\n",
              "  'markoviens',\n",
              "  'aléatoires',\n",
              "  'réordonnanceur'],\n",
              " ['déverbal',\n",
              "  'cadre',\n",
              "  'catégorisation',\n",
              "  'groupe',\n",
              "  'prépositionnel',\n",
              "  'analyse',\n",
              "  'dépendance'],\n",
              " ['calcul', 'similarité', 'modèle', 'vectoriel', 'okapi', 'vectorisation'],\n",
              " ['etiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'français',\n",
              "  'parlé',\n",
              "  'ressource',\n",
              "  'langagières'],\n",
              " ['corpus',\n",
              "  'parallèle',\n",
              "  'alignement',\n",
              "  'phrastique',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'statistique'],\n",
              " ['ressource',\n",
              "  'lexique',\n",
              "  'verbe',\n",
              "  'raffinement',\n",
              "  'étiquetage',\n",
              "  'rôle',\n",
              "  'sémantique'],\n",
              " ['analyse',\n",
              "  'distributionnelle',\n",
              "  'sémantique',\n",
              "  'lexicale',\n",
              "  'méronymie',\n",
              "  'évaluation'],\n",
              " ['cohésion', 'thématique', 'graphe', 'cooccurrences', 'marche', 'aléatoire'],\n",
              " ['paraphrase', 'wikipédia', 'aide', 'rédaction'],\n",
              " ['simplification', 'automatique', 'lisibilité', 'analyse', 'syntaxique'],\n",
              " ['fouille',\n",
              "  'graphe',\n",
              "  'réseau',\n",
              "  'phrastiques',\n",
              "  'analyse',\n",
              "  'textuelle',\n",
              "  'navigation',\n",
              "  'textuelle'],\n",
              " ['réécriture',\n",
              "  'graphe',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'dépendance',\n",
              "  'dmrs'],\n",
              " ['treebank', 'hybride', 'french', 'treebank', 'grammaire', 'propriété'],\n",
              " ['expression',\n",
              "  'polylexicale',\n",
              "  'alignement',\n",
              "  'bilingue',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'statistique'],\n",
              " ['corpus',\n",
              "  'multilingues',\n",
              "  'comparabilité',\n",
              "  'similarité',\n",
              "  'textuelle',\n",
              "  'translingue',\n",
              "  'classification'],\n",
              " ['taln',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'corpus',\n",
              "  'apprentissage',\n",
              "  'étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'segmentation',\n",
              "  'arabe',\n",
              "  'arbre',\n",
              "  'décision',\n",
              "  'lexique',\n",
              "  'jeu',\n",
              "  'étiquette',\n",
              "  'treetagger',\n",
              "  'asvm'],\n",
              " ['extraction',\n",
              "  'terme',\n",
              "  'clé',\n",
              "  'méthode',\n",
              "  'supervisées',\n",
              "  'méthode',\n",
              "  'supervisées',\n",
              "  'état'],\n",
              " ['corpus', 'écrit', 'scientifique', 'lexique', 'phraséologie'],\n",
              " ['chiasme', 'rhétorique', 'antimétabole', 'figure', 'style'],\n",
              " ['réécriture',\n",
              "  'graphe',\n",
              "  'évaluation',\n",
              "  'shéma',\n",
              "  'annotation',\n",
              "  'parsing',\n",
              "  'analyse',\n",
              "  'syntaxe',\n",
              "  'profonde'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'induction',\n",
              "  'sens',\n",
              "  'langue',\n",
              "  'dotées',\n",
              "  'ressource',\n",
              "  'langagières'],\n",
              " ['dialecte', 'tunisien', 'lexique', 'tunisian', 'dialect', 'translator'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'détection',\n",
              "  'automatique',\n",
              "  'session',\n",
              "  'recherche',\n",
              "  'analyse',\n",
              "  'journal',\n",
              "  'requête'],\n",
              " ['reconnaissance',\n",
              "  'nom',\n",
              "  'propre',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'chinois',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'analyse',\n",
              "  'syntaxique'],\n",
              " ['éthique', 'data', 'ressource', 'langagières'],\n",
              " ['taln', 'archive', 'archive', 'numérique', 'article', 'scientifique'],\n",
              " ['graphe',\n",
              "  'comparabilité',\n",
              "  'similarité',\n",
              "  'induites',\n",
              "  'document',\n",
              "  'comparables',\n",
              "  'clustering'],\n",
              " ['décodage', 'guidé', 'traduction', 'automatique', 'combinaison', 'système'],\n",
              " ['préédition', 'langage', 'contrôlé', 'traduction', 'statistique', 'forum'],\n",
              " ['classification',\n",
              "  'automatique',\n",
              "  'gramme',\n",
              "  'espagnol',\n",
              "  'variété',\n",
              "  'nationale'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'opinion',\n",
              "  'minoritaires',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'apprentissage',\n",
              "  'gramme',\n",
              "  'pondération'],\n",
              " ['accès', 'lexical', 'anomie', 'bout', 'langue', 'réseau', 'lexicaux'],\n",
              " ['coréférence', 'perceptron', 'multi', 'couche'],\n",
              " ['annotation',\n",
              "  'guide',\n",
              "  'annotation',\n",
              "  'annotation',\n",
              "  'agile',\n",
              "  'réécriture',\n",
              "  'graphe'],\n",
              " ['toponyme',\n",
              "  'information',\n",
              "  'spatiale',\n",
              "  'écriture',\n",
              "  'toponyme',\n",
              "  'bdnyme',\n",
              "  'ressource',\n",
              "  'lexicale'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'événement',\n",
              "  'médicaux',\n",
              "  'relation',\n",
              "  'temporelles',\n",
              "  'médecine'],\n",
              " ['catégorisation',\n",
              "  'apprentissage',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'wikipédia',\n",
              "  'graphe'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'corpus',\n",
              "  'arboré',\n",
              "  'dependances',\n",
              "  'depftb',\n",
              "  'conll',\n",
              "  'passage'],\n",
              " ['résolution',\n",
              "  'anaphore',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'base',\n",
              "  'règle',\n",
              "  'sujet',\n",
              "  'nul'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'marqueur',\n",
              "  'polarité',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées'],\n",
              " ['traduction', 'automatique', 'analyse', 'erreur', 'post', 'édiition'],\n",
              " ['segmentation',\n",
              "  'thématique',\n",
              "  'pondération',\n",
              "  'cohésion',\n",
              "  'lexicale',\n",
              "  'texttiling'],\n",
              " ['analyse',\n",
              "  'morphologique',\n",
              "  'lemmatisation',\n",
              "  'allemand',\n",
              "  'verbe',\n",
              "  'particule',\n",
              "  'séparable'],\n",
              " ['analyse',\n",
              "  'résolution',\n",
              "  'anaphore',\n",
              "  'pronom',\n",
              "  'personnel',\n",
              "  'collocation',\n",
              "  'corpus'],\n",
              " ['lexique',\n",
              "  'multi',\n",
              "  'lingue',\n",
              "  'hiérarchie',\n",
              "  'sémantique',\n",
              "  'universelle',\n",
              "  'traduction',\n",
              "  'automatique'],\n",
              " ['analyse', 'opinion', 'reputation', 'extraction', 'information'],\n",
              " ['chronologie', 'événementielle', 'évaluation', 'validation'],\n",
              " ['cascade',\n",
              "  'transducteur',\n",
              "  'graphe',\n",
              "  'unitex',\n",
              "  'texte',\n",
              "  'balise',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées'],\n",
              " ['post',\n",
              "  'édition',\n",
              "  'évaluation',\n",
              "  'système',\n",
              "  'production',\n",
              "  'corpus',\n",
              "  'parallèle'],\n",
              " ['lexical',\n",
              "  'linked',\n",
              "  'data',\n",
              "  'lexique',\n",
              "  'mult',\n",
              "  'ilingue',\n",
              "  'pivot',\n",
              "  'axies',\n",
              "  'sparql',\n",
              "  'spin'],\n",
              " ['aide', 'rédaction', 'langue', 'seconde', 'scienquest', 'scientext'],\n",
              " ['fouille', 'opinion', 'polarité', 'twitter'],\n",
              " ['corpus',\n",
              "  'comparable',\n",
              "  'extraction',\n",
              "  'terminologique',\n",
              "  'alignement',\n",
              "  'uima'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'reformulation',\n",
              "  'requête',\n",
              "  'difficulté',\n",
              "  'requête',\n",
              "  'résumé',\n",
              "  'automatique'],\n",
              " ['langue',\n",
              "  'amazighe',\n",
              "  'taln',\n",
              "  'nooj',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'morphologie',\n",
              "  'flexionnelle',\n",
              "  'morphologie',\n",
              "  'dérivationnelle'],\n",
              " ['apprentissage',\n",
              "  'automatique',\n",
              "  'chunking',\n",
              "  'inférence',\n",
              "  'grammaticale',\n",
              "  'frenchtreebank'],\n",
              " ['résumé', 'multi', 'document', 'résumé', 'orienté', 'requête', 'pomdp'],\n",
              " ['sémantique', 'lexicale', 'similarité', 'sémantique', 'thésaurus'],\n",
              " ['relation',\n",
              "  'sémantique',\n",
              "  'terme',\n",
              "  'domaine',\n",
              "  'spécialité',\n",
              "  'médecine',\n",
              "  'contexte',\n",
              "  'crosslangue'],\n",
              " ['analyse',\n",
              "  'discours',\n",
              "  'relation',\n",
              "  'implicites',\n",
              "  'apprentissage',\n",
              "  'automatique'],\n",
              " ['anglais', 'patron', 'lexico', 'syntaxiques', 'scienquest', 'scientext'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'dépendance',\n",
              "  'ambiguïté',\n",
              "  'évaluation',\n",
              "  'beam',\n",
              "  'search'],\n",
              " ['chunk',\n",
              "  'activation',\n",
              "  'mémoire',\n",
              "  'parsing',\n",
              "  'traitement',\n",
              "  'phrase',\n",
              "  'expérimentation'],\n",
              " ['multilingualisme',\n",
              "  'corpus',\n",
              "  'comparables',\n",
              "  'lexique',\n",
              "  'bilingue',\n",
              "  'vecteur',\n",
              "  'contexte',\n",
              "  'dépendance',\n",
              "  'syntaxiques'],\n",
              " ['apprentissage',\n",
              "  'corpus',\n",
              "  'apprenant',\n",
              "  'analyse',\n",
              "  'linguistique',\n",
              "  'erreur',\n",
              "  'étiquetage',\n",
              "  'automatique',\n",
              "  'this',\n",
              "  'that'],\n",
              " ['lexique',\n",
              "  'morpho',\n",
              "  'phonologique',\n",
              "  'ressource',\n",
              "  'lexicales',\n",
              "  'libres',\n",
              "  'wiktionnaire'],\n",
              " ['lexique',\n",
              "  'bilingue',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'spécialisé',\n",
              "  'désambiguïsation',\n",
              "  'sémantique',\n",
              "  'word'],\n",
              " ['inférence',\n",
              "  'relation',\n",
              "  'réconciliation',\n",
              "  'enrichissement',\n",
              "  'réseau',\n",
              "  'lexical',\n",
              "  'peuplonomie'],\n",
              " ['analyse',\n",
              "  'sémantique',\n",
              "  'automatique',\n",
              "  'sémantique',\n",
              "  'formelle',\n",
              "  'compositionnalité'],\n",
              " ['dialecte',\n",
              "  'langue',\n",
              "  'dotées',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'arabe'],\n",
              " ['néologisme', 'analyse', 'morphologique', 'lexique', 'dynamique'],\n",
              " ['segmentation',\n",
              "  'discursive',\n",
              "  'unité',\n",
              "  'discursive',\n",
              "  'minimale',\n",
              "  'langue',\n",
              "  'arabe'],\n",
              " ['traduction', 'automatique', 'apprentissage', 'discriminant'],\n",
              " ['page',\n",
              "  'texttiling',\n",
              "  'sélection',\n",
              "  'document',\n",
              "  'question',\n",
              "  'réponse',\n",
              "  'quaero',\n",
              "  'ritel',\n",
              "  'segmentation',\n",
              "  'textuelle',\n",
              "  'segmentation',\n",
              "  'thématique'],\n",
              " ['simplification', 'lexicale', 'fréquence', 'lexicale', 'modèle', 'langue'],\n",
              " ['analyse',\n",
              "  'sémantique',\n",
              "  'automatique',\n",
              "  'interface',\n",
              "  'syntaxe',\n",
              "  'sémantique',\n",
              "  'framenet'],\n",
              " ['framenet',\n",
              "  'français',\n",
              "  'construction',\n",
              "  'attribut',\n",
              "  'objet',\n",
              "  'divergence',\n",
              "  'syntaxe',\n",
              "  'sémantique'],\n",
              " ['extraction',\n",
              "  'terminologique',\n",
              "  'ressource',\n",
              "  'endogènes',\n",
              "  'apprentissage',\n",
              "  'automatique'],\n",
              " ['grammaire', 'temporalité', 'modélisation'],\n",
              " ['assistant',\n",
              "  'interactifs',\n",
              "  'apprentissage',\n",
              "  'artificiel',\n",
              "  'système',\n",
              "  'question',\n",
              "  'réponse'],\n",
              " ['graphe',\n",
              "  'lexical',\n",
              "  'composante',\n",
              "  'connexes',\n",
              "  'analogie',\n",
              "  'raisonnement',\n",
              "  'analogique',\n",
              "  'dérivation',\n",
              "  'lexicale'],\n",
              " ['résumé',\n",
              "  'conversation',\n",
              "  'parlées',\n",
              "  'résumé',\n",
              "  'extraction',\n",
              "  'rouge',\n",
              "  'corpus',\n",
              "  'decoda'],\n",
              " ['treebanks',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'grammaire',\n",
              "  'contexte',\n",
              "  'grammaire',\n",
              "  'propriété'],\n",
              " ['traduction', 'automatique', 'oeuvre', 'littéraire', 'post', 'édition'],\n",
              " ['étiquetage', 'morpho', 'syntaxique', 'évaluation', 'néologie', 'formelle'],\n",
              " ['fouille',\n",
              "  'texte',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'parole',\n",
              "  'chanson',\n",
              "  'tags',\n",
              "  'sociaux'],\n",
              " ['formule', 'lisibilité', 'texte', 'administratif', 'aide', 'rédaction'],\n",
              " ['hash', 'tweet', 'analyse', 'opinion'],\n",
              " ['affect',\n",
              "  'jugement',\n",
              "  'appréciation',\n",
              "  'interaction',\n",
              "  'humain',\n",
              "  'agent',\n",
              "  'question',\n",
              "  'réponse'],\n",
              " ['machine',\n",
              "  'finies',\n",
              "  'état',\n",
              "  'cascade',\n",
              "  'transducteur',\n",
              "  'expression',\n",
              "  'régulière'],\n",
              " ['japonais', 'corpus', 'analyseur', 'mecab', 'sagace'],\n",
              " ['concordancier',\n",
              "  'annotation',\n",
              "  'multi',\n",
              "  'niveau',\n",
              "  'linguistique',\n",
              "  'corpus',\n",
              "  'didactique'],\n",
              " ['reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'langue',\n",
              "  'amazighe',\n",
              "  'règle',\n",
              "  'annotation',\n",
              "  'jape',\n",
              "  'gate'],\n",
              " ['topic', 'models', 'induction', 'sens', 'néologie', 'sémantique'],\n",
              " ['grammaire', 'formelle', 'multi', 'linéarité', 'langue', 'signe'],\n",
              " ['multimodalité', 'corpus', 'extraction'],\n",
              " ['annotation',\n",
              "  'temporelle',\n",
              "  'timeml',\n",
              "  'éventualité',\n",
              "  'relation',\n",
              "  'temporelles',\n",
              "  'expression',\n",
              "  'temporelles'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'biomédicale',\n",
              "  'segmentation',\n",
              "  'document',\n",
              "  'identification',\n",
              "  'zone'],\n",
              " ['schéma', 'annotation', 'syntaxe', 'profonde', 'grammaire', 'dépendance'],\n",
              " ['analyse', 'argumentative', 'corpus', 'texte', 'scientifique', 'anthology'],\n",
              " ['réseau',\n",
              "  'lexical',\n",
              "  'français',\n",
              "  'exemple',\n",
              "  'lexicographiques',\n",
              "  'corpus',\n",
              "  'annoté',\n",
              "  'sémantiquement'],\n",
              " ['association', 'couleur', 'réseau', 'lexical', 'crowdsourcing'],\n",
              " ['induction', 'sens', 'bengali', 'weka', 'classification', 'supervisée'],\n",
              " ['ortolang',\n",
              "  'plateforme',\n",
              "  'mutualisation',\n",
              "  'corpus',\n",
              "  'ressource',\n",
              "  'linguistique'],\n",
              " ['analyse',\n",
              "  'sémantique',\n",
              "  'moteur',\n",
              "  'sémantique',\n",
              "  'chat',\n",
              "  'live',\n",
              "  'chat',\n",
              "  'conversation',\n",
              "  'ligne',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langage',\n",
              "  'base',\n",
              "  'connaissance',\n",
              "  'relation',\n",
              "  'client'],\n",
              " ['jeu', 'complexité', 'annotation', 'syntaxe', 'dépendance'],\n",
              " ['entité',\n",
              "  'nommées',\n",
              "  'désambiguïsation',\n",
              "  'apprentissage',\n",
              "  'wikipédia',\n",
              "  'catégorisation'],\n",
              " ['aide', 'rédaction', 'diacritique', 'modèle', 'langue', 'probabiliste'],\n",
              " ['dialecte', 'transcription', 'stam'],\n",
              " ['système',\n",
              "  'dialogue',\n",
              "  'traitement',\n",
              "  'incrémental',\n",
              "  'architecture',\n",
              "  'système',\n",
              "  'dialogue'],\n",
              " ['système',\n",
              "  'dialogue',\n",
              "  'application',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langage',\n",
              "  'naturel',\n",
              "  'assistant',\n",
              "  'personnel'],\n",
              " ['apprentissage',\n",
              "  'automatique',\n",
              "  'french',\n",
              "  'treebank',\n",
              "  'extraction',\n",
              "  'information'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'adaptation',\n",
              "  'domaine',\n",
              "  'marqueur',\n",
              "  'multi',\n",
              "  'polaire'],\n",
              " ['extraction',\n",
              "  'terme',\n",
              "  'clé',\n",
              "  'article',\n",
              "  'scientifique',\n",
              "  'domaine',\n",
              "  'spécialité',\n",
              "  'méthode',\n",
              "  'supervisées'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'extraction',\n",
              "  'rôle',\n",
              "  'événementiels',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'neuronaux'],\n",
              " ['étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'supervisé',\n",
              "  'descripteur',\n",
              "  'riche',\n",
              "  'système',\n",
              "  'statistique',\n",
              "  'robustes'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'dépendance',\n",
              "  'faisceaux',\n",
              "  'programmation',\n",
              "  'dynamique',\n",
              "  'treillis',\n",
              "  'mot',\n",
              "  'couplage',\n",
              "  'analyseur'],\n",
              " ['complexité',\n",
              "  'lexicale',\n",
              "  'analyse',\n",
              "  'morphologique',\n",
              "  'mot',\n",
              "  'gradués',\n",
              "  'ressource',\n",
              "  'lexicales'],\n",
              " ['réseau', 'lexical', 'inférence', 'annotation', 'radiologie'],\n",
              " ['correcteur',\n",
              "  'anaphore',\n",
              "  'pronom',\n",
              "  'saillance',\n",
              "  'approche',\n",
              "  'multistratégique',\n",
              "  'occurrence'],\n",
              " ['chunker',\n",
              "  'étiquetage',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'oral',\n",
              "  'disfluences'],\n",
              " ['normalisation', 'textuelle', 'correction', 'orthographique', 'analogie'],\n",
              " ['sémantique',\n",
              "  'lexicale',\n",
              "  'sémantique',\n",
              "  'distributionnelle',\n",
              "  'compositionalité'],\n",
              " ['apprentissage',\n",
              "  'partiellement',\n",
              "  'supervisé',\n",
              "  'analyse',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'transfert',\n",
              "  'cross',\n",
              "  'lingue'],\n",
              " ['corpus',\n",
              "  'comparable',\n",
              "  'corpus',\n",
              "  'monolingue',\n",
              "  'corpus',\n",
              "  'annoté',\n",
              "  'mesure',\n",
              "  'comparabilité',\n",
              "  'construction',\n",
              "  'corpus',\n",
              "  'comparable',\n",
              "  'analyse',\n",
              "  'morpho',\n",
              "  'syntaxique'],\n",
              " ['système',\n",
              "  'dialogue',\n",
              "  'traitement',\n",
              "  'incrémental',\n",
              "  'architecture',\n",
              "  'système',\n",
              "  'dialogue'],\n",
              " ['réseau',\n",
              "  'lexical',\n",
              "  'morphologie',\n",
              "  'dérivationnelle',\n",
              "  'famille',\n",
              "  'morphologique',\n",
              "  'sémantique',\n",
              "  'lexicale',\n",
              "  'français'],\n",
              " ['thésaurus',\n",
              "  'distributionnel',\n",
              "  'graphe',\n",
              "  'proche',\n",
              "  'voisin',\n",
              "  'fenêtre',\n",
              "  'parzen',\n",
              "  'algorithme',\n",
              "  'hongrois',\n",
              "  'tnormes',\n",
              "  'recherche',\n",
              "  'information'],\n",
              " ['discours', 'pathologique', 'schizophrénie', 'disfluences'],\n",
              " ['paraphrase',\n",
              "  'reformulation',\n",
              "  'corpus',\n",
              "  'oral',\n",
              "  'marqueur',\n",
              "  'reformulation',\n",
              "  'paraphrastique'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'naturel',\n",
              "  'désambiguïsation',\n",
              "  'morphologique',\n",
              "  'arabe',\n",
              "  'théorie',\n",
              "  'possibilité',\n",
              "  'classification',\n",
              "  'possibiliste'],\n",
              " ['analyse',\n",
              "  'guidée',\n",
              "  'tête',\n",
              "  'analyse',\n",
              "  'temps',\n",
              "  'linéaire',\n",
              "  'modèle',\n",
              "  'discriminant',\n",
              "  'inférence',\n",
              "  'approximative'],\n",
              " ['jugement',\n",
              "  'grammaticalité',\n",
              "  'syntaxe',\n",
              "  'modèle',\n",
              "  'grammaire',\n",
              "  'propriété',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'probabiliste'],\n",
              " ['annotation',\n",
              "  'sémantique',\n",
              "  'extraction',\n",
              "  'désambiguïsation',\n",
              "  'terminologique',\n",
              "  'textométrie',\n",
              "  'texte',\n",
              "  'intégral'],\n",
              " ['nom', 'spécifiés', 'motif', 'séquentiels', 'structure', 'discursive'],\n",
              " ['analyse',\n",
              "  'sentiment',\n",
              "  'interaction',\n",
              "  'humain',\n",
              "  'agent',\n",
              "  'agent',\n",
              "  'conversationnels',\n",
              "  'animé',\n",
              "  'dialogue',\n",
              "  'homme',\n",
              "  'machine'],\n",
              " ['alignement', 'research', 'learning', 'multimodalité'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'ajustement',\n",
              "  'modèle',\n",
              "  'caractéristique',\n",
              "  'grand',\n",
              "  'échelle'],\n",
              " ['polarité', 'sentiment', 'réseau', 'lexical', 'crowdsourcing', 'gwap'],\n",
              " ['réseau',\n",
              "  'neurone',\n",
              "  'artificiels',\n",
              "  'allocation',\n",
              "  'latente',\n",
              "  'dirichlet',\n",
              "  'initialisation',\n",
              "  'poids'],\n",
              " ['connecteur',\n",
              "  'discours',\n",
              "  'annotation',\n",
              "  'discursive',\n",
              "  'corpus',\n",
              "  'grammaire',\n",
              "  'discours'],\n",
              " ['reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'film',\n",
              "  'classification',\n",
              "  'règle',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'wikipedia'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'statistique',\n",
              "  'génération',\n",
              "  'automatique',\n",
              "  'texte',\n",
              "  'contexte',\n",
              "  'phrastique',\n",
              "  'terminologie',\n",
              "  'bilingue'],\n",
              " ['ressource', 'termino', 'ontologique', 'apprentissage', 'similarité'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'social',\n",
              "  'corpus',\n",
              "  'annoté',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'semi',\n",
              "  'supervisée'],\n",
              " ['corpus', 'spécialisé', 'patron', 'connaisssances', 'collocation'],\n",
              " ['corpus',\n",
              "  'dialogue',\n",
              "  'détection',\n",
              "  'référence',\n",
              "  'apprentissage',\n",
              "  'paire',\n",
              "  'mention'],\n",
              " ['réseau',\n",
              "  'lexico',\n",
              "  'sémantique',\n",
              "  'propagation',\n",
              "  'indexation',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'imagerie',\n",
              "  'médicale'],\n",
              " ['analyse', 'opinion', 'détection', 'ironie', 'apprentissage', 'supervisé'],\n",
              " ['morphologie', 'arabe', 'metagrammaire', 'frame', 'semantics'],\n",
              " ['centre',\n",
              "  'contact',\n",
              "  'conversation',\n",
              "  'tchat',\n",
              "  'interaction',\n",
              "  'analyse',\n",
              "  'lexicale',\n",
              "  'syntaxique'],\n",
              " ['analyse',\n",
              "  'conversation',\n",
              "  'humain',\n",
              "  'humain',\n",
              "  'extraction',\n",
              "  'automatique',\n",
              "  'unité',\n",
              "  'sémantique',\n",
              "  'pertinentes',\n",
              "  'validation',\n",
              "  'ontologie'],\n",
              " ['typologie',\n",
              "  'lien',\n",
              "  'inter',\n",
              "  'document',\n",
              "  'hypertexte',\n",
              "  'multimédia',\n",
              "  'presse'],\n",
              " ['corpus', 'français', 'annotation', 'pendances', 'pendances', 'projectives'],\n",
              " ['mult',\n",
              "  'ilinguisme',\n",
              "  'transfert',\n",
              "  'cross',\n",
              "  'lingue',\n",
              "  'étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'récurrents'],\n",
              " ['segmentation',\n",
              "  'thématique',\n",
              "  'titrage',\n",
              "  'automatique',\n",
              "  'pondération',\n",
              "  'okapi',\n",
              "  'mesure',\n",
              "  'similarité'],\n",
              " ['annotation', 'corpus', 'discours', 'relation', 'causales'],\n",
              " ['sémantique', 'distributionnelle', 'compositionnalité', 'flexion'],\n",
              " ['construction',\n",
              "  'lexique',\n",
              "  'morphologique',\n",
              "  'annotation',\n",
              "  'étiquetage',\n",
              "  'corpus',\n",
              "  'linguistique',\n",
              "  'diachronique'],\n",
              " ['fouille',\n",
              "  'séquence',\n",
              "  'motif',\n",
              "  'libres',\n",
              "  'classification',\n",
              "  'texte',\n",
              "  'sélection',\n",
              "  'descripteur'],\n",
              " ['pharmacovigilance', 'forum', 'santé', 'relation', 'causales'],\n",
              " ['tweets', 'étiquettage', 'morpho', 'syntaxique'],\n",
              " ['analyse',\n",
              "  'linguistique',\n",
              "  'discours',\n",
              "  'scientifique',\n",
              "  'vulgarisation',\n",
              "  'corpus',\n",
              "  'comparables',\n",
              "  'classification',\n",
              "  'genre'],\n",
              " ['comparaison',\n",
              "  'figuratif',\n",
              "  'comparé',\n",
              "  'comparant',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'surface',\n",
              "  'règle',\n",
              "  'manuelle',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'profonde'],\n",
              " ['community',\n",
              "  'management',\n",
              "  'textométrie',\n",
              "  'mult',\n",
              "  'ilinguisme',\n",
              "  'fouille',\n",
              "  'texte'],\n",
              " ['alignement',\n",
              "  'texte',\n",
              "  'génétique',\n",
              "  'textuelle',\n",
              "  'détection',\n",
              "  'homologie',\n",
              "  'séquence',\n",
              "  'textuelles'],\n",
              " ['corpus', 'corpus', 'arborés', 'environnement', 'étude', 'corpus'],\n",
              " ['génération',\n",
              "  'texte',\n",
              "  'prédiction',\n",
              "  'sémantique',\n",
              "  'frame',\n",
              "  'semantics',\n",
              "  'handicap',\n",
              "  'aide',\n",
              "  'communication'],\n",
              " ['tier',\n",
              "  'sgrm',\n",
              "  'système',\n",
              "  'gestion',\n",
              "  'règle',\n",
              "  'métier',\n",
              "  'analyse',\n",
              "  'sémantique'],\n",
              " ['annotation',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'corpus',\n",
              "  'oral',\n",
              "  'disfluences',\n",
              "  'unité',\n",
              "  'poly',\n",
              "  'lexicales'],\n",
              " ['apprentissage',\n",
              "  'imitation',\n",
              "  'apprentissage',\n",
              "  'structuré',\n",
              "  'étiquetage',\n",
              "  'séquence'],\n",
              " ['compte',\n",
              "  'rendu',\n",
              "  'hospitalier',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'apprentissage',\n",
              "  'statistique'],\n",
              " ['étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'apprentissage',\n",
              "  'statistique',\n",
              "  'champ',\n",
              "  'markoviens',\n",
              "  'aléatoires'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'analyse',\n",
              "  'temporelle',\n",
              "  'développement',\n",
              "  'corpus',\n",
              "  'annoté'],\n",
              " ['compréhension',\n",
              "  'automatique',\n",
              "  'parole',\n",
              "  'espace',\n",
              "  'sémantique',\n",
              "  'continu',\n",
              "  'apprentissage',\n",
              "  'donnée',\n",
              "  'référence',\n",
              "  'donnée',\n",
              "  'apprentissage',\n",
              "  'domaine'],\n",
              " ['événement',\n",
              "  'modèle',\n",
              "  'génératif',\n",
              "  'désambiguïsation',\n",
              "  'entité',\n",
              "  'échantillonnage',\n",
              "  'gibbs'],\n",
              " ['clarification',\n",
              "  'texte',\n",
              "  'désambiguïsation',\n",
              "  'lexicale',\n",
              "  'langue',\n",
              "  'dotées',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'portage',\n",
              "  'annotation'],\n",
              " ['textométrie',\n",
              "  'sémantique',\n",
              "  'corpus',\n",
              "  'fouille',\n",
              "  'opinion',\n",
              "  'analyse',\n",
              "  'sentiment'],\n",
              " ['relation',\n",
              "  'sémantique',\n",
              "  'patron',\n",
              "  'lexico',\n",
              "  'syntaxiques',\n",
              "  'distributionnalisme',\n",
              "  'prédication',\n",
              "  'hyperonymie',\n",
              "  'synonymie',\n",
              "  'méronymie',\n",
              "  'définition'],\n",
              " ['sémantique',\n",
              "  'lexicale',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'thésaurus',\n",
              "  'distributionnels'],\n",
              " ['fonction',\n",
              "  'noyau',\n",
              "  'variation',\n",
              "  'sémantique',\n",
              "  'réécriture',\n",
              "  'phrase',\n",
              "  'reconnaissance',\n",
              "  'paraphrase',\n",
              "  'implication',\n",
              "  'textuelle'],\n",
              " ['étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'analyse',\n",
              "  'dépendance',\n",
              "  'ancien',\n",
              "  'français',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'exploration',\n",
              "  'corpus'],\n",
              " ['similarité',\n",
              "  'sémantique',\n",
              "  'indexation',\n",
              "  'aléatoire',\n",
              "  'wikipédia',\n",
              "  'relation',\n",
              "  'sémantique'],\n",
              " ['typologie',\n",
              "  'syntaxe',\n",
              "  'treebank',\n",
              "  'inférence',\n",
              "  'grammaire',\n",
              "  'grammaire',\n",
              "  'propriété'],\n",
              " ['mesure',\n",
              "  'confiance',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'parole',\n",
              "  'paramètre',\n",
              "  'joint',\n",
              "  'redécodage',\n",
              "  'graphe'],\n",
              " ['alignement', 'multi', 'lingue', 'corpus', 'parallèle', 'cognat'],\n",
              " ['modèle',\n",
              "  'neuronal',\n",
              "  'traduction',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'approche',\n",
              "  'statistique',\n",
              "  'apprentissage',\n",
              "  'discriminant'],\n",
              " ['interjection',\n",
              "  'détection',\n",
              "  'émotion',\n",
              "  'lexique',\n",
              "  'affectif',\n",
              "  'analyse',\n",
              "  'sentiment',\n",
              "  'fouille',\n",
              "  'opinion'],\n",
              " ['corpus',\n",
              "  'oral',\n",
              "  'paraphrase',\n",
              "  'reformulation',\n",
              "  'marqueur',\n",
              "  'reformulation',\n",
              "  'paraphrastique',\n",
              "  'apprentissage',\n",
              "  'supervisé'],\n",
              " ['classification',\n",
              "  'supervisée',\n",
              "  'classification',\n",
              "  'fin',\n",
              "  'ligne',\n",
              "  'paragraphe',\n",
              "  'repliés'],\n",
              " ['terminologie',\n",
              "  'extraction',\n",
              "  'terme',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'agglutination',\n",
              "  'texte',\n",
              "  'médicaux'],\n",
              " ['entité',\n",
              "  'spatiales',\n",
              "  'relation',\n",
              "  'spatiales',\n",
              "  'mesure',\n",
              "  'similarité',\n",
              "  'corpus'],\n",
              " ['extension',\n",
              "  'lexicale',\n",
              "  'mesure',\n",
              "  'lesk',\n",
              "  'corpus',\n",
              "  'annotés',\n",
              "  'sens',\n",
              "  'désambiguïsation',\n",
              "  'lexicale'],\n",
              " ['sentiment', 'crowdsourcing', 'gwap', 'réseau', 'lexical', 'propagation'],\n",
              " ['analyse',\n",
              "  'salve',\n",
              "  'lexicales',\n",
              "  'hiérarchie',\n",
              "  'fragment',\n",
              "  'thématique',\n",
              "  'résumé',\n",
              "  'automatique',\n",
              "  'détection',\n",
              "  'ancre'],\n",
              " ['reformulation',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'terminologie',\n",
              "  'médicale',\n",
              "  'langage',\n",
              "  'profane'],\n",
              " ['morphologie',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'modèle',\n",
              "  'bayésiens',\n",
              "  'paramétriques'],\n",
              " ['prédiction',\n",
              "  'lexicale',\n",
              "  'modèle',\n",
              "  'adaptatifs',\n",
              "  'apprentissage',\n",
              "  'incrémental'],\n",
              " ['extraction',\n",
              "  'information',\n",
              "  'fouille',\n",
              "  'motif',\n",
              "  'reconnaissance',\n",
              "  'symptôme',\n",
              "  'texte',\n",
              "  'biomédicaux'],\n",
              " ['reformulation',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'paraphrase',\n",
              "  'classification',\n",
              "  'fonction',\n",
              "  'pragmatique'],\n",
              " ['analyse', 'discours', 'conversation', 'acte', 'dialogue', 'multimodalité'],\n",
              " ['analyse', 'dépendance', 'analyse', 'transition', 'oracle'],\n",
              " ['apprentissage',\n",
              "  'incrémental',\n",
              "  'raisonnement',\n",
              "  'analogique',\n",
              "  'transfert',\n",
              "  'langage'],\n",
              " ['analyse',\n",
              "  'littérature',\n",
              "  'scientifique',\n",
              "  'extraction',\n",
              "  'relation',\n",
              "  'clustering',\n",
              "  'biclustering'],\n",
              " ['lisibilité',\n",
              "  'annotation',\n",
              "  'sémantique',\n",
              "  'synonyme',\n",
              "  'prédiction',\n",
              "  'difficulté',\n",
              "  'lexicale',\n",
              "  'niveau',\n",
              "  'difficulté'],\n",
              " ['notoriété', 'nom', 'propre', 'prolexbase', 'wikipedia'],\n",
              " ['corpus',\n",
              "  'comparables',\n",
              "  'lexique',\n",
              "  'bilingue',\n",
              "  'domaine',\n",
              "  'spécialisé',\n",
              "  'langue',\n",
              "  'pivot'],\n",
              " ['classification',\n",
              "  'supervisée',\n",
              "  'sémantique',\n",
              "  'théorie',\n",
              "  'sens',\n",
              "  'texte',\n",
              "  'fonction',\n",
              "  'lexicales',\n",
              "  'statistique',\n",
              "  'medoïdes'],\n",
              " ['substitution', 'lexicale', 'difficulté', 'tâche', 'annotation'],\n",
              " ['arabe',\n",
              "  'approche',\n",
              "  'hybride',\n",
              "  'modèle',\n",
              "  'linked',\n",
              "  'data',\n",
              "  'datasets',\n",
              "  'lexique',\n",
              "  'bilingue'],\n",
              " ['correction',\n",
              "  'orthographique',\n",
              "  'correction',\n",
              "  'grammaticale',\n",
              "  'évaluation',\n",
              "  'positive',\n",
              "  'didactique',\n",
              "  'français',\n",
              "  'écrit',\n",
              "  'zone',\n",
              "  'résistance',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'diversifié'],\n",
              " ['portage',\n",
              "  'annotation',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'désambiguïsation',\n",
              "  'lexicale'],\n",
              " ['lexique',\n",
              "  'flexion',\n",
              "  'verbe',\n",
              "  'variabilité',\n",
              "  'graphique',\n",
              "  'unitex',\n",
              "  'alsacien'],\n",
              " ['multilinguisme',\n",
              "  'transfert',\n",
              "  'crosslingue',\n",
              "  'annotation',\n",
              "  'sémantique',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'récurrents'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'extraction',\n",
              "  'expression',\n",
              "  'cible',\n",
              "  'étiquetage',\n",
              "  'multilingue'],\n",
              " ['étiquetage', 'morphosyntaxique', 'multilingue', 'évaluation'],\n",
              " ['annotation', 'morphosyntaxique', 'corpus', 'entraînement', 'serbe'],\n",
              " ['syntaxe',\n",
              "  'modèle',\n",
              "  'jugement',\n",
              "  'grammaticalité',\n",
              "  'ingénierie',\n",
              "  'grammaire'],\n",
              " ['transfert',\n",
              "  'cross',\n",
              "  'lingue',\n",
              "  'analyse',\n",
              "  'dépendance',\n",
              "  'annotation',\n",
              "  'partielle'],\n",
              " ['rhèse',\n",
              "  'chunk',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'dyslexie',\n",
              "  'guide',\n",
              "  'annotation'],\n",
              " ['corpus',\n",
              "  'comparables',\n",
              "  'analyse',\n",
              "  'factorielle',\n",
              "  'correspondance',\n",
              "  'gramme',\n",
              "  'genre',\n",
              "  'textuels'],\n",
              " ['extraction',\n",
              "  'relation',\n",
              "  'analyse',\n",
              "  'temporelle',\n",
              "  'traitement',\n",
              "  'langue',\n",
              "  'biomédicale'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'article',\n",
              "  'ligne',\n",
              "  'corpus',\n",
              "  'vidéo',\n",
              "  'évaluation'],\n",
              " ['agent',\n",
              "  'virtuel',\n",
              "  'besoin',\n",
              "  'information',\n",
              "  'sélection',\n",
              "  'terme',\n",
              "  'donnée',\n",
              "  'bruitées'],\n",
              " ['dictée', 'lisibilité', 'orthographe', 'alao'],\n",
              " ['réseau',\n",
              "  'sociaux',\n",
              "  'média',\n",
              "  'hoax',\n",
              "  'réinformation',\n",
              "  'classification',\n",
              "  'texte'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'contexte',\n",
              "  'parole',\n",
              "  'genre',\n",
              "  'pronom',\n",
              "  'question'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langage',\n",
              "  'forum',\n",
              "  'discussion',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'langage',\n",
              "  'patient',\n",
              "  'maladie'],\n",
              " ['reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'french',\n",
              "  'treebank',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'réseau',\n",
              "  'neurone'],\n",
              " ['corpus', 'scolaire', 'alignement', 'normalisation'],\n",
              " ['déterminant',\n",
              "  'quantificateur',\n",
              "  'généralisés',\n",
              "  'sémantique',\n",
              "  'logique',\n",
              "  'dynamique'],\n",
              " ['étiquetage',\n",
              "  'automatique',\n",
              "  'incertitude',\n",
              "  'négation',\n",
              "  'apprentissage',\n",
              "  'artificiel',\n",
              "  'apprentissage',\n",
              "  'supervisé'],\n",
              " ['affirmation',\n",
              "  'inappropriées',\n",
              "  'spin',\n",
              "  'embellissement',\n",
              "  'résultat',\n",
              "  'article',\n",
              "  'biomédicaux',\n",
              "  'rôle',\n",
              "  'sémantique',\n",
              "  'extraction',\n",
              "  'entité'],\n",
              " ['expression', 'polylexicales', 'figement', 'variabilité'],\n",
              " ['résolution',\n",
              "  'anaphore',\n",
              "  'schéma',\n",
              "  'winograd',\n",
              "  'information',\n",
              "  'mutuelle',\n",
              "  'test',\n",
              "  'turing'],\n",
              " ['valeur',\n",
              "  'numériques',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'normalisation',\n",
              "  'domaine',\n",
              "  'médical'],\n",
              " ['analyse',\n",
              "  'cadre',\n",
              "  'sémantique',\n",
              "  'étiquetage',\n",
              "  'séquence',\n",
              "  'texte',\n",
              "  'encyclopédiques'],\n",
              " ['expression',\n",
              "  'référentielle',\n",
              "  'mention',\n",
              "  'détection',\n",
              "  'automatique',\n",
              "  'relation',\n",
              "  'coréférence'],\n",
              " ['factivité', 'modalité', 'degré', 'croyance', 'analyse', 'discursive'],\n",
              " ['flexion', 'morphophonologie', 'linguistique', 'quantitative', 'typologie'],\n",
              " ['fouille', 'texte', 'métaphore', 'géographie', 'humanité', 'numériques'],\n",
              " ['auto',\n",
              "  'encodeur',\n",
              "  'variationnel',\n",
              "  'apprentissage',\n",
              "  'faiblement',\n",
              "  'supervisé',\n",
              "  'changement',\n",
              "  'stylistique'],\n",
              " ['typologie', 'tweets', 'normalisation'],\n",
              " ['cooccurrences',\n",
              "  'inférence',\n",
              "  'patron',\n",
              "  'relation',\n",
              "  'sémantique',\n",
              "  'combinaison'],\n",
              " ['réseau',\n",
              "  'jeuxdemots',\n",
              "  'détection',\n",
              "  'relation',\n",
              "  'erronées',\n",
              "  'inférence',\n",
              "  'relation'],\n",
              " ['annotation', 'syntaxe', 'dépendance', 'crowdsourcing', 'jeu'],\n",
              " ['mot',\n",
              "  'standard',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'modèle',\n",
              "  'convolutionnel',\n",
              "  'plongement'],\n",
              " ['corpus',\n",
              "  'dialogue',\n",
              "  'coréférence',\n",
              "  'détection',\n",
              "  'mention',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'chunk',\n",
              "  'apprentissage',\n",
              "  'automatique'],\n",
              " ['multilinguisme', 'tafd'],\n",
              " ['traduction',\n",
              "  'automatique',\n",
              "  'neuronale',\n",
              "  'adaptation',\n",
              "  'domaine',\n",
              "  'étude',\n",
              "  'préliminaire'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'classification',\n",
              "  'supervisée',\n",
              "  'revue',\n",
              "  'systématique'],\n",
              " ['dialecte',\n",
              "  'arabe',\n",
              "  'arabizi',\n",
              "  'alternance',\n",
              "  'codique',\n",
              "  'translittération',\n",
              "  'identification',\n",
              "  'dialecte',\n",
              "  'analyse',\n",
              "  'morphologique'],\n",
              " ['modèle',\n",
              "  'langue',\n",
              "  'neuronal',\n",
              "  'représentation',\n",
              "  'continues',\n",
              "  'dérivée',\n",
              "  'caractère',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'approche',\n",
              "  'statistique'],\n",
              " ['traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'naturel',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'probabiliste',\n",
              "  'mot',\n",
              "  'vocabulaire',\n",
              "  'graphe',\n",
              "  'mot',\n",
              "  'plongement',\n",
              "  'mot',\n",
              "  'reconnaissance',\n",
              "  'optique',\n",
              "  'caractère'],\n",
              " ['constituant', 'discontinu', 'analyse', 'syntaxique', 'deep', 'learning'],\n",
              " ['sémantique', 'distributionnelle', 'thésaurus', 'plongement', 'lexicaux'],\n",
              " ['word', 'embedding', 'projection', 'aléatoire'],\n",
              " ['annotation',\n",
              "  'partie',\n",
              "  'discours',\n",
              "  'crowdsourcing',\n",
              "  'alsacien',\n",
              "  'langue',\n",
              "  'dotées'],\n",
              " ['ethique', 'science', 'participative', 'crowdsourcing', 'évaluation'],\n",
              " ['développement', 'ressource', 'lexicales', 'étymologie', 'wiktionary'],\n",
              " ['tweet', 'polarité', 'lstm'],\n",
              " ['analyse',\n",
              "  'caractère',\n",
              "  'lstm',\n",
              "  'gramme',\n",
              "  'caractère',\n",
              "  'détection',\n",
              "  'polarité',\n",
              "  'analyse',\n",
              "  'tweets'],\n",
              " ['fasttext', 'classification', 'ensemble'],\n",
              " ['analyse',\n",
              "  'opinion',\n",
              "  'boosting',\n",
              "  'arbre',\n",
              "  'décision',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'récurrents',\n",
              "  'plongement',\n",
              "  'mot'],\n",
              " ['tweets',\n",
              "  'fouille',\n",
              "  'opinion',\n",
              "  'transport',\n",
              "  'classification',\n",
              "  'automatique'],\n",
              " ['classification', 'régression', 'logistique'],\n",
              " ['analyse', 'polarité', 'réseau', 'neurone', 'word', 'embedding'],\n",
              " ['inférence', 'fouille', 'opinion', 'polarité'],\n",
              " ['résumé',\n",
              "  'automatique',\n",
              "  'texte',\n",
              "  'résumé',\n",
              "  'guidé',\n",
              "  'approche',\n",
              "  'extractive',\n",
              "  'approche',\n",
              "  'abstractive',\n",
              "  'traitement',\n",
              "  'automatique',\n",
              "  'langue',\n",
              "  'naturel',\n",
              "  'extraction',\n",
              "  'information'],\n",
              " ['registre', 'langue', 'descripteur', 'linguistique', 'validation'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'annotation',\n",
              "  'image',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'convolutionnels',\n",
              "  'détection',\n",
              "  'déforestation'],\n",
              " ['influence', 'média', 'social', 'réseau', 'centralité', 'opinion'],\n",
              " ['détection',\n",
              "  'coréférence',\n",
              "  'corpus',\n",
              "  'apprentissage',\n",
              "  'automatique',\n",
              "  'classification'],\n",
              " ['simplification',\n",
              "  'automatique',\n",
              "  'texte',\n",
              "  'analyse',\n",
              "  'lexicale',\n",
              "  'domaine',\n",
              "  'médical',\n",
              "  'simplification',\n",
              "  'lexicale',\n",
              "  'substitution',\n",
              "  'lexicale'],\n",
              " ['detection', 'erreur', 'réseau', 'neurone', 'récurrents'],\n",
              " ['reconnaissance',\n",
              "  'entité',\n",
              "  'nommées',\n",
              "  'benchmarking',\n",
              "  'évaluation',\n",
              "  'français'],\n",
              " ['analyse',\n",
              "  'constituant',\n",
              "  'corpus',\n",
              "  'arboré',\n",
              "  'erreur',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'système',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'statistique',\n",
              "  'neuraux',\n",
              "  'français'],\n",
              " ['analyse', 'dépendance', 'analyse', 'transition', 'oracle'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'construction',\n",
              "  'automatique',\n",
              "  'corpus',\n",
              "  'annotés'],\n",
              " ['forum',\n",
              "  'discussion',\n",
              "  'santé',\n",
              "  'classification',\n",
              "  'supervisée',\n",
              "  'domaine',\n",
              "  'médical',\n",
              "  'mésusage',\n",
              "  'médicament'],\n",
              " ['traduction', 'automatique', 'japonais', 'français'],\n",
              " ['sémantique',\n",
              "  'distributionnelle',\n",
              "  'spécialisation',\n",
              "  'plongement',\n",
              "  'lexicaux'],\n",
              " ['type',\n",
              "  'discours',\n",
              "  'discours',\n",
              "  'direct',\n",
              "  'incise',\n",
              "  'annotation',\n",
              "  'automatique'],\n",
              " ['analyse',\n",
              "  'sentiment',\n",
              "  'dialecte',\n",
              "  'tunisien',\n",
              "  'prétraitement',\n",
              "  'texte',\n",
              "  'entité',\n",
              "  'nommées'],\n",
              " ['dialogue',\n",
              "  'humain',\n",
              "  'humain',\n",
              "  'échec',\n",
              "  'dialogue',\n",
              "  'corpus',\n",
              "  'dialogue',\n",
              "  'apprentissage',\n",
              "  'artificiel',\n",
              "  'évaluation',\n",
              "  'dialogue',\n",
              "  'dialogue',\n",
              "  'asymétrique'],\n",
              " ['négation',\n",
              "  'français',\n",
              "  'portugais',\n",
              "  'brésilien',\n",
              "  'apprentissage',\n",
              "  'supervisé',\n",
              "  'réseau',\n",
              "  'neurone'],\n",
              " ['fouille',\n",
              "  'texte',\n",
              "  'réseau',\n",
              "  'signalisation',\n",
              "  'biologie',\n",
              "  'systémique',\n",
              "  'cascade',\n",
              "  'transducteur',\n",
              "  'cassys',\n",
              "  'unitex',\n",
              "  'prédicat'],\n",
              " ['taln', 'médical', 'simplification', 'réseau', 'lexico', 'sémantique'],\n",
              " ['modèle',\n",
              "  'langue',\n",
              "  'estimation',\n",
              "  'contrastive',\n",
              "  'bruitée',\n",
              "  'negative',\n",
              "  'sampling'],\n",
              " ['entité', 'nommées', 'schéma', 'annotation', 'simplification'],\n",
              " ['arabizi', 'dialecte', 'algérien', 'arabizi', 'algérien', 'translitération'],\n",
              " ['lieu',\n",
              "  'lieu',\n",
              "  'propre',\n",
              "  'commun',\n",
              "  'linguistique',\n",
              "  'corpus',\n",
              "  'cartographie'],\n",
              " ['emoji',\n",
              "  'recommandation',\n",
              "  'plongement',\n",
              "  'lexicaux',\n",
              "  'ressource',\n",
              "  'regroupement'],\n",
              " ['similarité',\n",
              "  'mot',\n",
              "  'plongement',\n",
              "  'mot',\n",
              "  'visualisation',\n",
              "  'donnée',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'peuplement',\n",
              "  'ontologie'],\n",
              " ['annotation', 'erreur', 'traduction', 'annotation', 'collaborative'],\n",
              " ['tokenisation',\n",
              "  'morphologie',\n",
              "  'étiquetage',\n",
              "  'morphosyntaxique',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'entité',\n",
              "  'relation',\n",
              "  'interface',\n",
              "  'graphique'],\n",
              " ['étiquetage', 'entité', 'nommées', 'corpus', 'annotation', 'structurée'],\n",
              " ['analyse',\n",
              "  'base',\n",
              "  'règle',\n",
              "  'annotation',\n",
              "  'sémantique',\n",
              "  'expression',\n",
              "  'régulière',\n",
              "  'extraction',\n",
              "  'information',\n",
              "  'fouille',\n",
              "  'texte',\n",
              "  'python'],\n",
              " ['corpus',\n",
              "  'annoté',\n",
              "  'sens',\n",
              "  'langue',\n",
              "  'arabe',\n",
              "  'alignement',\n",
              "  'sens',\n",
              "  'interlingues'],\n",
              " ['lisibilité',\n",
              "  'document',\n",
              "  'compréhension',\n",
              "  'alphabétisation',\n",
              "  'médicale',\n",
              "  'oculométrie'],\n",
              " ['plongement', 'lexicaux', 'évaluation', 'stabilité', 'reproductibilité'],\n",
              " ['mtraduction', 'automatique', 'évaluation', 'morphologie'],\n",
              " ['étiquetage', 'partie', 'discours', 'langue', 'dotées'],\n",
              " ['analyse',\n",
              "  'syntaxique',\n",
              "  'sémantique',\n",
              "  'modélisation',\n",
              "  'acquisition',\n",
              "  'jeu',\n",
              "  'langage'],\n",
              " ['détection',\n",
              "  'événement',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'convolutifs',\n",
              "  'contexte',\n",
              "  'discursif'],\n",
              " ['registre',\n",
              "  'langue',\n",
              "  'apprentissage',\n",
              "  'semi',\n",
              "  'supervisé',\n",
              "  'construction',\n",
              "  'corpus',\n",
              "  'classification',\n",
              "  'automatique'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'approche',\n",
              "  'supervisée',\n",
              "  'lstm',\n",
              "  'réseau',\n",
              "  'neuronal'],\n",
              " ['rattachement',\n",
              "  'prépositionnel',\n",
              "  'analyse',\n",
              "  'syntaxique',\n",
              "  'multimodale',\n",
              "  'stratégie',\n",
              "  'correction'],\n",
              " ['modèle',\n",
              "  'neuronal',\n",
              "  'apprentissage',\n",
              "  'transfert',\n",
              "  'transcription',\n",
              "  'comédie',\n",
              "  'italien'],\n",
              " ['reconnaissance',\n",
              "  'automatique',\n",
              "  'parole',\n",
              "  'adaptation',\n",
              "  'modèle',\n",
              "  'langage',\n",
              "  'mesure',\n",
              "  'indexibilité',\n",
              "  'recherche',\n",
              "  'information',\n",
              "  'éducation'],\n",
              " ['dialogue',\n",
              "  'chat',\n",
              "  'acte',\n",
              "  'dialogue',\n",
              "  'apprentissage',\n",
              "  'faiblement',\n",
              "  'supervisé'],\n",
              " ['structure',\n",
              "  'discours',\n",
              "  'supervision',\n",
              "  'distante',\n",
              "  'attachement',\n",
              "  'data',\n",
              "  'programming'],\n",
              " ['procédé',\n",
              "  'traduction',\n",
              "  'classification',\n",
              "  'automatique',\n",
              "  'extraction',\n",
              "  'paraphrase'],\n",
              " ['adaptation',\n",
              "  'domaine',\n",
              "  'classification',\n",
              "  'extraction',\n",
              "  'relation',\n",
              "  'texte',\n",
              "  'biomédicaux'],\n",
              " ['recherche',\n",
              "  'information',\n",
              "  'requête',\n",
              "  'forum',\n",
              "  'adhérence',\n",
              "  'médicamenteuse'],\n",
              " ['simplification',\n",
              "  'classification',\n",
              "  'similarité',\n",
              "  'phrase',\n",
              "  'parallèle',\n",
              "  'corpus',\n",
              "  'comparables',\n",
              "  'domaine',\n",
              "  'médical'],\n",
              " ['lexique', 'morphologique', 'lexique', 'syntaxique', 'ancien', 'français'],\n",
              " ['apprentissage',\n",
              "  'transfert',\n",
              "  'traduction',\n",
              "  'automatique',\n",
              "  'neuronale',\n",
              "  'quantité',\n",
              "  'donnée',\n",
              "  'proximité',\n",
              "  'langue'],\n",
              " ['plongement', 'évaluation', 'objective', 'synthèse', 'parole'],\n",
              " ['apprentissage',\n",
              "  'transfert',\n",
              "  'contenu',\n",
              "  'réseau',\n",
              "  'sociaux',\n",
              "  'langue',\n",
              "  'dotées',\n",
              "  'adaptation',\n",
              "  'domaine',\n",
              "  'étiquetage',\n",
              "  'morpho',\n",
              "  'syntaxique',\n",
              "  'reconnaissance',\n",
              "  'entité',\n",
              "  'nommées'],\n",
              " ['informativité',\n",
              "  'plongement',\n",
              "  'mot',\n",
              "  'classification',\n",
              "  'phrase',\n",
              "  'labellisation'],\n",
              " ['agent',\n",
              "  'conversationnels',\n",
              "  'chatbots',\n",
              "  'médecine',\n",
              "  'formation',\n",
              "  'similarité',\n",
              "  'sémantique',\n",
              "  'plongement',\n",
              "  'lexicaux'],\n",
              " ['réseau',\n",
              "  'lexico',\n",
              "  'sémantique',\n",
              "  'ressource',\n",
              "  'multilingue',\n",
              "  'inférence',\n",
              "  'relation'],\n",
              " ['correction',\n",
              "  'orthographique',\n",
              "  'dyslexie',\n",
              "  'apprentissage',\n",
              "  'langue',\n",
              "  'analyse',\n",
              "  'corpus'],\n",
              " ['schéma', 'winograd', 'résolution', 'anaphore', 'modèle', 'langue', 'lstm'],\n",
              " ['fouille',\n",
              "  'opinion',\n",
              "  'langage',\n",
              "  'évaluative',\n",
              "  'donnée',\n",
              "  'disparate',\n",
              "  'expérience',\n",
              "  'client'],\n",
              " ['langue', 'dotées', 'corse', 'ressource', 'linguistique', 'lemmatisation'],\n",
              " ['résolution',\n",
              "  'anaphore',\n",
              "  'apprentissage',\n",
              "  'renforcement',\n",
              "  'learning',\n",
              "  'critère',\n",
              "  'morphosyntaxiques',\n",
              "  'arabe'],\n",
              " ['similarité',\n",
              "  'textuelle',\n",
              "  'analyse',\n",
              "  'conversation',\n",
              "  'représentation',\n",
              "  'sémantique',\n",
              "  'sémantique',\n",
              "  'distributionnelle',\n",
              "  'distance',\n",
              "  'wasserstein'],\n",
              " ['résolution', 'coréférences', 'réseau', 'neurone', 'modèle', 'bout', 'bout'],\n",
              " ['obsecro',\n",
              "  'livre',\n",
              "  'heure',\n",
              "  'réutilisation',\n",
              "  'texte',\n",
              "  'variante',\n",
              "  'textuelles'],\n",
              " ['annotation', 'alsacien', 'occitan', 'universal', 'dependencies'],\n",
              " ['diachronie', 'plongement', 'lexicaux', 'analyse', 'bilingue'],\n",
              " ['plongement', 'lexicaux', 'réseau', 'complexe', 'détection', 'communauté'],\n",
              " ['désambiguïsation',\n",
              "  'lexicale',\n",
              "  'compression',\n",
              "  'vocabulaire',\n",
              "  'relation',\n",
              "  'sémantique'],\n",
              " ['corpus',\n",
              "  'clinique',\n",
              "  'clinique',\n",
              "  'annotation',\n",
              "  'catégorisation',\n",
              "  'extraction',\n",
              "  'information'],\n",
              " ['curriculum',\n",
              "  'apprentissage',\n",
              "  'transfert',\n",
              "  'apprentissage',\n",
              "  'bout',\n",
              "  'bout',\n",
              "  'extraction',\n",
              "  'concept',\n",
              "  'sémantique',\n",
              "  'entité',\n",
              "  'nommées'],\n",
              " ['ellipse', 'anglais', 'corpus', 'titre', 'détection', 'automatique'],\n",
              " ['génération',\n",
              "  'poésie',\n",
              "  'réseau',\n",
              "  'neurone',\n",
              "  'factorisation',\n",
              "  'matrice',\n",
              "  'négative'],\n",
              " ['réseau', 'neuronaux', 'modélisation', 'séquence', 'media', 'tiger'],\n",
              " ['expression', 'polylexicales', 'vebales', 'niveau', 'cecr', 'didactique']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7M-PP9C-RWf",
        "outputId": "15ef15c0-e149-44fa-b968-1ad681431bde"
      },
      "source": [
        "doLDA(words.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.002*\"dicovalence\" + 0.002*\"répétés\" + 0.002*\"empiriques\" + 0.002*\"jeu\"'), (1, '0.002*\"négation\" + 0.002*\"world\" + 0.002*\"extension\" + 0.002*\"tourisme\"')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.ldamodel.LdaModel at 0x7efe0411d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALiHMVd2-Dq"
      },
      "source": [
        "Transformers est une librairie qui utilise huggingface dans un environnement pytorch et tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R02wjiLcH3y",
        "outputId": "180d8e42-22df-4b52-ca10-401e9ee9d3a8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fa8bb40f6fe39ec1b054ab2f2c4f2fbcf96ef36f59afdce5564b7e061e7e9f89\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_7wEr-e3IOL"
      },
      "source": [
        "T5-base est un modèle encodeur décodeur entrainé sur des articles de presse,  il est capable de faire des résumés en prédisant à partir d'une séquence de représentation vectorielle d'une chaine de caractère une autre chaine plus petite. Sa capacité d'entrée est limité à 512 vecteurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "8a7436a844814321bec9efa9e75dddee",
            "6597aae9b50540d591d327d811140fe6",
            "ed160c828f7a45a6a21f017a0d3ff2dd",
            "c3a9805861074e85935bdc96f27308b2",
            "d00200ac39344a45bb4b13627e2415f5",
            "092cd69131e94e01a33869984d252490",
            "bc338c906c874f06ae79f192002690d2",
            "5c5c44d482814afeb6646e29f67ec4bf",
            "c13a796deb324ee5ab0517cfd9a67504",
            "662cf31735914c66a58e446f42f33a44",
            "015a6f5cdd2b40779560d911ae011a5b",
            "cc598a4ab9954c10979dd8704c0c64fe",
            "acc88fb05ab04cf58bd75d98ac4399e5",
            "f9d3f0f543ac40929ad82574955fb23f",
            "5149f97423974c5faa37fb19ab5ad650",
            "f0bfd2a76bcb45fabddba532ec553ae9",
            "7460571df65d4f6d976e6ad48b63e04a",
            "9c448466034c433ea0866e952be3ccb5",
            "06dc4f869fad46aa938042f1de1b536a",
            "389fc01fc08c46e6b30b27a60b44ef79",
            "986812b32d65416ba26c688e3ecbbe72",
            "5bbcdb4bcaeb4f8f9fd8fd8718a596b4",
            "bea411c3581b4eabb275826ddb052f2a",
            "2283e7654ee24404a56299462250b25e",
            "2a9e88b138e140578d81958edd8987c8",
            "78d775a25b404be5a76bffa9a101cac6",
            "7bb99946316e45bea265e0ff1641f329",
            "e6103afe0cc5478aa35e4ad92271f8fa",
            "79110aefc6994d6c9fa8f31991b600e5",
            "f82d5814f7c0414cb114a278e45956a0",
            "65a942425ee24c30a4c8f2c2ce1615a9",
            "ba06178a696249aea502f550eda4aad8"
          ]
        },
        "id": "gxlI-JaEc7AH",
        "outputId": "80fdcee8-7a46-49b2-8db7-046bb94c38fa"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a7436a844814321bec9efa9e75dddee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c13a796deb324ee5ab0517cfd9a67504",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7460571df65d4f6d976e6ad48b63e04a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9e88b138e140578d81958edd8987c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMV4xwl3kqt"
      },
      "source": [
        "Avec cette fonction je transforme ma liste de résumé d'article du corpus en liste des résumés concaténés s'ils font moins de 512 mots ensemble.\n",
        "Ceux qui font plus de 512 mots sont ajoutés à la liste immédiatement, ils seront tronqué par le modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1JqHtF8Un5J"
      },
      "source": [
        "def Make_Data_For_T5(text_list,token_func):\n",
        "  text_for_model = []\n",
        "  holder = ''\n",
        "  for i in range(len(text_list)):\n",
        "    if len(token_func.encode(text_list[i]))>512:\n",
        "      text_for_model.append(text_list[i])\n",
        "    else:\n",
        "      if len(token_func.encode(holder))+len(token_func.encode(text_list[i]))>512:\n",
        "        text_for_model.append(holder)\n",
        "        holder = ''\n",
        "      else:\n",
        "        holder += text_list[i]\n",
        "  return text_for_model\n",
        "text_for_model = Make_Data_For_T5(abstracts,tokenizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Tl_EuhacQP",
        "outputId": "f46d48a6-db2d-4e89-b3b6-4068e09e0ac4"
      },
      "source": [
        "len(text_for_model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KaYX7oJXx6K"
      },
      "source": [
        "summaries = []\n",
        "for i in text_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOh-KjwraJ3k",
        "outputId": "a7a472e7-d63f-4e5e-b2a5-e2e4dd261faa"
      },
      "source": [
        "summaries_for_model = Make_Data_For_T5(summaries,tokenizer)\n",
        "summaries_for_model = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' à en proposer des illustrations sous forme de séquences fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modèle de la Grammaire Applicative et Cognitive [DES 90] qui vise à \"expliquer\", à un certain niveau cognitif, les transferts entre représentations imagées et verbales.</s> d\\'analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un véritable formalisme linguistique. Nous présentons ici un aperçu du logiciel DECID développé au GETA afin d\\'informatiser le processus de rédaction du dictionnaire explicatif et combinatoire français contemporain.</s> dans le contexte des approches à base de grammaires faiblement sensibles au contexte, cette contribution passe en revue le problème de l\\'extraction de l\\'arbre d\\'analyse le plus probable au sens de Data-Oriented Parsing (DOP). Une démonstration formelle de l\\'utilisabilité des méthodes de Monte-Carlo est donnée, puis une technique d\\'échantillonnage contrôlée est développée per</s> l\\'ordre d\\'intervention de ces deux couches dans le processus d\\'analyse est déterminé par l\\'occurrence de marques de surface qui indiquent la présence d\\'une distorsion ou d\\'une construction particulière (interrogative, relative, etc.). La première version de l\\'analyseur nous a fourni des résultats encourageants qui nous invitent à reconsidérer le rôle et l\\'utilité des ressources linguistiques développées pour le traitement</s> reclasser les mots représentés sur la base de leurs contraintes syntaxiques-sémantiques ; il faut ensuite reclasser les mots représentés sur la base de leurs contraintes syntaxiques-sémantiques ; il faut ensuite reclasser ces mots sur la base de leurs contraintes syntaxiques-sémantiques.</s>',\n",
              " \" On parle souvent de chemins et de trajectoires, mais on ne les exprime pas dans le temps. La localisation exprime alors un certain nombre de relations entre une entité à localiser et des sites, tandis que le déplacement exprime un changement de ces relations dans le temps.</s> des données de grande taille. Nous présentons en détail la métrique Précision-Décision qui a été développée dans le cadre de GRACE pour mesurer quantitativement les performances des systèmes d'étiquetage.</s> linguistique informatique. une des recherches de pointe menées actuellement en informatique est l'extraction des connaissances dans un texte électronique (textual data mining). Nous présentons dans cet article un modèle hybride, à la fois robuste et fin, qui s'inspire des modèles neuronaux et de l'analyse linguistique informatique.</s> automatique de textes écrits.. un langage de représentation sémantico-cognitive des verbes. Cette communication décrit un outil informatique de construction et de consultation du lexique verbal. Cette communication ne présente pas de dictionnaire mais développe une méthodologie de construction et de consultation du lexique verbal.</s> les familles de mots morphologiquement reliés que nous avons obtenues sont correctes à 95 %. Nous proposons une méthode simple et puissante pour améliorer le processus d'acquisition automatique du langage médical.</s>. Or les cognats sont généralement captés au moyen d'une approximation abrupte, de nature opératoire. Nous avons ensuite essayé de développer un filtrage plus efficace, basé sur une méthode générale développée par nous.</s> d'une méthodologie précise. <unk> partir de l'arborescence sont constitués les groupes intonatifs, tout en tenant compte du rythme. Dans certains cas, des modifications de la structure syntaxique sont effectuées.</s>\",\n",
              " \" Nous présentons ici une implémentation de cette méthode de correction.Nous présentons dans ce document le problème de la détection et de la correction des graphies fautives dans les textes arabes. Nous présentons brièvement les principaux résultats obtenus à ce jour dans le cadre du projet MAREDI.</s> des connaissances langagières pré-codées. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux.Notre étude propose un modèle cohérent pour formaliser la modalité en tant que module interlingua d'un système de traduction automatique (TA).</s> une grammaire d'arbres adjoints compactée et sur la mise en concurrence des différentes hypothèses du système de reconnaissance de la parole. Nous présentons une stratégie d'analyse robuste dans le but de relayer la décision d'un système de reconnaissance de la parole.</s> n'est pas un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une pratique dans laquelle il faut tenir compte de plus en plus de chercheurs, qu'ils soient linguistes ou informaticiens.</s> sémantique. sémantique, il s'agit d'une requête orale. Si le dialogue est finalisé, cette requête nécessite une analyse linguistique plus fine que celle utilisée dans les applications classiques de CHM1.</s> grammaire, grammaire de propriétés, relation de dépendance, grammaire formelle, grammaire de dépendance, lexieparadigme d'évaluation, campagne d'évaluation, lexieparadigme d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation, campagne d'évaluation</s>\",\n",
              " \" syntaxique partielle, grammaires de dépendances, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de parole, longueur, fréquence lexicale, aide à la compréhension, lecture, spontané, débit de</s> langage stochastique. Les modèles de langage stochastiques favorisent l'interprétation d'un signal par les phrases les plus courtes possibles, celles-ci étant par construction souvent affectées par les coûts les plus bas.</s> il n'a jamais fait recette auprès des littéraires, des psycho-socios, des sémio-machins, des politiques et des pouvoirs académiques dont tout le monde a oublié sur quelles complicités exactes ils se fondaient. Il n'a jamais fait recette auprès des littéraires, des psycho-socios, des sémio-machins, des politiques et des pouvoirs </s> sémantique lexicaleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, Sémantique ProcéduraleAnalyse Distribuée, Micro-Systèmes, S</s> linguistique. linguistique, sémantique, etc. Nous présentons dans cet article un cadre d'explication des relations entre les différentes composantes de l'analyse linguistique (prosodie, syntaxe, sémantique, etc.). Cette approche permet d'expliquer certains phénomènes de variabilité dans des applications comme les systèmes de synthèse de parole.</s>\",\n",
              " \" d'information, e-mail, réseaux de neurones, apprentissage, spamAnalyse syntaxique, Robustesse d'analyse, HPSG, système multi-agent, AgentBuilderAnalyse, Robustesse d'analyse, HPSG, système multi-agent, AgentBuilderAnalyse, Robustesse d'analyse, HPSG, système multi-agent, AgentBuilderAnalyse,</s> linéaire, l'analyse syntaxique, l'analyse de corpus, annotation de corpus, filtrage automatique de textesSystème de question-réponse, recherche d'information, fiabilité des réponsesQuestions-réponses, l'analyse syntaxique, ressources lexicales, LTAG, représentation compacte du lexiqueDésambigu<unk>sation sémantique, arbres de classification sémantiqueDiscours</s> linguistique. Ce document fournit des éléments d'explication pour la description des relations entre les différents domaines de l'analyse linguistique. Il fournit des éléments d'explication pour la description des relations entre les différents domaines linguistiques.</s> traduction automatique de la langue, traduction automatique de la langue, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lex</s>\",\n",
              " \" sémantiques, patrons lexico-syntaxiquesAnonymisation, désidentification, reconnaissance d'entités nommées, textes juridiquesAnonymisation, désidentification, reconnaissance d'entités nommées, textes juridiquesAnonymisation, désidentification, reconnaissance d'entités nommées, textes juridiquesAnonymisation, désidentification, reconnaissance d'entités nommées, textes juridiquesAnonym</s> d'intervalles (RCG)Traduction de dialogue, évaluation subjective et objective de composants de TALNReprésentation des structures discursives, langage de représentation des connaissances linguistiques, n-gramme, chunksApprentissage partiel, inférence grammaticale, grammaire catégoriellesformalisme grammatical, interface syntaxe-sémantique, sous-spécification, polaritésGrammaires</s> sémantique, Décodage phonétique, Classifieur, réseaux de neuronesLinguistique, indexation, recherche d'information, statistiqueSynthèse de la parole arabe, Phonèmes, Diphones, Triphones, Unités acoustiques, Dictionnaire de polyphonesAlignement, corpus parallèles, analyse morphologique japonaise partielle, mémoire de traductionCorpus, jeu d'étiquettes, É</s>, apprentissage en linguistique textuelle, homographes, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage</s>\",\n",
              " \" linguistique, apprentissage automatique de termes, terminologie biomédicale, apprentissage artificiel, inférence de transducteurs, analyse syntaxiqueSegmentation automatique de termes, terminologie biomédicale, apprentissage artificiel, inférence de transducteurs, analyse syntaxiqueSegmentation automatique de termes, terminologie biomédicale, apprentissage artificiel, inférence de transducteurs, analyse syntaxique,</s> d'un ensemble de règles, chaînage de règles, géométrie spatiale, géométrie syntaxique, détection automatique d'informations évolutives, HPSG, Lexical Markup Framework, langage arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe, langue arabe,</s>, correcteur orthographique, correcteur grammatical, correcteur orthographique, correcteur grammatical, français, outils de correction linguistique, -Able, -ité, co-occurrences, correspondances, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co-occurrences, co</s> sémantique, classification automatique, classification linguistique, classification automatique, classification linguistique, classification linguistique, classification automatique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique, classification linguistique</s>\",\n",
              " \" d'information, representation de connaissances, biographies, entités nommées, représentation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation de connaissances, representation</s> traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur.</s> sémantique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, sémantique syntaxique, s</s> linguistique, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithmes d'apprentissage, algorithme</s>\",\n",
              " \" d'utilisation, langage finie à états, langage de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dérivation, arbre de dériv</s> sémantiques, indices syntaxiques, indices acoustiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, </s> en ligneDictionnaire électronique Arabe, usage éditorial, modèle normalisé, DécodageParaphrase, entités nommées, Analyse syntaxique, étiquetage morpho-syntaxique, terminologie médicale arabe, terminologie lexicale, unité lexicale, unité lexicale, unité lexicale, unité lexicale, unité lexicale, unité lexicale, </s> sémantique, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage évaluatif, langage</s>\",\n",
              " \" n-best candidats, pondérationLe modèle PLSI (« Probabilistic Latent semantic Indexing ») offre une approche de l'indexation de documents sémantiques latentes et a conduit à des applications dans divers domaines.</s> en fonctions grammaticalesfonctions syntaxiques, corpus bilingue, classification, taxonomieApache UIMA, Applications du TAL, Infrastructure logicielleApache UIMA, Applications du TAL, Infrastructure logicielleApache UIMA, Applications du TAL, Infrastructure logicielleApache UIMA, Applications du TAL, Infrastructure logicielleApache UIMA, Applications du TAL, Infrastructure logicielleApache UIMA, Applications du TAL, Infrastructure logicielle</s>, évaluation automatique, aire sous courbe ROC, évaluation automatique, évaluation automatique de textes subjectifs, aire sous courbe ROC, évaluation automatique de textes subjectifs, évaluation automatique, évaluation automatique de textes subjectifs, évaluation automatique, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs</s>, classification d'erreurs, classification d'entropie, analyseur syntaxiqueAnalyse syntaxique de surface, classification d'erreurs, déterminisme, désambigu<unk>sation lexicale, TerminologieMultimodalité, interaction entre domaines, grammaire, corpus monolingue parallèle, paraphrases, n-grammes, vecteurs de traits, analyse prédicative, étiquetage sémantique, psycholinguistique</s>\",\n",
              " \" sémantique d'information multi-lingue, traduction de requêtes, Wikipédia, ontologie multi-lingueLangue des signes, corpus vidéo comparables, Wikipédia, ontologie multi-lingue, traduction de requêtes, Wikipédia, ontologie multi-lingue, traduction de requêtes, Wikipédia, traduction automatique, traduction automatique</s>, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé</s> sémantiques, relations sémantiques, voisins distributionnelsExtraction d'information, extraction d'événements, segmentation thématique, documents oraux, cohésion lexicale, relations sémantiques, voisins distributionnelsExtraction d'information, extraction d'événements, segmentation thématique, organisation textuelle, relations sémantiques, voisins distributionnelsExtraction automatique de textes</s> ; Evaluation : métrique d'évaluation, constitution de référence, résumé de texte automatique, résumé extractif, statistiques de co-occurrence, collocations, analyse syntaxique, Wikipedia, INEX, entropie, classification d'information, ambigu<unk>té, classification de passages, enrichissement de requêtes, lexique dérivationnelRessources lexicales, familles morphologiques, clusters sémantiques, </s>\",\n",
              " ' terminologie, préterminologie, approches collaboratives, réseaux lexicaux, DSR, jeux sérieuxtraduction automatique statistique, analyse syntaxique, ambigu<unk>té pronominale, étiquetage morpho-syntaxique, structure textuelleAnalyseur syntaxique, traduction automatique, ambigu<unk>té pronominale, étiquetage morpho-syntaxique, structure textuelleAnalyseur syntaxique, traduction automatique,</s> Sentiments, Linguistique de Corpus, Dépêches FinancièresAnalyse de Sentiments, Linguistique de Corpus, Dépêches FinancièresAnalyse de Sentiments, Linguistique de Corpus, Dépêches FinancièresAnalyse de Sentiments, Linguistique de Corpus, Dépêches FinancièresAnalyse de Sentiments</s> linguistiques, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentalesÉtiqueteur, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentales, structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales,</s>, grammaires logiques, grammaires multimodales, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage, ancrage,</s>',\n",
              " ' apprentissage automatique, PDTB, RST, SDRTCombinaison de ressources, RI contextuelle, recherche webAdaptation non supervisée, Réconnaissance de la parole, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique, traduction automatique statistique</s> graphes, interface syntaxe-sémantique, interface sémantique-pragmatique, grammaire catégorielle, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique, apprentissage automatique,</s> graphe de cooccurrences, marche aléatoire, marche aléatoire, aide à la rédactionsimplification automatique, lisibilité, approche symbolique, approche numérique, approche hybride, aide à la rédactionsimplification automatique, lisibilité, aide à la rédactionsimplification automatique, lisibilité, aide à la rédaction, aide à la rédaction, aide à la rédaction, aide à la rédaction, aide à la</s> traducteurs, archives numériques, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique, articles scientifiques, ressources langagièresTALN Archives, archive numérique</s>',\n",
              " \" d'un corpus linguistique, langage sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, analyse sémantique, extraction d'information, recherche d'information, recherche d'information, recherche d</s>, apprentissage non-supervisé, extraction de connaissances, CRF, apprentissage non-supervisé, apprentissage non-supervisé, extraction de connaissances, CRF, apprentissage non-supervisé, extraction de connaissances, apprentissage non-supervisé, apprentissage non-supervisé, extraction de connaissances, apprentissage non-supervisé, extraction de connaissances, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé,</s>, lexique bilingue, lexique dynamique, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, Ontologie de domaine, On</s> terminologie, traduction terminologiqueTreebanks, langue arabe, langage hors-contexte, grammaire lexical, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques, espaces thématiques,</s>\",\n",
              " \" automatiséSystèmes de Dialogue, Traitement Incrémental, Architecture des Systèmes de Dialogue, Traitement automatiséSystèmes de Dialogue, Traitement automatisé, Architecture des Systèmes de Dialogue, Traitement automatisé, Architecture des Systèmes de Dialogue, Architecture des Systèmes de Dialogue, Architecture des Systèmes de Dialogue, Architecture des Systèmes de Dialogue,</s> corpus comparable, Corpus monolingue, Corpus annoté, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la comparabilité, Mesure de la</s> e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e</s> morphologie, arabe, metagrammaire, frame semanticsCorpus arboré, annotation en dépendances, dépendances non-projectivesAnalyse d'opinion, détection de l'ironie, apprentissage supervisédictionnaire, corpusMorphologie, arabe, métagrammaire, frame semanticsCorpus arboré, annotation en dépendances, dépendances non-projectivesAnalyse de sentiments associés</s> d'information, empreintes digitales textuelles, analyse syntaxique assistée par ordinateurYADTK est une plateforme ouverte pour développer des systèmes de dialogue oral.</s>\",\n",
              " \" sémantique, Indexation aléatoire, Wikipédia, Relation sémantiqueTypologie, syntaxe, treebank, inférence de grammaire, paramètres joints, redécodage de grapheAlignement multi-lingue, corpus parallèles, cognats.Entités nommées, désambigu<unk>sation, base de connaissancesMorphologie, Apprentissage non-supervisé, Modèles bayésiens non</s> sémantique, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexicale, classification lexica</s> sémantique, multilinguisme, transfert crosslingue, Analyse en dépendances, Annotations partielles.rhèse, chunk, apprentissage supervisé, alsacienMultilinguisme, transfert crosslingue, annotation sémantique, réseaux de neurones récurrents.traduction automatique du langage, flexion, verbes, variabilité graphique, Unitex, alsacienMultilinguisme, transfert crosslingu</s> sémantique.Réseaux neuronaux, apprentissage artificiel, étiquetage de séquences.Analyse numérique, extraction d'information, étiquetage par une ontologie, espace vectoriel, sémantique distributionnelle, modèle linéaire.Arabe, grammaire d'arbres adjoints, méta-grammaire, évaluation.Arabe, grammaire d'</s>\",\n",
              " \" ; Double validation croisée ; Information mutuelle.Ethique, science participative, crowdsourcing, alsacien, langues peu dotées.Classification automatique, Analyse de sentiments, transports, classification thématique.Tweets, fouille d'opinions, plongement de mots, réseaux de neurones récurrents, classification thématique.Tweets, fouille d'opinions, transports, classification automatique.</s> en phrases, domaine de spécialité, Spécification modale.Analyse du constituant, corpus arboré ; méta-grammaire ; interface syntaxe/sémantique ; étiquetage de rôles sémantiques, français.</s>. langue anglaise.Analyse de sentiment, dialecte tunisien, prétraitement de texte, entités nommées.traduction automatique ; japonais ; français.Analyse de sentiment, dialecte tunisien, prétraitement de texte, entités nommées.Analyse de sentiment, dialecte tunisien, prétraitement de texte, entités nommées.</s> apprentissage non supervisé.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments</s>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ira5OwgF6KY2"
      },
      "source": [
        "Résumé des résumés concentré, ce qui donne un petit paragraphe résumant le document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACE1Jb4R4Mk8"
      },
      "source": [
        "summaries_for_model_summarized = []\n",
        "for i in summaries_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries_for_model_summarized.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn-iJxSS8Rii",
        "outputId": "b81ffff7-e2f3-4f20-e856-28f6f0829e66"
      },
      "source": [
        "summaries_for_model_summarized = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" dans le contexte d'approches linguistiques faiblement sensibles, cette contribution passe en revue le problème de l'extraction de l'arbre d'analyse linguistique.</s>\",\n",
              " \" d'une méthodologie de construction et de consultation du lexique verbal. Cette communication décrit en détail un outil informatique de construction et de consultation du lexique verbal. Cette méthodologie a été développée dans le cadre de GRACE.</s>\",\n",
              " \" n'est pas un jeu de mots gratuit, mais bien la nécessité de soumettre à l'examen une méthode de correction linguistique plus fine que celle utilisée dans les applications classiques de CHM1.</s>\",\n",
              " \" linguistique, sémantique, etc.) n'a jamais fait recette auprès des littéraires, des psycho-socios, des politiques et des pouvoirs dont tout le monde a oublié sur quelles complices exactes ils se fondaient.</s>\",\n",
              " ' Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique.</s>',\n",
              " \" et d'intervalles (RCG)Traduction de dialogue, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage </s>\",\n",
              " ' orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique,</s>',\n",
              " ' ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par ordinateur, traduction assistée par</s>',\n",
              " ' syntaxique, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, </s>',\n",
              " \", classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification syntaxique, évaluation automatique, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, évaluation automatique de textes subjectifs, </s>\",\n",
              " ', apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé, apprentissage non-supervisé</s>',\n",
              " ' linguistiques, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentalesÉtiqueteur, apprentissage de langues, production de langage, livres de phrases, patrons, schéma de phrase, structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales</s>',\n",
              " ', approche numérique, approche hybride, approche symbolique, approche numérique, approche hybride, approche numérique, approche hybride, approche symbolique, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche numérique, approche hybride, approche</s>',\n",
              " ' terminologie, traduction terminologique, traduction bilingue, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduc</s>',\n",
              " ', e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, </s>',\n",
              " \", Relation sémantique.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire.Arabe, grammaire d'arbres adjoints, méta-grammaire</s>\",\n",
              " ' langue anglaise.Analyse de sentiment, dialecte tunisien, prétraitement de texte, entités nommées.Analyse de sentiment au niveau des aspects, ressources sémantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sémantiques, traduction.</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8FJBA2g_QOH"
      },
      "source": [
        "Ecriture des fichiers de résultats dans le stockage en ligne, pour conserver les résultats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCONf9D1HEW"
      },
      "source": [
        "MyFile=open('T5-base_summaries.txt','w')\n",
        "\n",
        "for element in summaries:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_model.txt','w')\n",
        "\n",
        "for element in summaries_for_model:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_summaries.txt','w')\n",
        "\n",
        "for element in summaries_for_model_summarized:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "!cp T5-base_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_model.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgogffNg_blg"
      },
      "source": [
        "J'ai essayé beaucoup de méthode, et regardé et lu beaucoup de document, notamment sur huggingface et transformers.\n",
        "J'ai préféré ces méthodes à celle de modèle keras avec des couches lstm car je n'étais vraiment pas convaincue par les performances de cette technique lors de la séance sur la génération de texte.\n",
        "La LDA ne fournissait pas également de résultat des plus explicites et pertinents à mon gout, j'ai donc délaisser ces méthodes pour la structure encodeur décodeur fourni par transformers.\n",
        "J'ai essayé d'utilisé un modèle prométeur par facebook, mais celui ne marchais pas, du fait du nom différent d'un attribut, la fonction generate ne pouvait récupérer l'encodeur du modèle ce qui provoquais une erreur arrétant l'éxecution du programme.\n",
        "\n",
        "\n",
        "\n",
        "La méthode que j'ai ici dévellopé consiste à résumer les résumés d'article concaténé pour ensuite concaténé et résumer à nouveau ces résumés.\n",
        "En ayant lû le contenu final, il touche bien aux différent principe du NLP et aborde les grands axes et les grandes méthodes de ce domaine, donnant un vue globale du contenu du corpus."
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a7436a844814321bec9efa9e75dddee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6597aae9b50540d591d327d811140fe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed160c828f7a45a6a21f017a0d3ff2dd",
              "IPY_MODEL_c3a9805861074e85935bdc96f27308b2"
            ]
          }
        },
        "6597aae9b50540d591d327d811140fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed160c828f7a45a6a21f017a0d3ff2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00200ac39344a45bb4b13627e2415f5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_092cd69131e94e01a33869984d252490"
          }
        },
        "c3a9805861074e85935bdc96f27308b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc338c906c874f06ae79f192002690d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:12&lt;00:00, 98.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c5c44d482814afeb6646e29f67ec4bf"
          }
        },
        "d00200ac39344a45bb4b13627e2415f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "092cd69131e94e01a33869984d252490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc338c906c874f06ae79f192002690d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c5c44d482814afeb6646e29f67ec4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c13a796deb324ee5ab0517cfd9a67504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_662cf31735914c66a58e446f42f33a44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_015a6f5cdd2b40779560d911ae011a5b",
              "IPY_MODEL_cc598a4ab9954c10979dd8704c0c64fe"
            ]
          }
        },
        "662cf31735914c66a58e446f42f33a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "015a6f5cdd2b40779560d911ae011a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acc88fb05ab04cf58bd75d98ac4399e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d3f0f543ac40929ad82574955fb23f"
          }
        },
        "cc598a4ab9954c10979dd8704c0c64fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5149f97423974c5faa37fb19ab5ad650",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:11&lt;00:00, 76.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0bfd2a76bcb45fabddba532ec553ae9"
          }
        },
        "acc88fb05ab04cf58bd75d98ac4399e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d3f0f543ac40929ad82574955fb23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5149f97423974c5faa37fb19ab5ad650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0bfd2a76bcb45fabddba532ec553ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7460571df65d4f6d976e6ad48b63e04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c448466034c433ea0866e952be3ccb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06dc4f869fad46aa938042f1de1b536a",
              "IPY_MODEL_389fc01fc08c46e6b30b27a60b44ef79"
            ]
          }
        },
        "9c448466034c433ea0866e952be3ccb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06dc4f869fad46aa938042f1de1b536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_986812b32d65416ba26c688e3ecbbe72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bbcdb4bcaeb4f8f9fd8fd8718a596b4"
          }
        },
        "389fc01fc08c46e6b30b27a60b44ef79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bea411c3581b4eabb275826ddb052f2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:03&lt;00:00, 257kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2283e7654ee24404a56299462250b25e"
          }
        },
        "986812b32d65416ba26c688e3ecbbe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bbcdb4bcaeb4f8f9fd8fd8718a596b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea411c3581b4eabb275826ddb052f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2283e7654ee24404a56299462250b25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9e88b138e140578d81958edd8987c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78d775a25b404be5a76bffa9a101cac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bb99946316e45bea265e0ff1641f329",
              "IPY_MODEL_e6103afe0cc5478aa35e4ad92271f8fa"
            ]
          }
        },
        "78d775a25b404be5a76bffa9a101cac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bb99946316e45bea265e0ff1641f329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79110aefc6994d6c9fa8f31991b600e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f82d5814f7c0414cb114a278e45956a0"
          }
        },
        "e6103afe0cc5478aa35e4ad92271f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65a942425ee24c30a4c8f2c2ce1615a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:02&lt;00:00, 470kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba06178a696249aea502f550eda4aad8"
          }
        },
        "79110aefc6994d6c9fa8f31991b600e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f82d5814f7c0414cb114a278e45956a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65a942425ee24c30a4c8f2c2ce1615a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba06178a696249aea502f550eda4aad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUNiu36r0au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396c89db-473d-4c80-ae39-0a8d15eb0c32"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq4hrow7mo4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1af92456-975f-456a-aec1-dbf2da384a9b"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tree = ET.parse(\"/content/drive/MyDrive/datasets/NLP/corpus_taln_v1.tei.xml\") #L'XML du corpus taln est Ã  insÃ©rer ici.\n",
        "root = tree.getroot()\n",
        "ns = re.findall(\"{.*}\", root.tag)[0] #Le nom de domaine XML du corpus.\n",
        "ns \n",
        "# {http://www.tei-c.org/ns/1.0}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{http://www.tei-c.org/ns/1.0}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACeRMuSyAjpj"
      },
      "source": [
        "Dans la fonction get_abstracts j'utilise la librairie xml elementtree comme conseillÃ© dans le sujet du projet 1 pour :\n",
        "\n",
        "1.   itÃ©rer sur les balises des articles \"TEI\" qui contiennent dans leur attribut de valise le mot clÃ© \"fr\" qui signifie que l'article est en franÃ§ais,\n",
        "\n",
        "2.   naviguer Ã  la balise div de l'entÃªte de l'article qui contient les rÃ©sumÃ©s dont je rÃ©cupÃ¨re la version en franÃ§ais si elle existe et est diffÃ©rente de \"None\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcG_YlEUI0ci"
      },
      "source": [
        "def Get_Abstracts(tree, size=None):\n",
        "  abstract = []\n",
        "  text = ''\n",
        "  tei = root.iter(ns+\"TEI\") #ItÃ©rateur sur les balises 'TEI' qui correspondent aux articles.\n",
        "  if size == None:\n",
        "    size = root.iter(ns+\"TEI\")\n",
        "  else:\n",
        "    size = range(size)\n",
        "  for i in size:\n",
        "    try:\n",
        "      x = tei.__next__()\n",
        "      if any(\"fr\" in s for s in x.attrib.values()):\n",
        "        for y in x.iter(ns+\"div\"):\n",
        "          if any(\"fr\" in s for s in y.attrib.values()):\n",
        "            for p in y.iter(ns+\"p\"):\n",
        "              if p.text != \"None\":\n",
        "                text = p.text.strip().replace('\\n\\t','') #Nettoyage de ce qui dÃ©borde dans les abstracts avec la fonction strip() et effacement des caractÃ¨res de saut Ã  la ligne prÃ©sent dans la chaine de caractÃ¨re brute.\n",
        "        if len(text) != 0:\n",
        "          abstract.append(text)\n",
        "    except:\n",
        "      break\n",
        "  return abstract"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_TiOui8L-p",
        "outputId": "9dd75606-acc6-4469-abfe-143ac61b3aa7"
      },
      "source": [
        "abstracts = Get_Abstracts(root)\n",
        "abstracts[0:5]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nous considÃ©rons dans notre travail la tÃ¢che du traitement automatique visant Ã  construire, Ã  partir de textes issus d\\'un corpus de constats d\\'accidents de la route, des interprÃ©tations compatibles avec ces derniers, et Ã  en proposer des illustrations sous forme de sÃ©quences d\\'images fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modÃ¨le de la Grammaire Applicative et Cognitive [DES 90], qui vise en particulier Ã  \"expliquer\", Ã  un certain niveau cognitif, les transferts entre reprÃ©sentations imagÃ©es et verbales. Pour une revue de la question relative Ã  la \"transcription automatique Verbal-Image\", nous renvoyons Ã  [ARN 90] ; et plus particuliÃ¨rement aux travaux de C. Vandeloise [VAN 87] et du groupe \"Langue, Raisonnement, Calcul\" de l\\'UniversitÃ© Paul Sabatier [AUR 90, SAB 95] ainsi qu\\'aux approches proposÃ©es dans [ARN 93] et dans le systÃ¨me SPRINT [YAM 92]. Plus proches encore de nos prÃ©occupations, B. Victorri et P. Enjalbert [ENJ 94, POI 95] posent le problÃ¨me de l\\'animation visuelle issue de l\\'interprÃ©tation de textes. Nous prÃ©sentons dans cet article, Ã  travers le traitement d\\'un exemple, la mÃ©thode gÃ©nÃ©rale d\\'analyse que nous avons adoptÃ©e, qui s\\'appuie en prioritÃ© sur des connaissances linguistiques. Le texte pris comme exemple est le suivant : Je roulais sur la partie droite de la chaussÃ©e quand un vÃ©hicule arrivant dans le virage a Ã©tÃ© complÃ¨tement dÃ©portÃ©. Serrant Ã  droite au maximum, je n\\'ai [pu] Ã©viter la voiture [qui arrivait Ã  grande vitesse]. Nous ne traitons pas ici la modalitÃ© introduite par pu , de mÃªme que la relative qui arrivait Ã  grande vitesse. Dans la premiÃ¨re partie de l\\'article, nous prÃ©sentons l\\'architecture globale du systÃ¨me informatique. Dans la deuxiÃ¨me partie, nous proposons des Ã©lÃ©ments d\\'analyse pour une solution opÃ©ratoire aux problÃ¨mes d\\'articulation des significations lexicales et grammaticales, sous forme d\\'une segmentation du texte en diffÃ©rentes phases spatio-temporelles. Dans la troisiÃ¨me partie, nous prÃ©sentons une modÃ©lisation des lieux de circulation et du mouvement des vÃ©hicules garantissant le passage Ã  l\\'image.',\n",
              " \"Nous donnons ici un aperÃ§u du logiciel DECID dÃ©veloppÃ© au GETA afin d'informatiser le processus de rÃ©daction du dictionnaire explicatif et combinatoire du franÃ§ais contemporain.\",\n",
              " 'Diverses mÃ©thodes ont Ã©tÃ© proposÃ©es pour construire un \"graphe conceptuel\" reprÃ©sentant le \"sens\" d\\'une phrase Ã  partir de son analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un vÃ©ritable formalisme linguistique. Nous nous intÃ©ressons ici Ã  la construction d\\'une telle reprÃ©sentation sÃ©mantique Ã  partir de la reprÃ©sentation syntaxique produite par une analyse LFG, et montrons comment une transposition du \"joint dirigÃ©\" des graphes conceptuels permet d\\'effectuer cette construction Ã  partir de la \"structure sÃ©mantique \"des LFG.',\n",
              " \"Le terme de lambda-DRT dÃ©signe un ensemble de mÃ©thodes permettant de construire des reprÃ©sentations sÃ©mantiques (DRS) Ã  partir d'arbres syntaxiques. La mise en oeuvre de telles mÃ©thodes nÃ©cessite l'Ã©laboration de systÃ¨mes de types dont le dÃ©tail est rarement prÃ©sentÃ©. C'est Ã  la description d'un tel systÃ¨me que cet article est consacrÃ©.\",\n",
              " \"Dans cet article, nous comparons deux modÃ¨les linguistiques utilisÃ©s en TAL, les grammaires d'arbres adjoints [= TAG] et le ThÃ©orie Sens-Texte [= TST]. Nous montrons que ces deux modÃ¨les prÃ©sentent des similitudes notables, et que les reprÃ©sentations les plus abstraites qu'ils donnent d'une phrase â€” la reprÃ©sentation sÃ©mantique en TST et l'arbre de dÃ©rivation en TAG â€” sont Ã©quivalentes. De ce rapprochement dÃ©coule d'une part que l'on peut s'inspirer de la procÃ©dure de dÃ©rivation TAG pour opÃ©rer la correspondance Sens-Texte, et d'autre part que l'on peut concevoir une grammaire TAG comme le rÃ©sultat de la prÃ©compilation d'une grammaire Sens-Texte.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzDZxsVA_jeU"
      },
      "source": [
        "J'utilise la librairie disponible Ã  ce [lien](https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer) qui permet la lÃ©mmatisation des mots franÃ§ais en se basant sur des ressources acadÃ©miques du [Lexique des Formes FlÃ©chies du FranÃ§ais](http://pauillac.inria.fr/~sagot/index.html#lefff).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Km3jBUiDOu",
        "outputId": "cfa80c37-d3de-4762-c8f2-c5310443f1f3"
      },
      "source": [
        "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
            "  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-6amagics\n",
            "  Running command git clone -q https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-6amagics\n",
            "Building wheels for collected packages: FrenchLefffLemmatizer\n",
            "  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-cp36-none-any.whl size=3533520 sha256=8ebef7656ab2fd981ad3f26236a959ddcaff9e17b98157607361fa92f5923bcf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wkxmwa3o/wheels/95/b7/c0/e249ca2690c04f6106b9581c5e4111287f71dbd85bac903445\n",
            "Successfully built FrenchLefffLemmatizer\n",
            "Installing collected packages: FrenchLefffLemmatizer\n",
            "Successfully installed FrenchLefffLemmatizer-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gY--5Dk4bj"
      },
      "source": [
        "Les abstracts doivent Ãªtre nettoyer et Ã©purer des mots d'arrÃªt basique comme prÃ©traitement avant de faire le tf-idf, je procÃ¨de Ã  ces Ã©tapes :\n",
        "\n",
        "\n",
        "1.   SÃ©paration des rÃ©sumÃ©s en token avec la fonction regex de tokÃ©nisation de nltk,\n",
        "\n",
        "2.   Utilisisation de la liste de mots d'arrÃªt de meilleure qualitÃ© que celle de nltk trouvÃ© [ici](https://github.com/cmchurch/nltk_french/blob/master/french-nltk.py) dans la fonction \"get_stopswords\",\n",
        "\n",
        "3.   Comme en travaux pratiques dirigÃ©s, le texte est mis en miniscule avec .lower(), a notÃ© que la double boucle est dÃ» Ã  des prÃ©cÃ©dentes mÃ©thodes que j'ai utilisÃ© et qui ont donnÃ© la forme peut pratique d'une liste de liste, ainsi il est nÃ©cessaire pour accÃ©der aux chaines de caractÃ¨res de faire deux fois des for x ~ in y\n",
        "\n",
        "4.   J'utilise ensuite la fonctionnalitÃ© de python sur la gÃ©nÃ©ration de liste avec opÃ©ration sur chaque Ã©lement pour retirer les mots d'arrÃªt simples puis tous les nombres et mots courts de trois lettres ou moins,\n",
        "\n",
        "5. Pour finir j'utilise la librairie rÃ©fÃ©rencer plus haut pour lemmatiser la liste de mots d'arrÃªt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP40M-7zagOv"
      },
      "source": [
        "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora, models\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  lemmatizer = FrenchLefffLemmatizer()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  fr_stop = [\"Ap.\", \"Apr.\", \"GHz\", \"MHz\", \"USD\", \"a\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ait\", \"alors\", \"aprÃ¨s\", \"as\", \"attendu\", \"au\", \"au-delÃ \", \"au-devant\", \"aucun\", \"aucune\", \"audit\", \"auprÃ¨s\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\", \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autour\", \"autre\", \"autres\", \"autrui\", \"aux\", \"auxdites\", \"auxdits\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\", \"aviez\", \"avions\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"banco\", \"ben\", \"bien\", \"bÃ©\", \"c\", \"c'\", \"c'est\", \"c'Ã©tait\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-lÃ \", \"celles\", \"celles-ci\", \"celles-lÃ \", \"celui\", \"celui-ci\", \"celui-lÃ \", \"celÃ \", \"cent\", \"cents\", \"cependant\", \"certain\", \"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-lÃ \", \"cf.\", \"cg\", \"cgr\", \"chacun\", \"chacune\", \"chaque\", \"chez\", \"ci\", \"cinq\", \"cinquante\", \"cinquante-cinq\", \"cinquante-deux\", \"cinquante-et-un\", \"cinquante-huit\", \"cinquante-neuf\", \"cinquante-quatre\", \"cinquante-sept\", \"cinquante-six\", \"cinquante-trois\", \"cl\", \"cm\", \"cmÂ²\", \"comme\", \"contre\", \"d\", \"d'\", \"d'aprÃ¨s\", \"d'un\", \"d'une\", \"dans\", \"de\", \"depuis\", \"derriÃ¨re\", \"des\", \"desdites\", \"desdits\", \"desquelles\", \"desquels\", \"deux\", \"devant\", \"devers\", \"dg\", \"diffÃ©rentes\", \"diffÃ©rents\", \"divers\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dl\", \"dm\", \"donc\", \"dont\", \"douze\", \"du\", \"dudit\", \"duquel\", \"durant\", \"dÃ¨s\", \"dÃ©jÃ \", \"e\", \"eh\", \"elle\", \"elles\", \"en\", \"en-dehors\", \"encore\", \"enfin\", \"entre\", \"envers\", \"es\", \"est\", \"et\", \"eu\", \"eue\", \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eÃ»mes\", \"eÃ»t\", \"eÃ»tes\", \"f\", \"fait\", \"fi\", \"flac\", \"fors\", \"furent\", \"fus\", \"fusse\", \"fussent\", \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"fÃ»mes\", \"fÃ»t\", \"fÃ»tes\", \"g\", \"gr\", \"h\", \"ha\", \"han\", \"hein\", \"hem\", \"heu\", \"hg\", \"hl\", \"hm\", \"hmÂ³\", \"holÃ \", \"hop\", \"hormis\", \"hors\", \"huit\", \"hum\", \"hÃ©\", \"i\", \"ici\", \"il\", \"ils\", \"j\", \"j'\", \"j'ai\", \"j'avais\", \"j'Ã©tais\", \"jamais\", \"je\", \"jusqu'\", \"jusqu'au\", \"jusqu'aux\", \"jusqu'Ã \", \"jusque\", \"k\", \"kg\", \"km\", \"kmÂ²\", \"l\", \"l'\", \"l'autre\", \"l'on\", \"l'un\", \"l'une\", \"la\", \"laquelle\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lez\", \"lors\", \"lorsqu'\", \"lorsque\", \"lui\", \"lÃ¨s\", \"m\", \"m'\", \"ma\", \"maint\", \"mainte\", \"maintes\", \"maints\", \"mais\", \"malgrÃ©\", \"me\", \"mes\", \"mg\", \"mgr\", \"mil\", \"mille\", \"milliards\", \"millions\", \"ml\", \"mm\", \"mmÂ²\", \"moi\", \"moins\", \"mon\", \"moyennant\", \"mt\", \"mÂ²\", \"mÂ³\", \"mÃªme\", \"mÃªmes\", \"n\", \"n'avait\", \"n'y\", \"ne\", \"neuf\", \"ni\", \"non\", \"nonante\", \"nonobstant\", \"nos\", \"notre\", \"nous\", \"nul\", \"nulle\", \"nÂº\", \"nÃ©anmoins\", \"o\", \"octante\", \"oh\", \"on\", \"ont\", \"onze\", \"or\", \"ou\", \"outre\", \"oÃ¹\", \"p\", \"par\", \"par-delÃ \", \"parbleu\", \"parce\", \"parmi\", \"pas\", \"passÃ©\", \"pendant\", \"personne\", \"peu\", \"plus\", \"plus_d'un\", \"plus_d'une\", \"plusieurs\", \"pour\", \"pourquoi\", \"pourtant\", \"pourvu\", \"prÃ¨s\", \"puisqu'\", \"puisque\", \"q\", \"qu\", \"qu'\", \"qu'elle\", \"qu'elles\", \"qu'il\", \"qu'ils\", \"qu'on\", \"quand\", \"quant\", \"quarante\", \"quarante-cinq\", \"quarante-deux\", \"quarante-et-un\", \"quarante-huit\", \"quarante-neuf\", \"quarante-quatre\", \"quarante-sept\", \"quarante-six\", \"quarante-trois\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatre-vingt-cinq\", \"quatre-vingt-deux\", \"quatre-vingt-dix\", \"quatre-vingt-dix-huit\", \"quatre-vingt-dix-neuf\", \"quatre-vingt-dix-sept\", \"quatre-vingt-douze\", \"quatre-vingt-huit\", \"quatre-vingt-neuf\", \"quatre-vingt-onze\", \"quatre-vingt-quatorze\", \"quatre-vingt-quatre\", \"quatre-vingt-quinze\", \"quatre-vingt-seize\", \"quatre-vingt-sept\", \"quatre-vingt-six\", \"quatre-vingt-treize\", \"quatre-vingt-trois\", \"quatre-vingt-un\", \"quatre-vingt-une\", \"quatre-vingts\", \"que\", \"quel\", \"quelle\", \"quelles\", \"quelqu'\", \"quelqu'un\", \"quelqu'une\", \"quelque\", \"quelques\", \"quelques-unes\", \"quelques-uns\", \"quels\", \"qui\", \"quiconque\", \"quinze\", \"quoi\", \"quoiqu'\", \"quoique\", \"r\", \"revoici\", \"revoilÃ \", \"rien\", \"s\", \"s'\", \"sa\", \"sans\", \"sauf\", \"se\", \"seize\", \"selon\", \"sept\", \"septante\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\", \"serions\", \"serons\", \"seront\", \"ses\", \"si\", \"sinon\", \"six\", \"soi\", \"soient\", \"sois\", \"soit\", \"soixante\", \"soixante-cinq\", \"soixante-deux\", \"soixante-dix\", \"soixante-dix-huit\", \"soixante-dix-neuf\", \"soixante-dix-sept\", \"soixante-douze\", \"soixante-et-onze\", \"soixante-et-un\", \"soixante-et-une\", \"soixante-huit\", \"soixante-neuf\", \"soixante-quatorze\", \"soixante-quatre\", \"soixante-quinze\", \"soixante-seize\", \"soixante-sept\", \"soixante-six\", \"soixante-treize\", \"soixante-trois\", \"sommes\", \"son\", \"sont\", \"sous\", \"soyez\", \"soyons\", \"suis\", \"suite\", \"sur\", \"sus\", \"t\", \"t'\", \"ta\", \"tacatac\", \"tandis\", \"te\", \"tel\", \"telle\", \"telles\", \"tels\", \"tes\", \"toi\", \"ton\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"trente-cinq\", \"trente-deux\", \"trente-et-un\", \"trente-huit\", \"trente-neuf\", \"trente-quatre\", \"trente-sept\", \"trente-six\", \"trente-trois\", \"trois\", \"trÃ¨s\", \"tu\", \"u\", \"un\", \"une\", \"unes\", \"uns\", \"v\", \"vers\", \"via\", \"vingt\", \"vingt-cinq\", \"vingt-deux\", \"vingt-huit\", \"vingt-neuf\", \"vingt-quatre\", \"vingt-sept\", \"vingt-six\", \"vingt-trois\", \"vis-Ã -vis\", \"voici\", \"voilÃ \", \"vos\", \"votre\", \"vous\", \"w\", \"x\", \"y\", \"z\", \"zÃ©ro\", \"Ã \", \"Ã§'\", \"Ã§a\", \"Ã¨s\", \"Ã©taient\", \"Ã©tais\", \"Ã©tait\", \"Ã©tant\", \"Ã©tiez\", \"Ã©tions\", \"Ã©tÃ©\", \"Ã©tÃ©e\", \"Ã©tÃ©es\", \"Ã©tÃ©s\", \"Ãªtes\", \"Ãªtre\", \"Ã´\"]\n",
        "  cleaned_text = []\n",
        "  for abstract in text:\n",
        "      lowercase_text = abstract.lower()\n",
        "      words = tokenizer.tokenize(lowercase_text)\n",
        "      non_stopped_words = [lemmatizer.lemmatize(i) for i in words if not i in fr_stop and not bool(re.search(\"\\d+\",i)) and len(i)>3]\n",
        "      cleaned_text.append(non_stopped_words)\n",
        "  return cleaned_text\n",
        "  \n",
        "def doLDA(cleaned_text):\n",
        "  dictionary = corpora.Dictionary(cleaned_text)\n",
        "  corpus = [dictionary.doc2bow(abstract) for abstract in cleaned_text]\n",
        "  ldamodel = models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary)\n",
        "  print(ldamodel.print_topics(num_topics=2, num_words=4))\n",
        "  return ldamodel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_be4mFnn36"
      },
      "source": [
        "Comme dans les exemples trouvables sur internet, j'ai utilisÃ© l'implÃ©mentation de tfidf de sklearn ce qui me permet de rÃ©cupÃ©rer le rÃ©sulat final soit forme d'un Dataframe pandas avec en abscisse les mots d'arrÃªt et en ordonnÃ© l'index des rÃ©sumÃ©s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV5HzTpfoJ5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "20b57d74-606e-4141-e6c4-12faa3be8f0c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "text = clean_text(text = abstracts)\n",
        "corpus = [' '.join(doc) for doc in text]\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns=feature_names)\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonnÃ©</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrÃ©gÃ©</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>acadÃ©miques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptÃ©es</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordÃ©</th>\n",
              "      <th>accÃ¨s</th>\n",
              "      <th>accÃ©der</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquiÃ¨re</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activitÃ©</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>Ã©tiquetagemorpho</th>\n",
              "      <th>Ã©tiqueteur</th>\n",
              "      <th>Ã©tiquettage</th>\n",
              "      <th>Ã©tiquette</th>\n",
              "      <th>Ã©tiquetÃ©</th>\n",
              "      <th>Ã©tiquetÃ©s</th>\n",
              "      <th>Ã©tranger</th>\n",
              "      <th>Ã©tude</th>\n",
              "      <th>Ã©tudiant</th>\n",
              "      <th>Ã©tudier</th>\n",
              "      <th>Ã©tudions</th>\n",
              "      <th>Ã©tudiÃ©</th>\n",
              "      <th>Ã©tudiÃ©es</th>\n",
              "      <th>Ã©tudiÃ©s</th>\n",
              "      <th>Ã©tymologie</th>\n",
              "      <th>Ã©valuatif</th>\n",
              "      <th>Ã©valuation</th>\n",
              "      <th>Ã©valuative</th>\n",
              "      <th>Ã©valuatives</th>\n",
              "      <th>Ã©valuer</th>\n",
              "      <th>Ã©valuerons</th>\n",
              "      <th>Ã©valuÃ©e</th>\n",
              "      <th>Ã©ventail</th>\n",
              "      <th>Ã©ventualitÃ©</th>\n",
              "      <th>Ã©vidence</th>\n",
              "      <th>Ã©vident</th>\n",
              "      <th>Ã©viter</th>\n",
              "      <th>Ã©volutif</th>\n",
              "      <th>Ã©volutifs</th>\n",
              "      <th>Ã©volution</th>\n",
              "      <th>Ã©volutive</th>\n",
              "      <th>Ã©volutives</th>\n",
              "      <th>Ã©volutivitÃ©</th>\n",
              "      <th>Ã©voque</th>\n",
              "      <th>Ã©voquÃ©es</th>\n",
              "      <th>Ã©vÃ¨nementielle</th>\n",
              "      <th>Ã©vÃ¨nements</th>\n",
              "      <th>Ã©vÃ©nement</th>\n",
              "      <th>Ã©vÃ©nementielle</th>\n",
              "      <th>Ã©vÃ©nementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1501 rows Ã— 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      abandonnant  abandonnÃ©  able  ...  Ã©vÃ©nement  Ã©vÃ©nementielle  Ã©vÃ©nementiels\n",
              "0             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "2             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "3             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "4             0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "...           ...        ...   ...  ...        ...             ...            ...\n",
              "1496          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1497          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1498          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1499          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "1500          0.0        0.0   0.0  ...        0.0             0.0            0.0\n",
              "\n",
              "[1501 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwRd1wxUoaHp"
      },
      "source": [
        "Les mots ayant un tfidf de 0 ne sont pas prÃ©sent dans les rÃ©sumÃ©s des lignes correspondantes, ils ne sont donc pas pertinent, je crÃ©e donc un deuxiÃ¨me jeu de donnÃ©e fait des valeurs strictement positives.\n",
        "\n",
        "La fonction describe donne des statistiques sur le jeu de donnÃ©e, celle ci est utile pour connaitre la rÃ©partition des valeurs td idf pertinentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "cvHML79AXhg0",
        "outputId": "a5467dd8-bef8-4905-f00e-0e829f90faff"
      },
      "source": [
        "desc = df[df > 0].describe()\n",
        "desc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandonnant</th>\n",
              "      <th>abandonnÃ©</th>\n",
              "      <th>able</th>\n",
              "      <th>abord</th>\n",
              "      <th>abordant</th>\n",
              "      <th>abrupte</th>\n",
              "      <th>abrÃ©gÃ©</th>\n",
              "      <th>absence</th>\n",
              "      <th>absent</th>\n",
              "      <th>abstractif</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>abstraite</th>\n",
              "      <th>abstraites</th>\n",
              "      <th>acadÃ©miques</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepte</th>\n",
              "      <th>acception</th>\n",
              "      <th>acceptÃ©es</th>\n",
              "      <th>accessibles</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompagne</th>\n",
              "      <th>accord</th>\n",
              "      <th>accordÃ©</th>\n",
              "      <th>accÃ¨s</th>\n",
              "      <th>accÃ©der</th>\n",
              "      <th>acoustique</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>acquisitionniste</th>\n",
              "      <th>acquiÃ¨re</th>\n",
              "      <th>actancielle</th>\n",
              "      <th>actant</th>\n",
              "      <th>acte</th>\n",
              "      <th>actif</th>\n",
              "      <th>action</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activitÃ©</th>\n",
              "      <th>actuelle</th>\n",
              "      <th>actuellement</th>\n",
              "      <th>acyclic</th>\n",
              "      <th>...</th>\n",
              "      <th>Ã©tiquetagemorpho</th>\n",
              "      <th>Ã©tiqueteur</th>\n",
              "      <th>Ã©tiquettage</th>\n",
              "      <th>Ã©tiquette</th>\n",
              "      <th>Ã©tiquetÃ©</th>\n",
              "      <th>Ã©tiquetÃ©s</th>\n",
              "      <th>Ã©tranger</th>\n",
              "      <th>Ã©tude</th>\n",
              "      <th>Ã©tudiant</th>\n",
              "      <th>Ã©tudier</th>\n",
              "      <th>Ã©tudions</th>\n",
              "      <th>Ã©tudiÃ©</th>\n",
              "      <th>Ã©tudiÃ©es</th>\n",
              "      <th>Ã©tudiÃ©s</th>\n",
              "      <th>Ã©tymologie</th>\n",
              "      <th>Ã©valuatif</th>\n",
              "      <th>Ã©valuation</th>\n",
              "      <th>Ã©valuative</th>\n",
              "      <th>Ã©valuatives</th>\n",
              "      <th>Ã©valuer</th>\n",
              "      <th>Ã©valuerons</th>\n",
              "      <th>Ã©valuÃ©e</th>\n",
              "      <th>Ã©ventail</th>\n",
              "      <th>Ã©ventualitÃ©</th>\n",
              "      <th>Ã©vidence</th>\n",
              "      <th>Ã©vident</th>\n",
              "      <th>Ã©viter</th>\n",
              "      <th>Ã©volutif</th>\n",
              "      <th>Ã©volutifs</th>\n",
              "      <th>Ã©volution</th>\n",
              "      <th>Ã©volutive</th>\n",
              "      <th>Ã©volutives</th>\n",
              "      <th>Ã©volutivitÃ©</th>\n",
              "      <th>Ã©voque</th>\n",
              "      <th>Ã©voquÃ©es</th>\n",
              "      <th>Ã©vÃ¨nementielle</th>\n",
              "      <th>Ã©vÃ¨nements</th>\n",
              "      <th>Ã©vÃ©nement</th>\n",
              "      <th>Ã©vÃ©nementielle</th>\n",
              "      <th>Ã©vÃ©nementiels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.108237</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.342702</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.279619</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.376711</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.385082</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.381658</td>\n",
              "      <td>0.341043</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.296847</td>\n",
              "      <td>0.417863</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.360660</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.410997</td>\n",
              "      <td>0.318679</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.243023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.308624</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105788</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.089011</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.254174</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440063</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023640</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.156819</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.184360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.163013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.179554</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.104128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.055251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.133793</td>\n",
              "      <td>0.067838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.189427</td>\n",
              "      <td>0.032545</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.207922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.079683</td>\n",
              "      <td>0.232430</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.096411</td>\n",
              "      <td>0.136131</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.120218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.058638</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.102108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.174677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.052591</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.070434</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.145592</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.118352</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.351925</td>\n",
              "      <td>0.108891</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.372931</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.062085</td>\n",
              "      <td>0.360501</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.138369</td>\n",
              "      <td>0.123565</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.096134</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.319018</td>\n",
              "      <td>0.036016</td>\n",
              "      <td>0.079687</td>\n",
              "      <td>0.326456</td>\n",
              "      <td>0.058839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.055999</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.078073</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.170236</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.174820</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.376107</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.102025</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.275764</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.131590</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.310124</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.359586</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.360251</td>\n",
              "      <td>0.250554</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.392465</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.230344</td>\n",
              "      <td>0.380424</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.205342</td>\n",
              "      <td>0.135071</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.243898</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.386965</td>\n",
              "      <td>0.114754</td>\n",
              "      <td>0.154782</td>\n",
              "      <td>0.360542</td>\n",
              "      <td>0.091839</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.245567</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.072856</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.060956</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.093946</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.197336</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.236578</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.396827</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.113916</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.350694</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383865</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.445103</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.461537</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.368577</td>\n",
              "      <td>0.329032</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.350722</td>\n",
              "      <td>0.400347</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.272315</td>\n",
              "      <td>0.146578</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.317559</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.454911</td>\n",
              "      <td>0.378852</td>\n",
              "      <td>0.229877</td>\n",
              "      <td>0.394629</td>\n",
              "      <td>0.291897</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.301311</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.105908</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.091875</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.109820</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.224435</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.298336</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.440921</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.126838</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.417633</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.387685</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.462888</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.487033</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.396525</td>\n",
              "      <td>0.426920</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.431534</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.379694</td>\n",
              "      <td>0.446544</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.339287</td>\n",
              "      <td>0.158084</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.535561</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.456986</td>\n",
              "      <td>0.525753</td>\n",
              "      <td>0.304972</td>\n",
              "      <td>0.428715</td>\n",
              "      <td>0.362058</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.354599</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.138840</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.119930</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.125694</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.296143</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.360094</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.469429</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.49014</td>\n",
              "      <td>0.127969</td>\n",
              "      <td>0.153754</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.098484</td>\n",
              "      <td>0.199494</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.383112</td>\n",
              "      <td>0.361251</td>\n",
              "      <td>0.380473</td>\n",
              "      <td>0.523828</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.082296</td>\n",
              "      <td>0.042082</td>\n",
              "      <td>0.458937</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.096389</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.537448</td>\n",
              "      <td>0.132849</td>\n",
              "      <td>0.498902</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.424473</td>\n",
              "      <td>0.478975</td>\n",
              "      <td>0.145834</td>\n",
              "      <td>0.16775</td>\n",
              "      <td>0.451068</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>0.474284</td>\n",
              "      <td>0.492741</td>\n",
              "      <td>0.23954</td>\n",
              "      <td>0.477939</td>\n",
              "      <td>0.448518</td>\n",
              "      <td>0.406260</td>\n",
              "      <td>0.169591</td>\n",
              "      <td>0.179809</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533672</td>\n",
              "      <td>0.667564</td>\n",
              "      <td>0.661729</td>\n",
              "      <td>0.459062</td>\n",
              "      <td>0.538022</td>\n",
              "      <td>0.380066</td>\n",
              "      <td>0.462802</td>\n",
              "      <td>0.404369</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.144373</td>\n",
              "      <td>0.187268</td>\n",
              "      <td>0.114487</td>\n",
              "      <td>0.180725</td>\n",
              "      <td>0.193035</td>\n",
              "      <td>0.562541</td>\n",
              "      <td>0.608532</td>\n",
              "      <td>0.694558</td>\n",
              "      <td>0.458665</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>0.174313</td>\n",
              "      <td>0.134081</td>\n",
              "      <td>0.172197</td>\n",
              "      <td>0.152857</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.135269</td>\n",
              "      <td>0.078354</td>\n",
              "      <td>0.141568</td>\n",
              "      <td>0.344205</td>\n",
              "      <td>0.184644</td>\n",
              "      <td>0.367850</td>\n",
              "      <td>0.54228</td>\n",
              "      <td>0.421852</td>\n",
              "      <td>0.511433</td>\n",
              "      <td>0.163373</td>\n",
              "      <td>0.22801</td>\n",
              "      <td>0.411759</td>\n",
              "      <td>0.607883</td>\n",
              "      <td>0.541786</td>\n",
              "      <td>0.594895</td>\n",
              "      <td>0.524093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 3002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       abandonnant  abandonnÃ©  ...  Ã©vÃ©nementielle  Ã©vÃ©nementiels\n",
              "count     1.000000   1.000000  ...        1.000000       1.000000\n",
              "mean      0.082296   0.096364  ...        0.594895       0.524093\n",
              "std            NaN        NaN  ...             NaN            NaN\n",
              "min       0.082296   0.096364  ...        0.594895       0.524093\n",
              "25%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "50%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "75%       0.082296   0.096364  ...        0.594895       0.524093\n",
              "max       0.082296   0.096364  ...        0.594895       0.524093\n",
              "\n",
              "[8 rows x 3002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqOsQ-KppbNy"
      },
      "source": [
        "J'extraie la ligne des moyennes que je place dans une variable sous forme d'un tableau triÃ© de maniÃ¨re descendante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SsMCyMEZa--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662a1c08-3ce4-4690-fc2a-f1ba2fbbe17b"
      },
      "source": [
        "tf_idf_mean = desc.iloc[1,:]\n",
        "mean_of_means = tf_idf_mean.sort_values(ascending=False).values\n",
        "mean_of_means"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88552986, 0.87503543, 0.85792386, ..., 0.04208241, 0.04208241,\n",
              "       0.04208241])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wGgunJlpzUq"
      },
      "source": [
        "La coupe se fait sur l'index de la partie entiÃ¨re du quart de la longueur du tableau, la valeur ext extraite dans une variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3Cd3s00Tnb",
        "outputId": "1dba7062-253b-4013-dc7e-78a1842dfa52"
      },
      "source": [
        "mean_of_means = mean_of_means[int(len(mean_of_means)*1/4)]\n",
        "mean_of_means"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4300170482020056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VVGbSoYqJIK"
      },
      "source": [
        "Les mots finaux sont ceux qui ont un score tfidf supÃ©rieur ou Ã©gale Ã  la valeur discriminatoire dÃ©terminer plus tÃ´t."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L2UeAZL56A8E",
        "outputId": "722491c6-00f2-4a39-9816-13acc423fbd3"
      },
      "source": [
        "words = tf_idf_mean[tf_idf_mean >= mean_of_means].index\n",
        "words = pd.DataFrame(words)\n",
        "words = words.rename(columns={0:\"words\"})\n",
        "words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>able</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>actant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>activation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adapatabilitÃ©</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Ã©volutivitÃ©</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>Ã©vÃ¨nements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>Ã©vÃ©nement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>Ã©vÃ©nementielle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>Ã©vÃ©nementiels</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>751 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              words\n",
              "0              able\n",
              "1            actant\n",
              "2        activation\n",
              "3            active\n",
              "4     adapatabilitÃ©\n",
              "..              ...\n",
              "746     Ã©volutivitÃ©\n",
              "747      Ã©vÃ¨nements\n",
              "748       Ã©vÃ©nement\n",
              "749  Ã©vÃ©nementielle\n",
              "750   Ã©vÃ©nementiels\n",
              "\n",
              "[751 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxYxZrCi20N1"
      },
      "source": [
        "J'Ã©pure le texte des mots d'arrÃªts dÃ©terminÃ©s par tfidf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKnNtPtIpQok",
        "outputId": "3c660ff8-62eb-456a-e29b-cab6517ba94c"
      },
      "source": [
        "final_text = [i for i in text if i in words.values]\n",
        "final_text[0:4]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['dÃ©placer',\n",
              "  'pied',\n",
              "  'moyen',\n",
              "  'activitÃ©',\n",
              "  'humaine',\n",
              "  'courante',\n",
              "  'trouver',\n",
              "  'chemin',\n",
              "  'suppose',\n",
              "  'souvent',\n",
              "  'aide',\n",
              "  'type',\n",
              "  'verbal',\n",
              "  'description',\n",
              "  'itinÃ©raire',\n",
              "  'iconique',\n",
              "  'croquis',\n",
              "  'carte',\n",
              "  'prÃ©sentons',\n",
              "  'article',\n",
              "  'systÃ¨me',\n",
              "  'capable',\n",
              "  'produire',\n",
              "  'description',\n",
              "  'itinÃ©raire',\n",
              "  'mÃ©tro',\n",
              "  'gÃ©nÃ©rateur',\n",
              "  'fondÃ©',\n",
              "  'cognitif',\n",
              "  'production',\n",
              "  'description',\n",
              "  'analyse',\n",
              "  'corpus',\n",
              "  'montrons',\n",
              "  'comment',\n",
              "  'facteur',\n",
              "  'importance',\n",
              "  'relative',\n",
              "  'information',\n",
              "  'choix',\n",
              "  'stylistique',\n",
              "  'peuvent',\n",
              "  'faire',\n",
              "  'varier',\n",
              "  'foi',\n",
              "  'contenu',\n",
              "  'forme',\n",
              "  'description',\n",
              "  'itinÃ©raire'],\n",
              " ['expression',\n",
              "  'spatio',\n",
              "  'temporalitÃ©',\n",
              "  'traditionnellement',\n",
              "  'scindÃ©e',\n",
              "  'paradigme',\n",
              "  'localisation',\n",
              "  'dÃ©placement',\n",
              "  'localisation',\n",
              "  'exprime',\n",
              "  'nombre',\n",
              "  'relation',\n",
              "  'entitÃ©',\n",
              "  'localiser',\n",
              "  'site',\n",
              "  'dÃ©placement',\n",
              "  'exprime',\n",
              "  'changement',\n",
              "  'relation',\n",
              "  'temps',\n",
              "  'omettre',\n",
              "  'autonomie',\n",
              "  'richesse',\n",
              "  'dÃ©placement',\n",
              "  'exprimer',\n",
              "  'rapport',\n",
              "  'localisation',\n",
              "  'opposer',\n",
              "  'paradigme',\n",
              "  'partagent',\n",
              "  'nombre',\n",
              "  'type',\n",
              "  'contrainte',\n",
              "  'topologie',\n",
              "  'distance',\n",
              "  'proposons',\n",
              "  'observer',\n",
              "  'domaine',\n",
              "  'spatio',\n",
              "  'temporel',\n",
              "  'articulation',\n",
              "  'faÃ§on',\n",
              "  'oppose',\n",
              "  'montre',\n",
              "  'contraire',\n",
              "  'partagent',\n",
              "  'travail',\n",
              "  'formalisation',\n",
              "  'analyse',\n",
              "  'destinÃ©',\n",
              "  'Ã©laboration',\n",
              "  'mÃ©canisme',\n",
              "  'comprÃ©hension',\n",
              "  'automatique'],\n",
              " ['objectif',\n",
              "  'Ã©tude',\n",
              "  'concerne',\n",
              "  'traitement',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'systÃ¨me',\n",
              "  'reconnaissance',\n",
              "  'parole',\n",
              "  'exploitant',\n",
              "  'contrainte',\n",
              "  'accord',\n",
              "  'phrase',\n",
              "  'reconnaÃ®tre',\n",
              "  'nombre',\n",
              "  'contrainte',\n",
              "  'peut',\n",
              "  'traitÃ©',\n",
              "  'modÃ¨le',\n",
              "  'langage',\n",
              "  'portÃ©e',\n",
              "  'locale',\n",
              "  'type',\n",
              "  'gram',\n",
              "  'utilisÃ©s',\n",
              "  'habituellement',\n",
              "  'modÃ¨le',\n",
              "  'proposÃ©s',\n",
              "  'modÃ¨le',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'modÃ¨le',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'permettent',\n",
              "  'rÃ©soudre',\n",
              "  'homophonie',\n",
              "  'mÃ©thode',\n",
              "  'modÃ¨le',\n",
              "  'base',\n",
              "  'syntagme',\n",
              "  'permet',\n",
              "  'introduire',\n",
              "  'contrainte',\n",
              "  'syntaxiques',\n",
              "  'modÃ¨le',\n",
              "  'homophone',\n",
              "  'cache',\n",
              "  'objet',\n",
              "  'discriminer',\n",
              "  'homophone',\n",
              "  'singulier',\n",
              "  'pluriel',\n",
              "  'maniÃ¨re',\n",
              "  'robuste',\n",
              "  'sensible',\n",
              "  'mauvais',\n",
              "  'reconnaissance',\n",
              "  'sein',\n",
              "  'phrase'],\n",
              " ['article',\n",
              "  'prÃ©sente',\n",
              "  'identification',\n",
              "  'corpus',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'considÃ©rÃ©s',\n",
              "  'linguiste',\n",
              "  'hautement',\n",
              "  'dÃ©nominatifs',\n",
              "  'approche',\n",
              "  'utilise',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologique',\n",
              "  'applique',\n",
              "  'corpus',\n",
              "  'prÃ©alablement',\n",
              "  'Ã©tiquetÃ©',\n",
              "  'lemmatisÃ©',\n",
              "  'avoir',\n",
              "  'rappelÃ©',\n",
              "  'propriÃ©tÃ©',\n",
              "  'linguistique',\n",
              "  'adjectif',\n",
              "  'relationnels',\n",
              "  'prÃ©senterons',\n",
              "  'programme',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'modification',\n",
              "  'apportÃ©es',\n",
              "  'effectuer',\n",
              "  'identification',\n",
              "  'Ã©valuerons',\n",
              "  'caractÃ¨re',\n",
              "  'dÃ©nominatif',\n",
              "  'adjectif',\n",
              "  'terme',\n",
              "  'nominaux',\n",
              "  'apparaissent',\n",
              "  'comparant',\n",
              "  'thesaurus',\n",
              "  'conclurons',\n",
              "  'intÃ©rÃªt',\n",
              "  'adjectif',\n",
              "  'foi',\n",
              "  'extraction',\n",
              "  'terminologie',\n",
              "  'problÃ©matique',\n",
              "  'extraction',\n",
              "  'connaissance',\n",
              "  'partir',\n",
              "  'corpus',\n",
              "  'mise',\n",
              "  'jour',\n",
              "  'thesaurus']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7M-PP9C-RWf",
        "outputId": "15ef15c0-e149-44fa-b968-1ad681431bde"
      },
      "source": [
        "doLDA(words.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.002*\"dicovalence\" + 0.002*\"rÃ©pÃ©tÃ©s\" + 0.002*\"empiriques\" + 0.002*\"jeu\"'), (1, '0.002*\"nÃ©gation\" + 0.002*\"world\" + 0.002*\"extension\" + 0.002*\"tourisme\"')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.ldamodel.LdaModel at 0x7efe0411d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALiHMVd2-Dq"
      },
      "source": [
        "Transformers est une librairie qui utilise huggingface dans un environnement pytorch et tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R02wjiLcH3y",
        "outputId": "180d8e42-22df-4b52-ca10-401e9ee9d3a8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 43.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fa8bb40f6fe39ec1b054ab2f2c4f2fbcf96ef36f59afdce5564b7e061e7e9f89\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_7wEr-e3IOL"
      },
      "source": [
        "T5-base est un modÃ¨le encodeur dÃ©codeur entrainÃ© sur des articles de presse,  il est capable de faire des rÃ©sumÃ©s en prÃ©disant Ã  partir d'une sÃ©quence de reprÃ©sentation vectorielle d'une chaine de caractÃ¨re une autre chaine plus petite. Sa capacitÃ© d'entrÃ©e est limitÃ© Ã  512 vecteurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "8a7436a844814321bec9efa9e75dddee",
            "6597aae9b50540d591d327d811140fe6",
            "ed160c828f7a45a6a21f017a0d3ff2dd",
            "c3a9805861074e85935bdc96f27308b2",
            "d00200ac39344a45bb4b13627e2415f5",
            "092cd69131e94e01a33869984d252490",
            "bc338c906c874f06ae79f192002690d2",
            "5c5c44d482814afeb6646e29f67ec4bf",
            "c13a796deb324ee5ab0517cfd9a67504",
            "662cf31735914c66a58e446f42f33a44",
            "015a6f5cdd2b40779560d911ae011a5b",
            "cc598a4ab9954c10979dd8704c0c64fe",
            "acc88fb05ab04cf58bd75d98ac4399e5",
            "f9d3f0f543ac40929ad82574955fb23f",
            "5149f97423974c5faa37fb19ab5ad650",
            "f0bfd2a76bcb45fabddba532ec553ae9",
            "7460571df65d4f6d976e6ad48b63e04a",
            "9c448466034c433ea0866e952be3ccb5",
            "06dc4f869fad46aa938042f1de1b536a",
            "389fc01fc08c46e6b30b27a60b44ef79",
            "986812b32d65416ba26c688e3ecbbe72",
            "5bbcdb4bcaeb4f8f9fd8fd8718a596b4",
            "bea411c3581b4eabb275826ddb052f2a",
            "2283e7654ee24404a56299462250b25e",
            "2a9e88b138e140578d81958edd8987c8",
            "78d775a25b404be5a76bffa9a101cac6",
            "7bb99946316e45bea265e0ff1641f329",
            "e6103afe0cc5478aa35e4ad92271f8fa",
            "79110aefc6994d6c9fa8f31991b600e5",
            "f82d5814f7c0414cb114a278e45956a0",
            "65a942425ee24c30a4c8f2c2ce1615a9",
            "ba06178a696249aea502f550eda4aad8"
          ]
        },
        "id": "gxlI-JaEc7AH",
        "outputId": "80fdcee8-7a46-49b2-8db7-046bb94c38fa"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a7436a844814321bec9efa9e75dddee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c13a796deb324ee5ab0517cfd9a67504",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7460571df65d4f6d976e6ad48b63e04a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9e88b138e140578d81958edd8987c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMV4xwl3kqt"
      },
      "source": [
        "Avec cette fonction je transforme ma liste de rÃ©sumÃ© d'article du corpus en liste des rÃ©sumÃ©s concatÃ©nÃ©s s'ils font moins de 512 mots ensemble.\n",
        "Ceux qui font plus de 512 mots sont ajoutÃ©s Ã  la liste immÃ©diatement, ils seront tronquÃ© par le modÃ¨le."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1JqHtF8Un5J"
      },
      "source": [
        "def Make_Data_For_T5(text_list,token_func):\n",
        "  text_for_model = []\n",
        "  holder = ''\n",
        "  for i in range(len(text_list)):\n",
        "    if len(token_func.encode(text_list[i]))>512:\n",
        "      text_for_model.append(text_list[i])\n",
        "    else:\n",
        "      if len(token_func.encode(holder))+len(token_func.encode(text_list[i]))>512:\n",
        "        text_for_model.append(holder)\n",
        "        holder = ''\n",
        "      else:\n",
        "        holder += text_list[i]\n",
        "  return text_for_model\n",
        "text_for_model = Make_Data_For_T5(abstracts,tokenizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Tl_EuhacQP",
        "outputId": "f46d48a6-db2d-4e89-b3b6-4068e09e0ac4"
      },
      "source": [
        "len(text_for_model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KaYX7oJXx6K"
      },
      "source": [
        "summaries = []\n",
        "for i in text_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOh-KjwraJ3k",
        "outputId": "de1ad2de-8b9a-43f6-e9dc-610e1e9c6fce"
      },
      "source": [
        "summaries_for_model = Make_Data_For_T5(summaries,tokenizer)\n",
        "summaries_for_model = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model]\n",
        "summaries_for_model[0:4]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Ã  en proposer des illustrations sous forme de sÃ©quences fixes. Notre recherche est le fruit d\\'une collaboration entre un laboratoire universitaire et une entreprise. Elle prend appui sur le modÃ¨le de la Grammaire Applicative et Cognitive [DES 90] qui vise Ã  \"expliquer\", Ã  un certain niveau cognitif, les transferts entre reprÃ©sentations imagÃ©es et verbales.</s> d\\'analyse syntaxique. Cependant, peu d\\'entre elles reposent sur un vÃ©ritable formalisme linguistique. Nous prÃ©sentons ici un aperÃ§u du logiciel DECID dÃ©veloppÃ© au GETA afin d\\'informatiser le processus de rÃ©daction du dictionnaire explicatif et combinatoire franÃ§ais contemporain.</s> dans le contexte des approches Ã  base de grammaires faiblement sensibles au contexte, cette contribution passe en revue le problÃ¨me de l\\'extraction de l\\'arbre d\\'analyse le plus probable au sens de Data-Oriented Parsing (DOP). Une dÃ©monstration formelle de l\\'utilisabilitÃ© des mÃ©thodes de Monte-Carlo est donnÃ©e, puis une technique d\\'Ã©chantillonnage contrÃ´lÃ©e est dÃ©veloppÃ©e per</s> l\\'ordre d\\'intervention de ces deux couches dans le processus d\\'analyse est dÃ©terminÃ© par l\\'occurrence de marques de surface qui indiquent la prÃ©sence d\\'une distorsion ou d\\'une construction particuliÃ¨re (interrogative, relative, etc.). La premiÃ¨re version de l\\'analyseur nous a fourni des rÃ©sultats encourageants qui nous invitent Ã  reconsidÃ©rer le rÃ´le et l\\'utilitÃ© des ressources linguistiques dÃ©veloppÃ©es pour le traitement</s> reclasser les mots reprÃ©sentÃ©s sur la base de leurs contraintes syntaxiques-sÃ©mantiques ; il faut ensuite reclasser les mots reprÃ©sentÃ©s sur la base de leurs contraintes syntaxiques-sÃ©mantiques ; il faut ensuite reclasser ces mots sur la base de leurs contraintes syntaxiques-sÃ©mantiques.</s>',\n",
              " \" On parle souvent de chemins et de trajectoires, mais on ne les exprime pas dans le temps. La localisation exprime alors un certain nombre de relations entre une entitÃ© Ã  localiser et des sites, tandis que le dÃ©placement exprime un changement de ces relations dans le temps.</s> des donnÃ©es de grande taille. Nous prÃ©sentons en dÃ©tail la mÃ©trique PrÃ©cision-DÃ©cision qui a Ã©tÃ© dÃ©veloppÃ©e dans le cadre de GRACE pour mesurer quantitativement les performances des systÃ¨mes d'Ã©tiquetage.</s> linguistique informatique. une des recherches de pointe menÃ©es actuellement en informatique est l'extraction des connaissances dans un texte Ã©lectronique (textual data mining). Nous prÃ©sentons dans cet article un modÃ¨le hybride, Ã  la fois robuste et fin, qui s'inspire des modÃ¨les neuronaux et de l'analyse linguistique informatique.</s> automatique de textes Ã©crits.. un langage de reprÃ©sentation sÃ©mantico-cognitive des verbes. Cette communication dÃ©crit un outil informatique de construction et de consultation du lexique verbal. Cette communication ne prÃ©sente pas de dictionnaire mais dÃ©veloppe une mÃ©thodologie de construction et de consultation du lexique verbal.</s> les familles de mots morphologiquement reliÃ©s que nous avons obtenues sont correctes Ã  95 %. Nous proposons une mÃ©thode simple et puissante pour amÃ©liorer le processus d'acquisition automatique du langage mÃ©dical.</s>. Or les cognats sont gÃ©nÃ©ralement captÃ©s au moyen d'une approximation abrupte, de nature opÃ©ratoire. Nous avons ensuite essayÃ© de dÃ©velopper un filtrage plus efficace, basÃ© sur une mÃ©thode gÃ©nÃ©rale dÃ©veloppÃ©e par nous.</s> d'une mÃ©thodologie prÃ©cise. <unk> partir de l'arborescence sont constituÃ©s les groupes intonatifs, tout en tenant compte du rythme. Dans certains cas, des modifications de la structure syntaxique sont effectuÃ©es.</s>\",\n",
              " \" Nous prÃ©sentons ici une implÃ©mentation de cette mÃ©thode de correction.Nous prÃ©sentons dans ce document le problÃ¨me de la dÃ©tection et de la correction des graphies fautives dans les textes arabes. Nous prÃ©sentons briÃ¨vement les principaux rÃ©sultats obtenus Ã  ce jour dans le cadre du projet MAREDI.</s> des connaissances langagiÃ¨res prÃ©-codÃ©es. Les premiers dialogues obtenus sont de ce fait laborieux, mais ils deviennent progressivement conviviaux.Notre Ã©tude propose un modÃ¨le cohÃ©rent pour formaliser la modalitÃ© en tant que module interlingua d'un systÃ¨me de traduction automatique (TA).</s> une grammaire d'arbres adjoints compactÃ©e et sur la mise en concurrence des diffÃ©rentes hypothÃ¨ses du systÃ¨me de reconnaissance de la parole. Nous prÃ©sentons une stratÃ©gie d'analyse robuste dans le but de relayer la dÃ©cision d'un systÃ¨me de reconnaissance de la parole.</s> n'est pas un jeu de mots gratuit, mais bien la nÃ©cessitÃ© de soumettre Ã  l'examen une pratique dans laquelle il faut tenir compte de plus en plus de chercheurs, qu'ils soient linguistes ou informaticiens.</s> sÃ©mantique. sÃ©mantique, il s'agit d'une requÃªte orale. Si le dialogue est finalisÃ©, cette requÃªte nÃ©cessite une analyse linguistique plus fine que celle utilisÃ©e dans les applications classiques de CHM1.</s> grammaire, grammaire de propriÃ©tÃ©s, relation de dÃ©pendance, grammaire formelle, grammaire de dÃ©pendance, lexieparadigme d'Ã©valuation, campagne d'Ã©valuation, lexieparadigme d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation, campagne d'Ã©valuation</s>\",\n",
              " \" syntaxique partielle, grammaires de dÃ©pendances, aide Ã  la comprÃ©hension, lecture, spontanÃ©, dÃ©bit de parole, longueur, frÃ©quence lexicale, aide Ã  la comprÃ©hension, lecture, spontanÃ©, dÃ©bit de parole, longueur, frÃ©quence lexicale, aide Ã  la comprÃ©hension, lecture, spontanÃ©, dÃ©bit de parole, longueur, frÃ©quence lexicale, aide Ã  la comprÃ©hension, lecture, spontanÃ©, dÃ©bit de</s> langage stochastique. Les modÃ¨les de langage stochastiques favorisent l'interprÃ©tation d'un signal par les phrases les plus courtes possibles, celles-ci Ã©tant par construction souvent affectÃ©es par les coÃ»ts les plus bas.</s> il n'a jamais fait recette auprÃ¨s des littÃ©raires, des psycho-socios, des sÃ©mio-machins, des politiques et des pouvoirs acadÃ©miques dont tout le monde a oubliÃ© sur quelles complicitÃ©s exactes ils se fondaient. Il n'a jamais fait recette auprÃ¨s des littÃ©raires, des psycho-socios, des sÃ©mio-machins, des politiques et des pouvoirs </s> sÃ©mantique lexicaleAnalyse DistribuÃ©e, Micro-SystÃ¨mes, SÃ©mantique ProcÃ©duraleAnalyse DistribuÃ©e, Micro-SystÃ¨mes, SÃ©mantique ProcÃ©duraleAnalyse DistribuÃ©e, Micro-SystÃ¨mes, SÃ©mantique ProcÃ©duraleAnalyse DistribuÃ©e, Micro-SystÃ¨mes, S</s> linguistique. linguistique, sÃ©mantique, etc. Nous prÃ©sentons dans cet article un cadre d'explication des relations entre les diffÃ©rentes composantes de l'analyse linguistique (prosodie, syntaxe, sÃ©mantique, etc.). Cette approche permet d'expliquer certains phÃ©nomÃ¨nes de variabilitÃ© dans des applications comme les systÃ¨mes de synthÃ¨se de parole.</s>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ira5OwgF6KY2"
      },
      "source": [
        "RÃ©sumÃ© des rÃ©sumÃ©s concentrÃ©, ce qui donne un petit paragraphe rÃ©sumant le document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACE1Jb4R4Mk8"
      },
      "source": [
        "summaries_for_model_summarized = []\n",
        "for i in summaries_for_model:\n",
        "  inputs = tokenizer.encode(i, return_tensors=\"pt\", max_length=512)\n",
        "  outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "  summaries_for_model_summarized.append(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn-iJxSS8Rii",
        "outputId": "b81ffff7-e2f3-4f20-e856-28f6f0829e66"
      },
      "source": [
        "summaries_for_model_summarized = [re.sub(\"<pad>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized = [re.sub(\"<extra_id_\\d>\",\"\",i) for i in summaries_for_model_summarized]\n",
        "summaries_for_model_summarized"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" dans le contexte d'approches linguistiques faiblement sensibles, cette contribution passe en revue le problÃ¨me de l'extraction de l'arbre d'analyse linguistique.</s>\",\n",
              " \" d'une mÃ©thodologie de construction et de consultation du lexique verbal. Cette communication dÃ©crit en dÃ©tail un outil informatique de construction et de consultation du lexique verbal. Cette mÃ©thodologie a Ã©tÃ© dÃ©veloppÃ©e dans le cadre de GRACE.</s>\",\n",
              " \" n'est pas un jeu de mots gratuit, mais bien la nÃ©cessitÃ© de soumettre Ã  l'examen une mÃ©thode de correction linguistique plus fine que celle utilisÃ©e dans les applications classiques de CHM1.</s>\",\n",
              " \" linguistique, sÃ©mantique, etc.) n'a jamais fait recette auprÃ¨s des littÃ©raires, des psycho-socios, des politiques et des pouvoirs dont tout le monde a oubliÃ© sur quelles complices exactes ils se fondaient.</s>\",\n",
              " ' Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique, Lexique.</s>',\n",
              " \" et d'intervalles (RCG)Traduction de dialogue, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage en linguistique textuelle, apprentissage </s>\",\n",
              " ' orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique, correcteur orthographique,</s>',\n",
              " ' ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par ordinateur, traduction assistÃ©e par</s>',\n",
              " ' syntaxique, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, indices syntaxiques, </s>',\n",
              " \", classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification d'erreurs, classification syntaxique, Ã©valuation automatique, Ã©valuation automatique de textes subjectifs, Ã©valuation automatique de textes subjectifs, Ã©valuation automatique de textes subjectifs, Ã©valuation automatique de textes subjectifs, Ã©valuation automatique de textes subjectifs, Ã©valuation automatique de textes subjectifs, </s>\",\n",
              " ', apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©, apprentissage non-supervisÃ©</s>',\n",
              " ' linguistiques, apprentissage de langues, production de langage, livres de phrases, patrons, schÃ©ma de phrase, structures fondamentalesÃ‰tiqueteur, apprentissage de langues, production de langage, livres de phrases, patrons, schÃ©ma de phrase, structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales, Structures fondamentales</s>',\n",
              " ', approche numÃ©rique, approche hybride, approche symbolique, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche symbolique, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche numÃ©rique, approche hybride, approche</s>',\n",
              " ' terminologie, traduction terminologique, traduction bilingue, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduction terminologique, traduc</s>',\n",
              " ', e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, e-learning, </s>',\n",
              " \", Relation sÃ©mantique.Arabe, grammaire d'arbres adjoints, mÃ©ta-grammaire.Arabe, grammaire d'arbres adjoints, mÃ©ta-grammaire.Arabe, grammaire d'arbres adjoints, mÃ©ta-grammaire.Arabe, grammaire d'arbres adjoints, mÃ©ta-grammaire.Arabe, grammaire d'arbres adjoints, mÃ©ta-grammaire</s>\",\n",
              " ' langue anglaise.Analyse de sentiment, dialecte tunisien, prÃ©traitement de texte, entitÃ©s nommÃ©es.Analyse de sentiment au niveau des aspects, ressources sÃ©mantiques, traduction.Analyse de sentiments au niveau des aspects, ressources sÃ©mantiques, traduction.</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8FJBA2g_QOH"
      },
      "source": [
        "Ecriture des fichiers de rÃ©sultats dans le stockage en ligne, pour conserver les rÃ©sultats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCONf9D1HEW"
      },
      "source": [
        "MyFile=open('T5-base_summaries.txt','w')\n",
        "\n",
        "for element in summaries:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_model.txt','w')\n",
        "\n",
        "for element in summaries_for_model:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "MyFile=open('T5-base_summaries_of_summaries.txt','w')\n",
        "\n",
        "for element in summaries_for_model_summarized:\n",
        "     MyFile.write(element)\n",
        "     MyFile.write('\\n')\n",
        "MyFile.close()\n",
        "\n",
        "!cp T5-base_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_model.txt \"/content/drive/MyDrive/datasets/NLP/\"\n",
        "!cp T5-base_summaries_of_summaries.txt \"/content/drive/MyDrive/datasets/NLP/\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgogffNg_blg"
      },
      "source": [
        "J'ai essayÃ© beaucoup de mÃ©thode, et regardÃ© et lu beaucoup de document, notamment sur huggingface et transformers.\n",
        "J'ai prÃ©fÃ©rÃ© ces mÃ©thodes Ã  celle de modÃ¨le keras avec des couches lstm car je n'Ã©tais vraiment pas convaincue par les performances de cette technique lors de la sÃ©ance sur la gÃ©nÃ©ration de texte.\n",
        "La LDA ne fournissait pas Ã©galement de rÃ©sultat des plus explicites et pertinents Ã  mon gout, j'ai donc dÃ©laisser ces mÃ©thodes pour la structure encodeur dÃ©codeur fourni par transformers.\n",
        "J'ai essayÃ© d'utilisÃ© un modÃ¨le promÃ©teur par facebook, mais celui ne marchais pas, du fait du nom diffÃ©rent d'un attribut, la fonction generate ne pouvait rÃ©cupÃ©rer l'encodeur du modÃ¨le ce qui provoquais une erreur arrÃ©tant l'Ã©xecution du programme.\n",
        "\n",
        "\n",
        "\n",
        "La mÃ©thode que j'ai ici dÃ©vellopÃ© consiste Ã  rÃ©sumer les rÃ©sumÃ©s d'article concatÃ©nÃ© pour ensuite concatÃ©nÃ© et rÃ©sumer Ã  nouveau ces rÃ©sumÃ©s.\n",
        "En ayant lÃ» le contenu final, il touche bien aux diffÃ©rent principe du NLP et aborde les grands axes et les grandes mÃ©thodes de ce domaine, donnant un vue globale du contenu du corpus."
      ]
    }
  ]
}